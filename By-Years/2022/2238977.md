* 2238977
* CAREER: Physiological Modeling of Longitudinal Human Trust in Autonomy for Operational Environments
* CSE,IIS
* 08/01/2023,07/31/2028
* Allison Anderson, University of Colorado at Boulder
* Continuing Grant
* Todd Leen
* 07/31/2028
* USD 121,687.00

This project develops models of human trust in autonomous systems by measuring
the body's response to working with the system over time. Every day, people work
with highly autonomous systems in operational environments, such as teaming with
robots in warehouse distribution facilities or flying an airplane. If a person's
trust in the autonomy is too high or low relative to its capability, the person
may rely on it too much or not use it at all. Trust changes over time as someone
interacts with the autonomous system and learns its capabilities. However, the
person's lack of awareness of their own trust influences behavior, and as a
result impacts performance and safety. It is difficult to measure someone's
trust while they are doing these tasks because accurate measurements of trust
often disrupt the work being done. If trust can be measured continuously over
time, the person's interaction with the autonomous system can be made safer and
more efficient. Given the increased use of autonomy across sectors including
manufacturing, aerospace, the tech industry, and military, continuous measures
of trust may impact US economy and security. Further, there is a need to prepare
a diverse, technically trained workforce for advanced operational environments.
People who will be working with autonomous systems are often not trained on the
importance of trust and how it may change over time. Further, there are
currently limited opportunities for underserved and underrepresented populations
to enter this in-demand workforce. &lt;br/&gt;&lt;br/&gt;To address these needs,
the project contributes to fundamental understanding of trust in operational
environments by modeling trust dynamics from physiological signals. Changes in
trust manifest as physiological responses, which can be detected by monitoring
the heart, eye, skin, and brain. While there is increasing interest in
physiological monitoring to estimate trust, this work has been constrained to
the laboratory under ideal conditions and has yet to be successful applied to
operational environments. This project has four Research Goals (R#). R1 models
initial trust with physiological features used to predict operators' self-
reported trust. R2 assesses learned trust dynamics after repeated interactions
with autonomy. R3 investigates trust calibration by assessing operators' trust
dynamics when the reliability of the autonomous agent shifts. R4 seeks to
understand the utility of wearable sensors to model trust in operational
environments. Two demonstration environments are used: a person working with a
simulated robot to fill orders in a distribution warehouse, and a person flying
an aircraft with the assistance of an automated flight planner. The education
component of this project has two educational goals (E#) to train the human-
autonomous teaming (HAT) workforce on the importance of trust and engage the
next generation of HAT researchers and operators. E1 trains operators on the
importance of trust for workplace safety and performance through educational
modules for HAT operators. It also informs the research goals through a series
of operator interviews to define the task used in this research. E2 increases
access and engagement in STEM in Colorado. The key effort in E2 administers
experiential learning modules called Traveling Trunks, which are easy-to-
administer lessons that use HAT as a hook to increase student interest. They are
disseminated in rural, underserved high school classrooms. E2 also incorporates
outreach and research mentorship to further reinforce the STEM pipeline.
Together, these goals broadly promote an improved understanding of trust in
autonomy to demystify its abilities and improve intelligent adoption of autonomy
in operational settings.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.