* 1664923
* CRII: RI: Planning and learning with macro-actions in cooperative multiagent systems
* CSE,IIS
* 09/01/2016,01/31/2018
* Christopher Amato, Northeastern University
* Standard Grant
* James Donlon
* 01/31/2018
* USD 124,005.00

The proposal aims at studying the problem of decentralized planning. The general
technical area is decentralized partially observable Markov decision process
(Dec-POMDP). The PI proposes a theory on macro-actions by using finite-state
controllers of Dec-POMDPs. Macro-actions enable the planner to perform multiple
planning steps in a single computation cycle whereas a planner using regular
actions can only perform one action in each computation cycles. As a result,
macro-actions have the potential to solve planning problems much more
efficiently enabling (1) distributed planning tasks across multiple agents, (2)
planning in environments where agents have only limited knowledge about the
state of the world, and (3) planning in uncertain environments where actions
might have multiple outcomes.

There are many potential areas of application of this research including
distributed agents monitoring a network for security breaches, distributed
military planning, and coordinating multiple robots involved in disaster
recovery tasks.