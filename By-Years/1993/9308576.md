* 9308576
* Coordinates of Multisensory Space
* BIO,IOS
* 09/01/1993,02/28/1997
* M. Alex Meredith, Virginia Commonwealth University
* Standard Grant
* Christopher Platt
* 02/28/1997
* USD 161,535.00

9308576 Meredith We interact with objects in the space around our bodies by
interpreting visual, auditory, touch, and other sensory signals in a frame of
spatial reference. Each sensory modality has its own reference system for
central "maps" in the cortex of the brain, with vision using a map centered by
the geometry of the retina of the eye, hearing head-centered, and the
somatosensory system body-centered. However, generating appropriate behavior for
orientation to a stimulus requires some common coordinate system, so that, for
example, the eyes turn within the head to look toward the source of a sound from
one side. The superior colliculus is a complex structure in the midbrain that is
strongly implicated in this kind of spatial orientation. This work provides
novel tests for neural mechanisms that could provide a reference system for this
sensory to motor integration. Recording activity in alert, behaving animals will
clarify how multisensory neurons in deep layers of the superior colliculus
integrate combined auditory and visual stimuli. Activity of these neurons will
be examined during stimulation of one or more of the motor inputs, to further
test how motor commands may shape the response. These experiments will determine
if multisensory collicular neurons code sensory space in terms of motor
coordinates, and will clarify the relation between unimodal and multisensory
frames of reference. This novel approach will enhance our understanding of how
the brain deals with the complex sensory environment, and so will have a broad
impact on research in many sensory fields, in sensorimotor integration, and in
attention and cognition. ***