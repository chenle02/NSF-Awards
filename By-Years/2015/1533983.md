* 1533983
* PFI:BIC Human-Centered Smart-Integration of Mobile Imaging and Sensing Tools with Machine Learning for Ubiquitous Quantification of Waterborne and Airborne Nanoparticles
* TIP,TI
* 10/01/2015,09/30/2019
* Aydogan Ozcan, University of California-Los Angeles
* Standard Grant
* Jesus Soriano Molla
* 09/30/2019
* USD 1,018,160.00

This Partnerships for Innovation: Building Innovation Capacity (PFI:BIC) project
focuses on the creation of a human-centered smart toolset and service system for
on-site and ubiquitous quantification and automated
charaterization/classification of nanosize objects. Nanoparticles are being used
in more and more commercial and industrial products while their health and
environmental implications are still under debate. The toxicity of nanomaterials
not only varies among different materials, but is also highly dependent on the
dose of exposure. Developing a sensitive method to detect the release and
spatio-temporal distribution of nanoparticles in the environment as well as in
daily lives is a high priority before their toxicity effects are fully
understood via long-term toxicological studies. Despite this urgent need for
widespread detection and quantification of nanoparticle distributions, current
technologies are lacking appropriate features for ubiquitous and cost-effective
mapping and quantification of nanoparticle contamination. This project aims to
create a transformative and human-centered toolset for on-site and ubiquitous
quantification and automated characterization of nanomaterials found in houses,
workplaces and the environment based on the cost-effective integration of
computational imaging and mobile sensing techniques with big data based dynamic
machine learning algorithms. &lt;br/&gt;&lt;br/&gt;The central challenge in this
project is to translate the bulky and expensive laboratory equipment currently
used for nanoparticle quantification and characterization to field-portable,
easy-to-use, cost-effective, and rapid analysis devices and smart service
systems aiming to be massively used by consumers in their daily routines. To
solve this challenge, highly sensitive optical imaging systems will be developed
based on mass-produced Complementary Metal-Oxide Semiconductor (CMOS) sensor
chips embedded in mobile phones with extraordinary signal to noise ratios (SNR)
and large fields-of-view for high-throughput machine learning based automated
nanoparticle analysis and classification. One approach this will take is to
combine computational microscopy with self-assembled nanolenses around
nanoparticles that significantly enhance imaging SNR and contrast. The aim of
this approach is to enable automated detection and sizing of individual
nanoparticles, mono-dispersed samples, and complex poly-dispersed mixtures,
where the sample concentrations can span ~5 orders-of-magnitude and particle
sizes can range from 40 nm to millimeter-scale, which provide unmatched
performance metrics compared to existing nanoparticle sizing approaches. Another
approach that will be implemented is the development of highly sensitive multi-
modal (e.g. fluorescence plus dark-field) mobile phone based microscopy
platforms for distributed nanoparticle imaging and sensing. Furthermore, in
terms of big data analysis and machine learning tools, the techniques in this
project can adaptively learn "semantic" similarities that can be used for more
accurate data classification. These techniques are unlike existing techniques
developed so far in the literature. The extant technologies are based only on
signal similarities, which do not work well on multi-modality data. The smart
and adaptive methods of this project are the first in the literature that come
with confidence bounds, that is, they not only have the capability to accurately
classify the information, but they also provide guarantees about the accuracy of
this classification, which is quite important for self-learning smart service
systems. Through these field-portable devices that are integrated with adaptive
big data based decision analytics and quantification algorithms, spatio-temporal
maps of nanoparticle concentrations and size distributions in various consumer
samples will be created for public or personal monitoring (e.g., measurements of
waterborne/airborne particles at home, workplace, or airborne particles along a
freeway, etc.).&lt;br/&gt;&lt;br/&gt;The broader impacts of this transformative
research include (1) The development of these nanoparticle sensing and
quantification platforms and smart service systems will extend the boundaries of
current optical metrology science, resulting in new advances in the fields of
nanophotonics and optical microscopy (2) These devices will also be easy to
translate into various biomedical, chemical and material science applications,
significantly impacting the use and regulations of nanotechnologies in consumer
market and related products. (3) This project would deliver a paradigm-shift by
ubiquitous quantification and spatiotemporal mapping/monitoring of nanoparticle
contamination and exposure even in non-laboratory settings, assisting in the
revelation and better understanding of various cause-effect relationships at the
consumer level that have remained unidentified so far due to the limitations of
existing nano-imaging, detection and quantification technologies, also providing
maps of potential health risks. (4) This project will also establish a
complementary educational outreach program based in
California.&lt;br/&gt;&lt;br/&gt;The lead institution and primary partners
included in this cross-organizational interdisciplinary project are: Lead
Academic Institution: University of California, Los Angeles, CA, School of
Engineering, Electrical and Bioengineering Departments; Primary Industrial
Partner: Holomic LLC (Small Business located in Los Angeles, CA); Other
Industrial Partner: Google Inc. (Large Business located in Mountain View, CA).