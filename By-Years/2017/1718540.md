* 1718540
* SHF: Small: High-Level Programming Models for GPUs
* CSE,CCF
* 07/01/2017,06/30/2021
* John Reppy, University of Chicago
* Standard Grant
* Anindya Banerjee
* 06/30/2021
* USD 390,388.00

Modern Graphics-Processor Units (GPUs) are capable of performance that, just a
few years ago, would have been classified as supercomputer-level. With the trend
of integrating GPU cores into heterogeneous multicore processors, GPUs are
becoming an important source of future performance growth in mainstream
processors. Unfortunately, GPUs are notoriously hard to program, especially for
irregular parallel computations. This project aims to address the challenges of
programming GPUs by supporting higher-level programming models with advanced
compilation techniques. The intellectual merits of the proposed work are that it
advances the state of the art in compilation techniques and programming models
for GPUs and other accelerator architectures. The broader impact of the project
is to widen the applicability of GPUs to a wider range of computational problems
and, in turn, to help make GPUs useful to a broader community of users by
supporting higher-level programming models for GPUs that are easier to
program.&lt;br/&gt;&lt;br/&gt;The project focuses on the use of Nested Data
Parallelism (NDP) and the supporting global flattening transformation, which
supports irregular parallelism by compiling it down to flat data parallelism.
While NDP provides a high-level elegant programming model for many kinds of
irregular parallel computations, a straightforward implementation is not
competitive with hand-written GPU code. The goal of this project it to develop
and evaluate a collection of techniques for compiling NDP code to GPU with the
objective of making NDP competitive with hand-written CUDA and OpenCL code. The
work will be carried out in the context of a compiler for Blelloch's NESL
language, which is a small first-order functional language that embodies the
core concepts of NDP. NESL provides a small, but expressive, context for the
proposed research. The work is evaluated by benchmarking against handwritten
CUDA and OpenCL solutions for various irregular parallel algorithms.