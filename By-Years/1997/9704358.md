* 9704358
* SGER:  Experiments on Integrating Speech Recognition and    Natural Language Processing
* CSE,IIS
* 01/15/1997,06/30/1998
* Leah Jamieson, Purdue Research Foundation
* Standard Grant
* Gary W Strong
* 06/30/1998
* USD 50,000.00

*** This project addresses the integration of speech recognition and natural
language processing components in a speech understanding system. Most current
speech recognizers use word-level hidden Markov models (HMMs)in conjunction with
n-gram language models. Additional flexibility can be achieved by using phones
as the basic recognition unit. This research proposes a new technique called a
SOHMM Stochastic Observation Hidden Markov Model - for recognizing words from
phone candidates. Most current spoken language systems use probabilistic
language models to model syntactic and semantic patterns. This project will
integrate a SOHMM- based speech recognizer with a Constraint-Dependency Grammar
(CDG) parser, which supports the use of lexical, prosodic, syntactic, and
semantic knowledge sources in a uniform modular framework, as well as the use of
domain- specific constraints. This work will refine the model for the SOHMM-CDG
spoken language processing system and address the problem of building and
pruning word graphs, which act as the interface between the two components. An
experiment will be conducted to demonstrate the effectiveness of the integrated
system for recognizing and parsing utterances in the TIMIT and Resource
Management corpora. Sentence accuracy should be significantly improved over what
is possible using only statistical language models, especially when domain-
specific constraints are used ***.