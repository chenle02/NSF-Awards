* 1815587
* CHS: Small: Collaborative Research: Validating and Communicating Model-Based Approaches for Data Visualization Ability Assessment
* CSE,IIS
* 09/01/2018,08/31/2022
* Lane Harrison, Worcester Polytechnic Institute
* Continuing Grant
* Balakrishnan Prabhakaran
* 08/31/2022
* USD 248,337.00

People are encountering graphs, charts, and other visual representations of data
now more than ever before. Yet creators of these visualizations currently must
reason with sparse and conflicting evidence on how well people can read the
visualizations they publish. Current guidelines do not take into account the
possibility that different people have different strengths and weaknesses when
interpreting visual data. This project will use studies of visualization
effectiveness to inform our understanding of the abilities and biases of
viewers, both individually and collectively. To do this, the project team will
use a combination of experiments, statistical modeling, and interview studies to
both challenge long-standing assumptions about visualization effectiveness, and
to lay a foundation for future experiments that account for differences in
visualization reading ability. The work will also support a broader educational
goal of using robust statistical modeling techniques in experimentation, through
course modules that can be integrated into existing data visualization courses,
and through outreach activities that allow individuals to see how well they
perform visualization tasks compared to others who have taken the
experiments.&lt;br/&gt;&lt;br/&gt;This work seeks to answer three primary
research questions. The first is to determine the extent to which individuals
differ in their ability to perform basic tasks with data visualizations, through
large-scale crowdsourced experiments that use transparent statistical
methodologies to establish individual differences in data visualization
performance. The second question evaluates the relationship between low-level
visualization performance and higher-level assessments such as visualization
literacy and cognitive abilities, recruiting both expert and novice populations
to evaluate the extent to which these hypothesized measures of visualization
literacy correlate with each other. The third question determines how
alternative ways of presenting visualization experiment results shape the design
recommendations researchers and designers draw from them, through a comparative
evaluation of longstanding ways of presenting visualization experiment results,
and by designing new ways of presenting results that may lead to more mature
interpretation of experiment results by broader visualization community. The
work will provide new perspectives on visualization literacy by augmenting chart
reading experiments with novel measures of visualization ability, and by
studying how creators currently make use of existing visualization design
guidelines in their design process.&lt;br/&gt;&lt;br/&gt;This award reflects
NSF's statutory mission and has been deemed worthy of support through evaluation
using the Foundation's intellectual merit and broader impacts review criteria.