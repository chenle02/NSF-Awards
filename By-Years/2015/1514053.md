* 1514053
* III: Medium: Constructing Knowledge Bases by Extracting Entity-Relations and Meanings from Natural Language via "Universal Schema"
* CSE,IIS
* 09/01/2015,08/31/2020
* Andrew McCallum, University of Massachusetts Amherst
* Continuing Grant
* Hector Munoz-Avila
* 08/31/2020
* USD 1,000,000.00

Automated knowledge base (KB) construction from natural language is of
fundamental importance to (a) scientists (for example, there has been long-
standing interest in building KBs of genes and proteins), (b) social scientists
(for example, building social networks from textual data), and (c) national
defense (where network analysis of criminals and terrorists have proven useful).
The core of a knowledge base is its objects ("entities", such as proteins,
people, organizations and locations) and its connections between these objects
("relations", such as one protein increasing production of another, or a person
working for an organization). This project aims to greatly increase the accuracy
with which entity-relations can be extracted from text, as well as increase the
fidelity which many subtle distinctions among types of relations can be
represented. The project's technical approach -- which we call "universal
schema" -- is a markedly novel departure from traditional methods, based on
representing all of the input relation expressions as positions in a common
multi-dimensional space, with nearby relations having similar meanings. Broader
impacts will include collaboration with industry on applications of economic
importance, collaboration with academic non-computer-scientists on a
multidisciplinary application, creating and publicly releasing new data sets for
benchmark evaluation by ourselves and others (enabling scientific progress
through improved performance comparisons), creating and publicly releasing an
open-source implementation of our methods (enabling further scientific research,
easy large-scale use, rapid commercialization and third-party enhancements).
Education impacts include creating and teaching a new course on knowledge base
construction for the sciences, organizing a research workshop on embeddings,
extraction and knowledge representation, and training multiple undergraduates
and graduate students. &lt;br/&gt;&lt;br/&gt;Most previous research in relation
extraction falls into one of two categories. In the first, one must define a
pre-fixed schema of relation types (such as lives-in, employed-by and a handful
of others), which limits expressivity and hides language ambiguities. Training
machine learning models here either relies on labeled training data (which is
scarce and expensive), or uses lightly-supervised self-training procedures
(which are often brittle and wander farther from the truth with additional
iterations). In the second category, one extracts into an "open" schema based on
language strings themselves (lacking ability to generalize among them), or
attempts to gain generalization with unsupervised clustering of these strings
(suffering from clusters that fail to capture reliable synonyms, or even find
the desired semantics at all). This project proposes research in relation
extraction of "universal schema", where we learn a generalizing model of the
union of all input schemas, including multiple available pre-structured KBs as
well as all the observed natural language surface forms. The approach thus
embraces the diversity and ambiguity of original language surface forms (not
trying to force relations into pre-defined boxes), yet also successfully
generalizes by learning non-symmetric implicature among explicit and implicit
relations using new extensions to the probabilistic matrix factorization and
vector embedding methods that were so successful in the NetFlix prize
competition. Universal schema provide for a nearly limitless diversity of
relation types (due to surface forms), and support convenient semi-supervised
learning through integration with existing structured data (i.e., the relation
types of existing databases). In preliminary experiments, the approach already
surpassed by a wide margin the previous state-of-the-art relation extraction
methods on a benchmark task. New proposed research includes new training
processes, new representations that include multiple-senses for the same surface
form as well as embeddings with variances, new methods of incorporating
constraints, joint inference between entity- and relation-types, new models of
non-binary and higher-order relations, and scalability through parallel
distribution. The project web site
(http://www.iesl.cs.umass.edu/projects/NSF_USchema.html) will include
information on the project and provide access to data sets, source code and
documentation, teaching and workshop materials, and publications. In addition,
datasets will be disseminated via UCI Machine Learning Repository (or other
similar archive location for machine learning data) to facilitate sharing with
other researchers and ensure long-term availability, and GitHub will be used to
facilitate release, sharing, and archiving of code.