* 2213235
* SBIR Phase I:  Real-Time Artificial Intelligence (AI) Bidirectional American Sign Language (ASL) Communication System
* TIP,TI
* 02/15/2023,10/31/2023
* Nicholas Wilkins, SIGN-SPEAK Inc
* Standard Grant
* Peter Atherton
* 10/31/2023
* USD 256,000.00

The broader impact of this Small Business Innovation Research (SBIR) Phase I
project is to improve the communication between Deaf and Hard of Hearing (D/HH)
individuals and the hearing community through automated sign language
recognition. In the United States alone there are over 48 million D/HH
individuals, who in total possess $87 billion in purchasing power. It appears
businesses are not adequately serving this community, as is evidenced by the
plethora of Americans with Disabilities Act (ADA) lawsuits against numerous
companies. The proposed technology will provide plug-and-play software for
organizations to improve their interactions with D/HH individuals. Businesses
and governments will be able to interact with their D/HH employees, customers,
or constituents when interpreters are unavailable. This technology can be
integrated into a variety of platforms, from retail point-of-sale equipment to
chatbots and video/teleconferencing systems.&lt;br/&gt;&lt;br/&gt;This Small
Business Innovation Research (SBIR) Phase 1 project aims to develop technology
to perform unconstrained sign language recognition and natural sign language
production. Specifically, current methods to train language translation models
are ill-equipped to handle the sign language domain due to the lack of training
data within this domain. Additionally, all currently established methods (apart
from motion capture, which is unscalable) for producing American Sign Language
(ASL) result in stilted, unnatural signing from an avatar. This project will
develop solutions to these issues within the domain of ASL via semi-supervised
expert-augmented models and data augmentation techniques. Technical hurdles
include the lack of models to handle high-dimensional low-resource language
domains, and lack of sufficiently large datasets. Technical milestones include
creating semi-supervised datasets, engineering data augmentation techniques,
generating a natural signing avatar, and performing extensive usability testing.
This project aims to produce a method for automatically interpreting between a
low-resource sign language and English to improve accessibility and increase
equity for the Deaf and Hard of Hearing communities.&lt;br/&gt;&lt;br/&gt;This
award reflects NSF's statutory mission and has been deemed worthy of support
through evaluation using the Foundation's intellectual merit and broader impacts
review criteria.