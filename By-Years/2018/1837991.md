* 1837991
* BIGDATA: F: Compositional Learning, Maps and Transfer: Statistical and Machine Learning on Collections of Data Sets
* CSE,IIS
* 01/01/2019,12/31/2022
* Mauro Maggioni, Johns Hopkins University
* Standard Grant
* Sylvia Spengler
* 12/31/2022
* USD 700,000.00

One of the landmarks of human intelligence is the ability to not only find
solutions to hard problems, but to learn from past experiences and accumulate
knowledge that may be (partially) transferred for quickly solving new problems.
This project will develop novel foundational techniques for learning
compositional rules, from collections of data sets and machine learning
problems. The building blocks that the investigator will develop enable sharing
of learning across multiple data sets and modalities. A first building block
will enable machine learning algorithms to store solutions to past problems and
use maps and abstractions to transfer knowledge to new problems. This requires
efficient techniques for learning maps, how to compose them to enable knowledge
transfer, all in a way that is compatible with the representation of the
problems and their solutions, which also need to be automatically learned. These
ideas will be tested on problems ranging from object and pattern recognition of
images to behavior of interacting agent systems, from fusing data sets acquired
with different sensors to controlling virtual and real agents. This project will
provide general, foundational results in machine learning, which can be applied
to applications in virtually any domain of human endeavor.
&lt;br/&gt;&lt;br/&gt;The investigator will develop new techniques focused on
representation and transfer learning, in particular: (i) Compositional Learning:
the ability to learn and factorize through composition maps between data sets,
and of functions (for classification and regression tasks) on data sets (e.g.
the task f may be learned by using the map h to one data set on which learning
already occurred and the already-learned function g on that data), in order to
enhance both learning rates, knowledge extraction and transfer across data sets
and data types; (ii) Map Learning: the ability to efficiently learn, represent,
store, recall and apply maps between complex data sets, possibly of different
modalities; but also learn maps that transform, at least approximately, one task
into another, and transfer knowledge from one task to another; (iii)
Representation Learning: the ability to learn how to efficiently represent,
store and recall complex data sets, across multiple sensor modalities, and
across different levels of abstractions -- for example, learning efficient
representations of data from multiple types of sensors, learning of classifiers
and regression functions, or learning interaction kernels in agent-based
systems, as well as transfer those functions across sensor modalities, data
sets, dynamical systems. While advancing current state of art techniques in each
of these learning abilities, the research will tackle applications in learning
invariances and performing object recognition tasks in images, detecting whether
objects in an image are new or known, learn interaction rules from observing
trajectories of interacting agent systems, and implement the ideas of
compositional learning in the context of learning systems both virtual (for
examples, using the OpenAI challenges) and real (for example, using robots), on
sequences of tasks of increasing difficulty.&lt;br/&gt;&lt;br/&gt;This award
reflects NSF's statutory mission and has been deemed worthy of support through
evaluation using the Foundation's intellectual merit and broader impacts review
criteria.