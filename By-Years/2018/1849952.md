* 1849952
* CRII: RI: Active Learning of Preferences for Human-Aware Autonomy
* CSE,IIS
* 06/01/2019,11/30/2022
* Dorsa Sadigh, Stanford University
* Standard Grant
* Juan Wachs
* 11/30/2022
* USD 175,000.00

Humans' preferences play a key role in specifying how robotics systems should
act, i.e., how an assistive robot arm should move, or how an autonomous car
should drive. The learned human preferences are an important element in planning
for interactive autonomous systems, e.g., robots collaborating with different
types of human teammates, or shared autonomy with a human to efficiently
teleoperate a robot arm. One hopes that learning techniques can be used to learn
reward functions representing humans' preferences for robotics applications.
However, a significant part of the success of learning algorithms can be
attributed to the availability of large amounts of labeled data. Unfortunately,
collecting and labeling data can be costly and time-consuming in robotics
applications. In addition, humans are not always capable of reliably assigning a
success value (reward) to a given robot action, and their demonstrations are
usually suboptimal due to the difficulty of operating robots with more than a
few degrees of freedom. The proposed research develops foundational techniques
to address the key challenges of using learning techniques in human-robot
interaction. &lt;br/&gt;&lt;br/&gt;The goal of this project is to develop
efficient methods and algorithms to first better model and understand humans
preferences while operating, interacting, and collaborating with robots.
Furthermore, the investigator will design algorithms that plan for robots that
are aware of such preferences and can initiate a safe and seamless interaction
with humans. This project involves two main contributions: (1) Developing
efficient and active algorithms to learn probabilistic mixture models for humans
preferences about how a robot should operate based on comparisons and rankings.,
and (2) Developing planning algorithms for robots that leverage humans
preferences to enable seamless shared autonomy and more efficient human-robot
interaction. Preliminary results in the domain of autonomous driving suggest
that one can learn driving preferences of humans and this approach can improve
efficiency and safety of robotics systems.&lt;br/&gt;&lt;br/&gt;This award
reflects NSF's statutory mission and has been deemed worthy of support through
evaluation using the Foundation's intellectual merit and broader impacts review
criteria.