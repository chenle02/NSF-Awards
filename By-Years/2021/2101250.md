* 2101250
* AstroSLAM - A Robust and Reliable Visual Localization and Pose Estimation Architecture for Space Robots in Orbit
* CSE,CCF
* 10/01/2021,09/30/2024
* Danfei Xu, Georgia Tech Research Corporation
* Standard Grant
* Peter Brass
* 09/30/2024
* USD 792,864.00

Space robotics is essential for all current and future space exploration and
utilization missions. Advanced space-robotic technologies will enable in-orbit
servicing and refueling of satellites, and will support more elaborate missions
such as in-orbit large flexible structure assembly, debris removal, inspection,
hardware upgrades, etc. For instance, current communication satellites have a
typical lifetime of 10 to 15 years, at which point an otherwise perfectly
functioning satellite runs out of propellant and is decommissioned. Refueling
the satellite can add several years of additional lifetime and revenue. Future
envisioned missions to the Moon, Mars and beyond will also require advanced
robotic capabilities in orbit. Many future exploration missions envision
integrated teams of astronauts and free flying “co-robots” that support or
monitor the human crew activities. What is currently missing from these missions
is the ability to provide full 4D (space-time) situational awareness using
autonomous on-board perception and planning capabilities. Recent technological
breakthroughs for ground robots pave the way for similar advancements in robotic
in-orbit operations to enable routine robotic operations in space in the not-so-
distant future. These include perception and planning algorithms, machine
learning based pattern recognition, autonomy, new computer hardware
architectures, human-machine interfaces, and dexterous manipulation, among many
others. The outcome of the research will be the ability of astronauts and space
robots to work together to enable inspection, monitoring, and classification of
resident space objects; maneuvering and proximity operations and docking;
salvage and retrieval of malfunctioning or tumbling spacecraft; and servicing,
construction, repair, upgrade, and refueling missions of assets in
orbit.&lt;br/&gt;&lt;br/&gt;This project will develop novel visual perception,
localization, mapping, and planning algorithms that will enable new capabilities
in terms of situational awareness for space robots that can work alone or
alongside astronauts in orbit. The research plan includes the development of
novel automated feature extraction and matching algorithms using deep neural
network architectures, adapted to the challenging imaging conditions (collimated
light, high contrast, lack of atmospheric scattering, paucity of distinctive
features, etc.) and orbital motion constraints imposed in space. This will
enable robust and reliable relative pose estimation, 3D shape reconstruction and
characterization of space objects. Novel optimal planning and prediction methods
based on a factor-graph optimization framework will be matched to these new
perception capabilities to account for fuel usage and orbital motion
constraints. The experimental validation of the theory will take place at the
Georgia Tech Autonomous Spacecraft Testing of Robotic Operations in Space
platform, a state-of-the-art spacecraft simulation platform. The research will
involve both graduate and undergraduate students. The results of this research
will be disseminated to the community by journal and conference publications,
organization of invited workshops and seminar presentations, and by targeted
exposure (press releases, interviews) to popular
media.&lt;br/&gt;&lt;br/&gt;This project is supported by the cross-directorate
Foundational Research in Robotics program, jointly managed and funded by the
Directorates for Engineering (ENG) and Computer and Information Science and
Engineering (CISE).&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.