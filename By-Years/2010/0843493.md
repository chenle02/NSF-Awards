* 0843493
* RUI:  A Common Cognitive Foundation for Rhythm in Music and Speech
* SBE,BCS
* 03/01/2009,02/28/2013
* John Neuhoff, College of Wooster
* Standard Grant
* William Badecker
* 02/28/2013
* USD 38,371.00

Music and speech have long been thought to have common cognitive underpinnings,
and recent research has shown that the music of expert composers tends to
reflect the speech rhythms of their native language. However, simple music
production is generally a more common undertaking, practiced by a much larger
proportion of society than just expert composers. Moreover, experts have an
elaborate cognitive and neural framework for music that enables them to
perceive, organize, and produce music in ways that novices can not. This project
will investigate the hypothesis that in the absence of this musical expertise,
music novices have music-speech connections that are even more tightly bound to
language than those shown in experts. In other words, the lack of a specific
cognitive framework for music may force novices to rely more heavily on speech
rhythms when they produce simple rhythmic tunes. In a series of experiments
examining the perception and production of music rhythm by experts and novices,
this project explores the proposition that music-speech connections in rhythm
are stronger and far more widespread than have been previously shown.
&lt;br/&gt;&lt;br/&gt;The examination of a common rhythmic foundation for music
and speech has received relatively little attention in the scientific
literature, particularly when compared to pitch processing. In the pitch domain,
for example, important discoveries have been made with respect to how the tonal
qualities of music and speech are processed and the apparent specialization of
the right and left auditory cortices in processing music and speech
respectively. Our corresponding knowledge of commonalities in music and speech
rhythm processing lags significantly behind. Nonetheless, there is emerging
evidence of interplay between music and speech in both perception and
production. Music has been shown to be an effective aid in language acquisition,
and language learning has conversely been shown to enhance statistical learning
of musical stimuli. However, the role that rhythm processing plays in the
interplay between music and speech is still unclear. Thus, our ability to
capitalize on these links in areas such as speech therapy or stroke
rehabilitation is limited. This project will begin to provide a theoretical
foundation for our knowledge of this linkage and will provide important insights
into the common underpinnings of music and speech.