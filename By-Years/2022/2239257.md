* 2239257
* CAREER: Exploring and Exploiting Data-Centric Modeling for Fairness in Machine Learning
* CSE,IIS
* 05/01/2023,04/30/2028
* Na Zou, Texas A&M Engineering Experiment Station
* Continuing Grant
* Sylvia Spengler
* 04/30/2028
* USD 219,303.00

This project will lead to advances in dealing with data challenges to facilitate
fairness in machine learning, promote broad utilization of machine-learning
algorithms in high-stake applications, and ensure a fair and transparent
decision-making process for future information systems. While machine-learning
methods have achieved success in real-world applications, they often suffer from
biases and show discrimination towards certain demographics especially in high-
stakes applications, which risks significant harm to both society and
individuals. Existing work focuses on “model-centric” computational approaches
that build models while overlooking the importance of data quality. To tackle
the challenges raised by the lack of high quality data and the lack of a
comprehensive understanding of fairness in all its respects, this project will
integrate model-centric with “data-centric” modeling, which systematically
engineers the data needed for a fair decision-making process. The successful
outcome of this multidisciplinary research will lead to effective and efficient
algorithms that enhance the generalizability and trustworthiness of learned
models, and improve the fairness of algorithms deployed in real-world systems in
health informatics and disaster resilience. The education programs of this
project will play an integral part in training the next generation of the U.S.
workforce with critical Responsible Artificial Intelligence (RAI) technologies
and attract and retain diverse members of the future workforce in STEM.
&lt;br/&gt;&lt;br/&gt;The research goal of this project is to develop a
computational framework for tackling data challenges in fairness through data-
centric fairness mitigation solutions that explore and exploit data and prior
knowledge. Complementing existing studies focusing on model-centric or data-
driven approaches, this project investigates a novel research direction that
systematically explores a data-centric fairness mitigation framework.
Specifically, the research objectives include: (1) to explore and extract data
characteristics on instances, features and a representative subset of examples
in terms of fairness, allowing that fairness definitions and metrics may vary
across real-world applications; (2) to expand and refine prior knowledge to
guide the discrimination-mitigation process via instance augmentation, feature
set expansion, and measurement redefinition perspectives; (3) to leverage
interpretable and interactive data and prior knowledge as a key element for
further improving fairness modeling; and (4) to demonstrate effectiveness on
real-world applications including healthcare informatics and disaster
resilience. The educational objectives are: (1) to incorporate responsible
artificial intelligence (RAI) into curriculum design via integrating research
findings and case studies into current and new courses; (2) to enhance public
interest in and awareness of RAI by organizing data challenges and broadcasting
information on social media platforms; and (3) to attract and retain women and
underrepresented minorities to ensure a diverse future STEM
workforce.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.