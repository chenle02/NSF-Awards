* 0957016
* Context-based Indoor Object Detection
* CSE,IIS
* 09/15/2009,08/31/2013
* YingLi Tian, CUNY City College
* Standard Grant
* Jie Yang
* 08/31/2013
* USD 133,671.00

Robust and efficient indoor object detection can help people with severe vision
impairment to independently access unfamiliar indoor environments. However, most
existing object detection methods are developed either for a specific type of
object (e.g. face) or for general nature objects (e.g., building, sky, etc)
which cannot be directly applied to indoor objects due to following challenges:
1) big inter-class variations of the object model among different indoor
environments, 2) small intra-class variations of different object models, 3)
less texture compared to objects in natural scene or outdoor environments, 4)
only part of the object is captured due to occlusions or blind user, 5) view and
scale variations of the objects caused by the position and distance change
between the user and the object, and 6) lack of suitable databases.

This EAGER project is to explore new methods to detect indoor objects by
incorporating the context information from signs (both text and iconic) and
other visual clues such as signage of bathrooms and elevator floor numbers. The
research enriches the study of object detection by incorporating context
information, and leads to significant improvements over existing methods. The
methods developed in this project provide new strategies and technologies for
the blind and visually impaired to access unfamiliar indoor environments. The
research also benefits many important research areas including video
surveillance, intelligent conference rooms, video indexing, and human-computer
interactions.