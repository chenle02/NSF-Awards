* 2311983
* SHF: Medium: Language Support for Sound and Efficient Programmable Inference
* CSE,CCF
* 10/01/2023,09/30/2027
* Jan Hoffmann, Carnegie-Mellon University
* Continuing Grant
* Anindya Banerjee
* 09/30/2027
* USD 500,000.00

The goal of this project is to make powerful Bayesian models and inference
algorithms more usable, accessible, and reliable in challenging data science
problems. Bayesian inference provides a principled approach to learning
probabilistic models by combining prior modeling assumptions with observed data.
It enables state-of-the-art results in problems from diverse areas including
biostatistics, robotics, computational physics, quantitative finance, cognitive
science, and machine learning. Advantages of Bayesian inference include the
ability to incorporate prior domain-specific knowledge, to quantify uncertainty
about parameters and predictions, and to generalize well to novel data. A key
challenge, however, is correctly implementing and diagnosing Bayesian inference
algorithms, especially those that target sophisticated probabilistic models. The
project's novelty is to address this challenge by developing rigorous
programming-language techniques that make sound and effective Bayesian inference
more easily applicable. The project's impact is to boost the development and
exploration of more flexible Bayesian methods among researchers and help domain
experts more reliably leverage these technologies for real-world problems.

The research plan of the project builds on probabilistic programming languages
(PPLs) such as Stan, Gen, and Pyro, which provide interfaces that cleanly
separate model development from the specification of the corresponding inference
algorithm. To make Bayesian learning feasible for more flexible models and
larger data sets, several PPLs have enabled users to write custom probabilistic
inference algorithms through "programmable inference" interfaces that automate
many complex computations needed to develop effective inference algorithms.
However, it is easily possible for users to accidentally write incorrect
inference programs in such a way that breaks convergence and leads to unsound
results. Even worse, such mistakes often go unnoticed. The research in this
project aims to alleviate the fundamental tension between soundness and
flexibility of programmable inference by (1) applying new programming-language
techniques such as static analysis and type systems to verify whether a user-
written inference program satisfies theoretical conditions for soundness; and
(2) developing new dynamic statistical program analyses to empirically assess
the quality of approximate posterior samples produced from the sound inference
program. In this way, the system ensures that approximate inference algorithms
are not only soundly implemented but are also effective for a given problem in
practice. The practicality of the developed techniques is validated through
evaluations on challenging data science problems. Moreover, the research results
are integrated in the graduate and undergraduate education at Carnegie Mellon
University.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.