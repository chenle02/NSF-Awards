* 0313184
* ITR/NGS:  Stochastic Multicue Tracking of Objects with Many Degrees of Freedom
* CSE,CNS
* 09/01/2003,08/31/2007
* Dimitris Metaxas, Rutgers University New Brunswick
* Continuing Grant
* David Du
* 08/31/2007
* USD 399,999.00

The dynamic data driven estimation of 3D human shape and motion from optical
sensors (cameras)&lt;br/&gt;is a fundamental problem that has many applications
such as non-invasive security and monitoring&lt;br/&gt;systems and human-
computer interaction. The difficulty of the problem stems from a) the
shape&lt;br/&gt;complexity and the many degrees of freedom due to the high
articulation and deformations of the&lt;br/&gt;human body, b) the noise
introduced by the sensors, c) the dynamically changing appearance of
the&lt;br/&gt;human body in an image sequence in terms of shape and intensity,
and d) the unknown distributions&lt;br/&gt;of the visual cues (e.g., edges and
optical ow) and the lack of a principled methodology of how to&lt;br/&gt;combine
them. Lagrange dynamics-based 3D deformable models have the potential of being
successful in analyzing the shape and motion of non-rigid or articulated data
such as the face and hands since they&lt;br/&gt;can adapt to the shape and
motion variations across individuals. This proposal aims to develop a deformable
model-based framework for human shape and motion estimation which can cope with
the dynamic changes of the input visual data and the resulting need for the
dynamic integration of visual cues extracted from the input data. Our proposed
approach should be able to evaluate automatically and dynamically the
\trustworthiness" of each visual cue and integrate subsequently the cues in a
manner that reects their importance. The methods that are proposed here are
general and are not only applicable to&lt;br/&gt;face/hand tracking but to whole
body tracking.