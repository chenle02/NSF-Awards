* 2047224
* CAREER: Foundations for Fair Social Network Analysis
* CSE,IIS
* 10/01/2021,09/30/2026
* Sucheta Soundarajan, Syracuse University
* Standard Grant
* Sylvia Spengler
* 09/30/2026
* USD 601,376.00

An increasing amount of decision making is influenced by algorithms, and while
this has resulted in clear benefits to society, the possible harms are starting
to become apparent. In a striking example of such harms, recent works have
argued that use of algorithms can perpetuate or create new forms of unethical
discrimination. The area of social network analysis, in which individuals
interact with one another through a complex set of connections, contains many
worrisome applications. For example, some credit scoring companies use social
network data (e.g., friends and family connections) to assign credit scores to
individuals; and in such applications, it is important to ensure that the
algorithms used in such a process are not inadvertently discriminating against
individuals on the basis of protected attributes like race or sex. In this
project, the investigator will develop algorithms for the area of fair social
network analysis. The goal of fair social network analysis is to understand how
network structure and network algorithms may lead to systematic harm against
groups of individuals, and to propose remedies for such cases. This project is
among the first in the area of fair social network analysis, and its
contributions will be of value to both practitioners and researchers working
with network data. The resulting algorithms may be used in applications like
online advertisement targeting and social media friendship recommendation. In
addition to the scientific objectives of the project, the investigator will
conduct activities related to course development in the area of ethical
algorithm design, co-development of Continuing Legal Education seminars for
attorneys (focusing on ethics of algorithms), outreach to local rural students,
and development of a handbook on guidelines for technologists working with
community organizations.&lt;br/&gt;&lt;br/&gt;While there is a growing body of
research on fairness in machine learning, existing methods do not consider
dependencies between points, and so do not apply to network tasks like link
prediction or community detection. The project will contain three tasks. In the
first task, the investigator will design tests for determining whether
unfairness exists in a network structure or network analysis. In the second
task, the investigator will design algorithms to reduce the unfairness in
network analysis. In the third task, the investigator will design algorithms for
modifying a network to reduce unfairness in its structure. The main
contributions of this project will be (1) Development of formal definitions of
fairness in networks, (2) Creation of algorithmic tests to detect unfairness in
network structure, (3) Design of tests to determine reliance of a network
analysis algorithm on a particular attribute, (4) Development of algorithms to
mitigate such reliance, and (5) Development of algorithms to modify a network to
reduce wrongful bias. Education and outreach activities include course
development in algorithmic design, and engagement with the legal community and
community organizations.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.