* 1657599
* CRII: CHS: Data-Driven Automation of Color Encodings for Data Visualization
* CSE,IIS
* 09/01/2017,02/29/2020
* Danielle Szafir, University of Colorado at Boulder
* Standard Grant
* Ephraim Glinert
* 02/29/2020
* USD 174,855.00

Graphs, charts, and other visualizations of data rely on color both to convey
key aspects of the underlying data and to attract and engage viewers. Getting
both the accuracy and aesthetics of color choices right, however, is hard, and
most existing tools for helping designers focus on just one of the two.
Developing accurate color mappings is even harder because how colors are
perceived changes depending on the size and shape of visual marks, lighting and
contrast, and a number of other factors. In this project, the research team will
use designs created by existing tools to construct an initial statistical model
of color mappings that captures expert designers' current decision-making. They
will then improve those models by creating visualizations based on the models,
altering size, shape, contrast, and lighting, and testing how well people can
use those designs to learn the underlying values of the data. Finally, the team
will create a design tool that allows both expert and non-expert designers to
create visualizations, choosing anchor colors and aspects of the visualization,
and generating color maps that are most accurate and aesthetic based on the
models and the designer's choices. The work will lead to more accurate models of
perception and mechanisms for choosing color maps that capture both design
expertise and perceptual accuracy; this, in turn, will lead to practical
improvements in the effectiveness of data visualizations that are increasingly
part of people's experience. The team also plans to increase the accessibility
of data visualizations by helping designers choose color mappings that are more
usable by people with color-blindness, while making the tools themselves more
usable by color-blind people. The tools and work will also be integrated into
several courses on human-computer interaction and data science at the lead
investigator's institution, benefiting students from a variety of research
groups and departments.

Color ramps will be represented as a set of control points (two end points in
sequential encodings and two end points plus a midpoint in diverging ramps) that
determine the overall structure of the ramp, and a smooth interpolation path
that connecting the control points in colorspace. To capture current expert
practice, the team will first extract initial color ramps from colormaps
available in existing design-based visualization tools, using the CIELAB
colorspace to model the statistical characteristics of the control points and
interpolation paths of these encodings, generating aesthetic constraints
grounded in the current design consensus. The team will then use crowdsourcing
platforms, which have been shown to be effective for a number of perceptual and
visualization experiments, to systematically study how specific aspects of
visualization design including mark shape, mark size, and visualization type,
affect people's ability to detect color differences in colorspace; further,
conducting the experiment online means this model will be specifically tailored
to the online/web/screen viewing context. This empirical model can enforce
perceptual constraints imposed by visualization design choices on the color
ramps generated by the aesthetic models by constraining and repositioning
control points. Finally, these models will be integrated into a publicly
available color authoring system that will be validated through use in courses
at the lead researcher's institution and at design workshops with the local
community. In addition to developing the specific models and tools around color
encodings, the work sets up a broader research agenda of combining automation
and interaction, in which semi-automated guidance democratizes effective
visualization practice and allows people to leverage prior designs and create
new representations without requiring extensive visualization training.