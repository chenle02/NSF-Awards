* 1252835
* CAREER: Learning Scalable Models for Grounded Semantic Parsing
* CSE,IIS
* 09/01/2013,08/31/2020
* Luke Zettlemoyer, University of Washington
* Continuing Grant
* D.  Langendoen
* 08/31/2020
* USD 500,000.00

One core challenge in natural language research is to do robust, wide coverage
semantic analysis. Recently, there has been progress towards solving this
problem by developing algorithms for learning semantic parsers that map
sentences to rich, logical representations of their meaning. State-of-the-art
approaches have reached the level where they can, with sufficient training data,
be used to learn highly accurate parsers for many different natural languages on
a number of benchmark problems. However, the general applicability of this work
has been limited by the focus on somewhat idealized conditions, where the
application domain is of limited size, sentences are analyzed in isolation, and
there is an exclusive focus on database query
applications.&lt;br/&gt;&lt;br/&gt;This CAREER project aims to build a framework
for grounded semantic parsing that solves these challenges by reasoning about a
sentence's possible meanings given its linguistic and situated context. This
type of reasoning is necessary for extending existing learning approaches to
fundamentally new applications, such as conversational understanding. However,
it is also be crucial for the next generation of semantic parsers that learn
from easily gathered data and scale to domains that are several orders of
magnitude more complex than previously considered.&lt;br/&gt;&lt;br/&gt;The
project will extend the PI's educational and outreach efforts, including the
creation of freely shared online content for introductory and advanced semantics
topics. It will also enable new initiatives by the PI to increase diversity in
computer science study and research, by supporting efforts to motivate students
through early exposure to exciting language understanding problems.