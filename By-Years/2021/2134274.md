* 2134274
* Collaborative Research: SCALE MoDL: Representation Theoretic Foundations of Deep Learning
* MPS,DMS
* 01/01/2022,12/31/2024
* Qi Yu, University of California-San Diego
* Continuing Grant
* Yong Zeng
* 12/31/2024
* USD 203,917.00

In the past decade, deep learning has had transformative impacts across society.
However, progress has often relied on heuristic methods, massive data, and great
computing power. This comes with limited theoretical understanding and has at
times given rise to failures of generalization and vulnerable performance in
extreme scenarios. This project will address these limitations by developing
strong theoretical foundations for deep learning using representation theory,
which is the mathematical study of symmetry. Symmetry plays a key role in human
reasoning. Greater understanding of the role symmetry plays in deep learning
will unlock a variety of improved models. These include models that can learn
from scientific knowledge and not just raw data, models with trustable,
guaranteed performance, and models that can recombine patterns they have already
learned — as humans do easily — to generalize to new situations more rapidly. An
explicit goal of this project is to broaden research into why deep learning
works. To this end, the investigators will integrate the research into education
and establish a mentorship program for high school students from groups
underrepresented in science.&lt;br/&gt;&lt;br/&gt;The goal of the research is to
understand the role of representation theory in enabling efficient optimization
and improved generalization of deep learning even in domains with approximate or
unknown symmetry. This project pursues three lines of research that will broaden
the impact of representation theory in deep learning beyond strict inductive
biases. The first is the trade-off between the degree of symmetry in the model
and the degree of symmetry in the domain. This line of research will study
networks that combine equivariant and non-equivariant features. The second line
of research will examine learning symmetry directly from data to improve
generalization in domains without known symmetries. The third aim is to develop
a theoretical basis for deep learning using quiver representations. This
perspective reveals the symmetry of the structure of deep-learning models
themselves, through their parameter spaces, even when the domains have no
obvious symmetry.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.