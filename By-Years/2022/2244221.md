* 2244221
* Collaborative Research: SaTC: EDU: Fire and ICE: Raising Security Awareness through Experiential Learning Activities for Building Trustworthy Deep Learning-based Applications
* EDU,DGE
* 07/01/2023,06/30/2026
* Yan Huang, Kennesaw State University Research and Service Foundation
* Standard Grant
* ChunSheng Xin
* 06/30/2026
* USD 44,734.00

In privacy-sensitive and safety-critical applications, deep learning models are
increasingly accepted and utilized. This trend is bound to continue: many open-
source frameworks and tools from online code repositories are embedded with deep
learning modules. However, many deep learning models contain hidden weaknesses
that could be exploited by attacks, posing significant risks to user privacy and
safety. It is essential, therefore, to raise security awareness among college
students, who are the future data engineering practitioners, and equip them with
knowledge and strategies for designing trustworthy, deep learning based
applications. &lt;br/&gt;&lt;br/&gt;This project responds to the urgent need in
three critical areas: integrity, confidentiality and equity (ICE). A series of
easy-to-implement experiential learning activities concretize learners’
awareness of potential vulnerabilities in deep learning models and enhance their
ability to build secure applications of their own. These activities are
expressly designed for learners with little prior knowledge, and are streamlined
to reduce preparation time and cost for the instructor. The activities’
flexibility maximizes the equitable dissemination of relevant knowledge that is
critical to society. The investigators are especially mindful of the needs of
minority and socio-economically disadvantaged student
populations.&lt;br/&gt;&lt;br/&gt;A total of twelve learning activity sets
address a wide array of issues arising in ICE areas. For data integrity, threats
posed by adversarial examples, data poisoning, and backdoor hidden features are
tackled. The emphasis on experiential learning allows learners to become
acquainted with the process and effects of attacks before learners are equipped
with strategies and trained to implement proper defense. To enhance
confidentiality, learners first encounter at least two potential sources of
privacy leakage, dataset overfitting and abusive querying, and are then taught
preventative countermeasures. Both sample biases and algorithmic biases in deep
learning models are addressed in the learning activities.
&lt;br/&gt;&lt;br/&gt;Artificial intelligence and deep learning constitute a
fast-developing field, and educators must keep pace. The project enriches the
supply of educational tools by introducing recent discoveries in the field,
including those made by the investigators themselves.&lt;br/&gt;&lt;br/&gt;This
award reflects NSF's statutory mission and has been deemed worthy of support
through evaluation using the Foundation's intellectual merit and broader impacts
review criteria.