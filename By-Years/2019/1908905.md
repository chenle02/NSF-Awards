* 1908905
* CIF: Small: Towards Robust Statistical Learning: Theory and Algorithms
* CSE,CCF
* 10/01/2019,09/30/2023
* Stanislav Minsker, University of Southern California
* Standard Grant
* Alfred Hero
* 09/30/2023
* USD 351,331.00

Machine learning algorithms are used to automate various tasks by finding
patterns in the existing data. The mathematical analysis of machine learning
algorithms starts by assuming that the available dataset is described by a model
with certain properties. However, as real-world data often do not satisfy the
model assumptions exactly, there is a need to reduce the gap between the
"mathematical" and "real" worlds by weakening the mathematical assumptions. The
concept of robustness plays a central role in understanding this gap. First, the
project will formulate principles for building robust algorithms. The project
will then apply these principles to address problems related to the existence of
mathematically justified and computationally efficient robust methods for
prediction and classification tasks, which are among the most popular problems
solved by machine learning algorithms. The project will also support
undergraduate research by training students to apply advanced methods to the
analysis of modern data sets. Additional efforts will be made to establish
closer ties between the academic and industry machine learning research
communities. &lt;br/&gt;&lt;br/&gt;One part of the project is devoted to robust
empirical risk minimization. Empirical risk minimization is one of the
fundamental concepts underlying modern mathematical statistics and statistical
learning algorithms, including regression and maximum likelihood estimation.
However, empirical risk minimization is not robust in many scenarios, with a
single "atypical point" amongst the observations possibly significantly
affecting performance. The work done in the course of this project will lead to
algorithms that avoid explicit outlier detection and removal, and which instead
take advantage of existing or purposefully induced symmetries in the
distribution of the data. The analysis of these new algorithms will require the
development of novel techniques related to Bahadur-type representations of
robust estimators, and of new generalizations of the median-of-means principle.
Another part of the project aims at developing robust modifications of the
Federated Learning algorithm, originally designed as a communication-effective
alternative to the standard centralized datacenter framework. The project will
design new and robust versions of the Federated Learning algorithm that provably
work in the challenging scenario where the input data have different
distributions. Finally, the investigator will address inferential problems in
robust learning by devising robust versions of posterior distributions that are
central objects in Bayesian statistics; he will study the Bernstein-von Mises
theorem for these robust posteriors, a fundamental result connecting the
frequentist and Bayesian methods.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.