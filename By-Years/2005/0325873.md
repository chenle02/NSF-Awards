* 0325873
* ITR/NGS: Automatic Performance Tuning for Large Scale Scientific Applications
* CSE,CNS
* 03/01/2004,02/28/2009
* James Demmel, University of Tennessee Knoxville
* Continuing Grant
* Anita La Salle
* 02/28/2009
* USD 1,550,000.00

Simulation has become a critical component of the scientific method, with the
resulting demands for&lt;br/&gt;computational power continually pushing the
limits of available hardware. Scientific applications need to&lt;br/&gt;be tuned
to acheive high efficiency, but hand tuning by application scientists cannot
keep pace with the ever changing features of the underlying hardware. It is not
uncommon for applications that involve a large amount of communication or memory
operations relative to computation to run at under 10% of the peak performance
of a machine. The goal of the project is to address the widening gap between
peak performance of computers and attained performance of real applications by
developing several innovative approaches to address such challenges. Namely:
design new automatic tuning techniques for dense linear algebra, sparse linear
algebra, and inter processor communication kernels; target emerging
architectures of importance to the high performance computing community,
including commodity processors with SIMD extensions, clusters, vector
processors, and highly parallel machines; develop an intermediate representation
and compilation model for these operations that will allow tuning of new
operations to be incorporated into compilers and programming systems; deliver
these capabilities to users by integrating them into languages (Matlab, UPC,
Titanium); and explore the impact of new kernels on higher level algorithm
design.&lt;br/&gt;&lt;br/&gt;The project will deliver tuned kernels to users
through standard libraries (BLAS, LAPACK, MPI, ScaLAPACK, PETSc) as well as
parallel languages designed to make high end machines more accessible (UPC and
Titanium), and will evaluate the impact of our work on large scale scientific
applications that use these systems.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;