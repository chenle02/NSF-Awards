* 2147694
* Collaborative Research: SaTC: CORE: Medium: Foundations of Trust-Centered Multi-Agent Distributed Coordination
* CSE,CNS
* 06/15/2022,05/31/2026
* Stephanie Gil, Harvard University
* Standard Grant
* Phillip Regalia
* 05/31/2026
* USD 489,462.00

This project will develop the theoretical foundations of trust-centered
resilience for distributed coordination and optimization of multi-agent systems
in the presence of adversaries. The resilience is to be achieved by agentsâ€™
learning trustworthiness of their neighbors through local communications, which
allows them to mitigate the detrimental impact of adversarial actions. In
particular, the agents can identify and isolate the adversaries and, thus, the
agents are able to sustain the desired system performance. Such resilient
autonomous multi-agent systems are likely to play an important role in the
future deployment of autonomous vehicle fleets, automated delivery systems (such
as robots and drones), as well as physical and connected devices in our
homes.&lt;br/&gt;&lt;br/&gt;The approach is to establish the theoretical
foundations and analytical framework for efficient exploitation of stochastic
"side information" found in the network, in order to arrive at provably stronger
guarantees of resilience for multi-agent optimization problems. Malicious
actions are addressed through probabilistic link-corruption models, which
provides an important separation between the attack and its impact on the
system. This separation is critical as it enables the development of trust
models using statistical inference techniques. The resulting model is suitable
for studying the impact of corrupted data on the resilience of multi-agent
coordination and optimization tasks. The focus in this work is on deriving
resilient distributed optimization algorithms and resilient consensus protocols
that can tolerate more than half of the network connectivity being malicious; a
classical requirement that this project aims to relax. Specific objectives of
the project are to develop methods for distributed detection of an attack,
attack mitigation, and characterization of attainable performance guarantees in
the presence of adversaries. The contribution is a unified theory for
understanding how inter-agent communications can be used to detect and isolate
malicious agents, while provably quantifying their impact on system
performance.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission
and has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.