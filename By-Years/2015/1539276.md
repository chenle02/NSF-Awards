* 1539276
* Collaborative Research: Neural-Cognitive Analysis of spatial scenes with competing, dynamic sound sources
* SBE,BCS
* 09/01/2015,08/31/2019
* Jonas Braasch, Rensselaer Polytechnic Institute
* Standard Grant
* Kurt Thoroughman
* 08/31/2019
* USD 335,598.00

This project investigates neurocognitive mechanisms that extract important
information from a mixture of sound sources. Imagine a day where you could no
longer distinguish the honking horn of a car coming right at you from other
street sounds. This cognitive ability to attend to one sound source while
ignoring others presents an everyday challenge for people with hearing
impairments. While the basic neural mechanisms for detecting and localizing
single sounds are known, we do not know how the brain accomplishes auditory
scene analysis with multiple sound sources. So far, studies have focused on
lower brain centers in rodents and carnivores, while the neural mechanisms for
source segregation are expected to be at higher levels, in the auditory cortex.
This study will record the responses of single cortical neurons and conduct
human-subject experiments for the same acoustic scenarios. Based on the
integration of these results, a functional auditory model will be developed.
This will provide new scientific insights and enable intelligent algorithms for
hearing aids, social robotics, and surveillance systems. The project will
provide research opportunities for graduate and undergraduate students and
include outreach activities and online learning resources for high-school and
college students to increase the public awareness of neuroscience. The research
results and the model will be shared with the academic community.

This proposal will use an interdisciplinary approach to gain understanding of
the central mechanisms of auditory scene analysis by integrating
psychoacoustical experiments with single-unit electrophysiology. The study will
investigate how the auditory system localizes a target sound temporally embedded
in a spatially separated masker. Single-unit recording will target the caudal
region of the auditory cortex, the putative "where" pathway for complex sound
analysis. We hypothesize that cortical activity represents both the old and new
sounds, so that the internal representation of the "old" masking source can be
subtracted from the overall mixture. This facilitates a clearer perception of
the "new" target element, demonstrating a fundamental psychophysical phenomenon
within auditory scene analysis. To test this hypothesis, we will identify the
neural signals for individual sound sources separately and in combination. We
will then interpret these signals based on the perceptual data gained from sound
localization tests with multiple moving and stationary sound sources.
Discovering the fundamental brain mechanisms for auditory scene analysis will
provide new neurophysiological insight into a well-established psychophysical
field and offer potential technical solutions for sound-source segregation.