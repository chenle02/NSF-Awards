* 2132972
* NRI: Robust and Efficient Physics-based Learning and Reasoning in Degraded Environments
* CSE,IIS
* 02/01/2022,01/31/2026
* Jingjin Yu, Rutgers University New Brunswick
* Standard Grant
* Cang
* 01/31/2026
* USD 1,490,276.00

This project will perform fundamental research into developing and integrating
physics-driven reasoning and planning techniques to enable autonomous robots to
manipulate unknown irregular objects and navigate in unstructured, dynamic
environments. The developed techniques will be deployed on RoboMantis: a four-
legged, wheeled robot that can assist in first-response missions. The project
will fill the important gap between existing research on learning models of
unknown objects from data and research on developing adequate simulation tools
for robotic manipulation and locomotion by answering three fundamental
questions: 1) How to efficiently simulate the effects of robotic actions on
objects with uncertain models? 2) How to use physics simulation tools to plan
manipulation and locomotion strategies for navigating in unstructured terrains?
and, 3) How to learn physical models of objects on the fly? The project builds
on top of progress in computer vision, physics simulation, and planning, towards
developing an efficient toolset for robotic navigation in
rubble.&lt;br/&gt;&lt;br/&gt;The main technical objectives of this project are
to: 1) Develop physics simulation tools that can be used for efficiently
inferring models of both rigid and non-rigid objects and for robust planning, 2)
Develop optimization tools for learning models of objects from limited vision
and interaction data, 3) Develop manipulation and navigation algorithms that can
leverage the learned models, and 4) Demonstrate the fully integrated system on a
diverse range of tasks related to search and rescue operations, such as
manipulating unknown objects in clutter and navigating in rubble. The project
will adopt a Bayesian approach where models of objects that are typically found
in piles of rubble, such as debris and rocks, will be inferred from a few RGB-D
images providing partial views of the scenes, and also from their responses to
forces applied by the robot during locomotion and manipulation actions.
Hypotheses of various models will be used to simulate the effects of the exerted
forces on the objects. Models that best reproduce the observed effects of the
forces will be given the highest probabilities. The inferred models will then be
used to plan robust manipulation and locomotion actions that allow the robot to
clear its way and advance through a pile of debris. The project brings together
an interdisciplinary team of investigators who have expertise in computer
vision, physics simulation and planning. Implementations of the developed
solutions will be provided to the research community as open-source software
packages. This will be coupled with the generation of educational material,
especially programming assignments on manipulation challenges that require
physics reasoning, which will be shared with the academic community. The
material will aim to attract undergraduate students early in their studies to
STEM by using hands-on experience that can be provided with the use of robotics,
while also exposing them to foundational methods and data-driven tools. When
appropriate, efforts will be made to introduce the research, in particular the
hardware demonstrations, to K-12 students to cultivate their early interests in
robotics, which touches all aspects of STEM. In the process, the PIs will aim to
leverage diversity programs at Rutgers University to recruit and support
underrepresented groups.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.