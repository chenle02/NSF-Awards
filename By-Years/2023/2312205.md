* 2312205
* Collaborative Research: CIF: Medium: Statistical and Algorithmic Foundations of Distributionally Robust Policy Learning
* CSE,CCF
* 10/01/2023,09/30/2027
* Zhengyuan Zhou, New York University
* Continuing Grant
* Alfred Hero
* 09/30/2027
* USD 237,028.00

Efficient data-driven policy learning and deployment techniques are transforming
many facets of our society as a result of their broad applicability in
engineering, scientific and societal applications. Given the access to high-
performance computing, the use of simulators and digital twins, for example,
have emerged as practical alternatives to test and learn complex optimization
policies. As a result, significant scholarly efforts have been devoted to this
research area in the past decade. However, despite having made landmark
progress, existing work in this area often makes a key (implicit) assumption;
namely, that the environment in which the policy is trained will be the same as
the environment in which the policy is deployed. Policies learned under this
assumption can be fragile, as this assumption often does not hold in practical
environments, either due to the simulator model specification or environment
shifts. The goal of this project is to study statistical and algorithmic
foundations for developing provably efficient robust policy learning in unknown
environments, under a possibly misspecified generative model.

The project studies comprehensive statistical and algorithmic foundations for
distributionally robust policy learning in contextual bandits and reinforcement
learning (RL) environments and develops statistically optimal and
computationally efficient algorithms across a wide range of non-parametric
distributional shifts. These provide a powerful framework for capturing model-
agnostic environment changes, but at the same time, pose intellectual challenges
as the unknown worst-case environment lies in an infinite-dimensional space. The
presented program opens up several fundamental research directions that call for
novel and principled developments. First, the project develops information-
theoretic tools to understand the fundamental learning limits for
distributionally robust policy learning and to characterize how the
distributional uncertainty contributes to the difficulty of learning.
Additionally, the project develops computationally efficient and statistically
optimal estimation schemes for distributionally robust performance analysis of a
given policy. Lastly, the project translates the efficiency gains in estimation
due to learning a distributionally robust policy.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.