* 1907401
* SHF: Small: Locality Aware Scheduling in Multi-GPU Systems
* CSE,CCF
* 10/01/2019,09/30/2024
* Laxmi Bhuyan, University of California-Riverside
* Standard Grant
* Danella Zhao
* 09/30/2024
* USD 431,586.00

Heterogeneous multiprocessor architectures consisting of Central Processing
Units (CPUs) and Graphical Processing Units (GPUs) are increasingly used to
accelerate parallel workloads like High Performance Computing (HPC) and cloud
computing. GPUs provide significant improvements in performance compared to
traditional multi-core CPUs, and therefore, are heavily used as accelerators.
Multiple GPUs are employed to further speed up the execution and improve storage
capacity. Current multi-GPU architectures, such as DGX, provide ultra-high
bandwidth NVLink communication to transfer the data directly between the GPUs.
However, partitioning those computations and data in multi-GPUs based on various
memory and communication models poses a tremendous challenge to the programmers.
This project develops graph-based partitioning techniques for different
applications considering data locality among the computations in the GPUs.
Secondly, the current literature on heterogeneous scheduling does not consider
processing inside the GPU, leaving it to the manufacturer. This project also
develops a locality-based Thread Block (TB) scheduler by extending the same
graph-based technique to cache block sharing.&lt;br/&gt;&lt;br/&gt;The project
is carried out in several steps. First, it develops micro-benchmarks for
measuring the computation and communication cost for execution in a multi-GPU
architecture. A profiling tool is developed to measure the data sharing among
the TBs for GPU execution. Second, an adjacency graph is designed for the multi-
GPU data partition, where the vertices represent the computation, and edges
represent the communication cost between the vertices. A similar graph model is
also developed for data sharing inside a GPU, where vertices represent the TBs
and edges represent the number of shared blocks between the TBs. Third, a
recursive bi-partitioning technique is developed for the adjacency graph using
known heuristics and software to achieve load balance among the partitions and
minimize the communication cost between the partitions in a multi-GPU system. TB
scheduling is also proposed considering the L2 cache size and the resource limit
inside a GPU. Fourth, the technique is extended to partition data and
computations between CPUs and GPUs in a heterogeneous multiprocessor. Finally,
two regular applications, LU decomposition and Wavefront, are analyzed, and
multi-GPU scheduling is developed through real implementation using GPU
architectures. Some irregular applications from the Rodinia and CUDA-SDK
benchmarks are also analyzed to develop graph models and execute them on the
GPGPUSim for verification of the TB scheduling inside the
GPU.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has
been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.