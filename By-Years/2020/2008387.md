* 2008387
* NSF-BSF: RI: Small: Structured Distributions in Deep Nets
* CSE,IIS
* 10/01/2020,09/30/2023
* Alexander Schwing, University of Illinois at Urbana-Champaign
* Continuing Grant
* Rebecca Hwa
* 09/30/2023
* USD 450,000.00

The goal of this research is to develop methods that improve interaction between
AI systems and humans. AI systems are increasingly more prevalent in decision
making processes, for instance, in navigation systems for avoiding traffic jams.
However, while one could ask a peer for a recommendation and the reason behind
it, todayâ€™s AI systems often cannot provide a justification for their output.
Hence, users have to 1) trust the system recommendation blindly, 2) verify
plausibility individually, or 3) ignore the recommendation. To address the
limitation that none of those three options is desirable, the research develops
models which can explain their output, the research develops algorithms which
can be controlled, and the research develops methods which permit interaction
with the model. Inspired by a human focusing on subsets of the data when making
a recommendation, the research seeks to obtain explain-ability, control-ability
and interact-ability by extracting which parts of the data provided most
evidence. For this we use probability distributions inside AI systems.
Furthermore, this research will support development of a cohort of PhD and
undergraduate students at the University of Illinois at Urbana-Champaign,
outreach activities in the local neighborhood and development of two classes: a
novel undergrad class on entry-level machine learning and a novel grad class on
distributions in AI systems.&lt;br/&gt;&lt;br/&gt;Technically, distributions
inside AI systems are often referred to as attention. Attention provides a
compelling framework 1) to explain the decisions formed in discriminative
networks; 2) to control the sampling process in generative models; and 3) to
interact in reinforcement learning systems. The technical aims of this research
are divided into three thrusts. The first thrust scales attention mechanisms to
data that comprises multiple modalities and develops algorithms which better
capture probability distributions in those high-dimensional settings. The second
thrust generalizes those algorithms to more complex data structures and
leverages those results for AI systems which generate high-dimensional output,
e.g., a description of an image. The third thrust studies interaction between
humans and AI systems that leverage distributions.&lt;br/&gt;&lt;br/&gt;This
award reflects NSF's statutory mission and has been deemed worthy of support
through evaluation using the Foundation's intellectual merit and broader impacts
review criteria.