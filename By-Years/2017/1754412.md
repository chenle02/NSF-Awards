* 1754412
* Mechanisms for multi-modal gaze stabilization in Drosophila
* BIO,IOS
* 03/01/2018,02/29/2024
* Jessica Fox, Case Western Reserve University
* Continuing Grant
* Susan Renn
* 02/29/2024
* USD 706,449.00

Moving animals often use vision to determine where they are and where they are
going. However, the scene in an animal's eyes only makes sense if it knows its
own body position and movements. While they are moving, animals can also predict
how their senses will be affected by their own movements. For example, as a
human walks, his eyes bounce up and down with his steps, but he does not see
this motion because his brain predicts and ignores this self-generated visual
information. Though much is known about how this process works in a single sense
organ, less is known about how multiple senses work together to do this. In many
animals, the inner ear monitors the position and movement of the body. However,
the inner ear is inside the head and difficult to study and manipulate. This
project will take advantage of animals with rotation sensors on the outside of
their bodies to observe how these organs influence behavior. In flies,
specialized organs called halteres detect body movements and these structures
are located outside the body near the wings. This research will measure changes
in fly behavior that occur when the sensory information coming from the haltere
is changed and when it does not match information gathered through vision. This
work will show how multiple senses are integrated with the animal's own behavior
to guide movement. By examining how the brain combines multiple sensory inputs
and anticipates the consequences of its own behaviors, this work will uncover
mechanisms of the brain's function that can be applied to other species and that
can be used to understand biological brains and engineer algorithms for moving
machines. The project will also be incorporated into a series of workshops at an
all-girls high school with the goal of improving quantitative and computer
coding skills in female students. &lt;br/&gt;&lt;br/&gt;Distinguishing between
self-generated and externally generated body movements is a central challenge
for the nervous system. Efference copy, a neural signal of opposite sign to
expected sensory input, is a possible mechanism for this distinction. Efference
copies have been observed in single sensory systems, but how might they function
in a multi-sensory context? Using an animal with a well-understood visual system
and an easily-accessible mechanosensory organ, these experiments will
investigate how these two sensory modalities combine during voluntary and
involuntary movements. In flies, body rotations are detected by specialized
mechanosensors called halteres. These are modified hindwings that perform a
function similar to the mammalian vestibular system. This project will
investigate the integration of haltere information, visual information, and
motor commands through quantitative behavioral analysis of flying flies. Flies
will fly under different conditions: flight with imposed body rotations
(tethered to a motor), flight with free, self-generated rotations (tethered to
pins suspended between magnets), and rigidly tethered flight (no body rotations)
with imposed movements of the haltere. The fly's head movement behavior will be
observed under these conditions, and the behavior of intact flies will be
compared to flies with their mechanosensory halteres removed or manipulated.
Finally, information theoretic analysis will be used to quantify the flow of
information in the visual and mechanosensory systems and construct a theoretical
framework that can be used to understand how information about body rotations is
integrated with visual information to control posture and gaze. Taken together,
these experiments and model will demonstrate how two sensory modalities are
combined and integrated with motor feedback during flight. Broader impacts
include workshops to broaden experience for young women in quantitative and
computer coding skills and presentation of the work to various non-scientific
audiences. Work completed here has application to the field of robotics and the
development of higher quality autonomous aerial
robotics.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.