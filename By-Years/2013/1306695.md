* 1306695
* NSF Postdoctoral Fellowship in Biology FY 2013
* BIO,DBI
* 06/01/2013,05/31/2015
* Matthew Green, Green                   Matthew        H
* Fellowship Award
* michael vanni
* 05/31/2015
* USD 138,000.00

Neural mechanisms of mobile prey detection during locomotion

The visual world of animals is always in motion. A video camera mounted directly
onto the eyeball would record a blur of perpetual movement. Visual motion can
signal the presence of behaviorally important objects such as prey or predators,
yet each time an animal shifts its gaze or engages in locomotion, the visual
surround also moves. How does the brain distinguish between visual motion caused
by movement of the eyes, head or body, versus visual motion caused by mobile
objects in the environment? To tackle this question, this fellowship will
support the development of innovative, virtual reality methods that will be
combined with genetic techniques to record the activity of specific circuit
elements in the brain of larval zebrafish while they attempt to visually track
and capture "virtual" prey items. In zebrafish and many other vertebrates, the
ability to capture prey is reliant on a midbrain structure called the optic
tectum; however, very little is known about identity or function of neural
circuits in the tectum or elsewhere in the brain that function to detect and
direct attention towards mobile prey. Although current neural recording
techniques require that fish be immobilized, a virtual reality system overcomes
this limitation by simulating the motion of the visual world that fish would
experience while freely swimming. Critically, a virtual reality system will make
it possible to experimentally decouple changes in the sensory surround from
motor actions, allowing for a precise dissection of feedback mechanisms between
sensory and motor processing in the nervous system.

Training goals include learning to implement real-time, closed-loop controllers
for visual displays, and learning to use genetic methods for identifying and
imaging neurons in zebrafish. This fellowship will also support the development
of a human eye-tracking, virtual reality system, to be used in the classroom or
in a public venue, such as a museum. This eye-tracking system will allow
students or the public to interactively investigate relationships between their
movement and their perception of motion.