* 1749494
* EAGER: Low-Energy Architectures for Machine Learning
* CSE,CCF
* 09/15/2017,08/31/2018
* Keshab Parhi, University of Minnesota-Twin Cities
* Standard Grant
* Sankar Basu
* 08/31/2018
* USD 125,000.00

Machine learning systems and classifiers will be part of future smart devices.
Industrial internet-of-things (IIOT) and cyber-physical systems (CPS) will be
equipped with real-time feature extraction and classification to provide
feedback and/or warning signals in some cases. Smart medical devices can analyze
signals and trigger therapy to improve human health. Security systems can
analyze activity data and thwart planned attacks. Reducing energy consumption in
these smart devices is critical for increasing battery life in portable
applications. This proposal addresses techniques to reduce energy consumption in
feature extraction and classification. The broader impacts will be in
demonstrating a new approach for feature extraction and classification with
significantly less energy consumption without degrading sensitivity and
specificity, along with training and educating graduate and undergraduate
students in related disciplines through laboratory and computational
experiences.&lt;br/&gt;&lt;br/&gt;The proposed framework computes features and
classifies the test data using a simple level-1 classifier that makes use of low
precision. If the classification is successful, then the process terminates.
Otherwise the level-2 classifier is invoked. The level-2 classifier makes use of
higher precision for the feature extraction and classification; however, it
reuses the low-precision results of the level-1 classifier. The process is
repeated in an iterative manner until the test sample is classified with a high
probability. The proposed approach differs from existing approaches in the sense
that the classifier at a certain level is trained using only the training
samples that do not contain the samples that were correctly classified in prior
levels. The precision at the different levels of feature extraction and
classification are the same for both training and test phases. This is expected
to lead to higher classification accuracy. The features and classifiers are
computed using approximate computing in an incremental manner. Other innovative
aspects include: selection of classes of features that require less energy
(e.g., time-domain vs. frequency-domain), ranking of these features using
techniques such as minimally-redundant maximally-relevant (mRMR) and use of
classifiers such as classification and regression tree (CART) or AdaBoost.
Approximate computing of features and classifiers in an incremental manner will
be investigated to reduce overall energy consumption while maintaining high
sensitivity and specificity. Training of the P-Boost classifier and testing the
classifier will be based on same precision; thus there is no disconnect between
the precision of the classifiers used for training and testing. The proposed
"holistic" approach is likely to result in significant savings in energy
consumption compared to state-of-the-art machine learning
systems.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.