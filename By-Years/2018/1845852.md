* 1845852
* CAREER: Information-Theoretic Foundations of Fairness in Machine Learning
* CSE,CCF
* 02/01/2019,01/31/2024
* Flavio Calmon, Harvard University
* Continuing Grant
* Alfred Hero
* 01/31/2024
* USD 547,900.00

Machine learning algorithms can identify complex patterns in very large
datasets. These algorithms are increasingly used in applications of significant
social consequence, such as loan approval, hiring, and bail and sentencing
decisions. However, real-world data may reflect discrimination patterns that
exist in society at large. Consequently, decisions based on algorithms that
learn from data are at risk of inheriting and, ultimately, reinforcing
discriminatory and unfair social biases. This project aims to precisely
characterize the operational limits of discrimination discovery and control in
machine learning by combining legal and social science definitions of fairness
with powerful mathematical tools from information theory, statistics, and
optimization. This cross-disciplinary effort aims to provide fundamental theory
and design guidelines for data scientists and engineers who will create the next
generation of fair data-driven algorithms and applications. The technical
results of this project will also inform the debate surrounding the social
impact of machine learning. Moreover, this research will be used as a vessel for
engaging students and researchers from diverse backgrounds in the applicability
of information theory, machine learning, optimization, and, more broadly, math
and engineering to social challenges.&lt;br/&gt;&lt;br/&gt;Automated methods for
discovering and controlling discrimination in machine learning inherently face a
trade-off between fairness and accuracy, and are limited by the dimensionality
of the underlying data. This project creates a comprehensive information-
theoretic framework that captures the limits of discrimination control by
determining (i) how to systematically identify data features that may lead to
discrimination; (ii) how to ensure fairness by producing new, information-
theoretically grounded data representations; (iii) the fundamental information-
theoretic trade-offs between fairness, distortion, and accuracy; and (iv) the
impact of finite samples in discrimination detection and mitigation. The key
advantage of the information-theoretic methodology adopted in this project is
that it captures fundamental, algorithm-independent properties of
discrimination, while being fertile ground for the development of novel
mathematical tools and models relevant to both data scientists and information
theorists. The theoretical component of this research weaves new connections
between information theory and robust statistics by analyzing the impact of
local perturbations of probability distributions on discrimination metrics, and
creates new information-theoretic models useful in discrimination control,
privacy, and representation learning. The applied component of this research
develops robust, data-driven methods for measuring and mitigating discrimination
that are immediately relevant for fair algorithmic decision-making in
applications of consequence.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.