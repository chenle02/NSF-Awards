* 0905506
* HCC: Medium: Sound Rendering for Physically Based Simulation
* CSE,IIS
* 07/01/2009,06/30/2015
* Steve Marschner, Cornell University
* Continuing Grant
* Ephraim Glinert
* 06/30/2015
* USD 1,213,705.00

Computational physics can help us animate crashing rigid and deformable bodies,
or fracturing solids, or splashing water, but the results are silent movies.
Virtually no practical algorithms exist for synthesizing synchronized sounds
automatically. Instead, sound recordings are edited manually for pre-produced
animations or triggered automatically in interactive settings. The former is
labor intensive and inflexible, while the latter produces awkward, repetitive
results. This situation is a serious obstacle to building realistic, interactive
simulations (whether for entertainment, training, or other applications), which
require sound to be compelling,. In this research the PIs will begin filling
this broad void by pursuing fundamental advances in computational methods while
solving several particularly challenging sound rendering problems. The goal is
to produce some of the first viable methods in this area, upon which many more
can be built. Successful implementation of this program will fundamentally
transform our relationship with our increasingly convincing simulated realities,
because for the first time we will be able to hear them as well as see them. To
these ends, the PIs will develop fundamental algorithms that address the
problems of simulating the vibrations that cause sound and computing the sound
field produced by those vibrations.&lt;br/&gt;&lt;br/&gt;1) Reduced-order
vibration models. Simulating vibration in complex structures is expensive
because of the need for both high model complexity and audio-rate temporal
resolution. The PIs will develop dimensional model reduction methods to enable
efficient sound rendering from complex, nonlinearly vibrating geometry, such as
thin shells.&lt;br/&gt;&lt;br/&gt;2) All-frequency sound radiation. Realistic
sound requires computing the radiated sound field from a vibrating surface over
the very broad range of audible frequencies. But existing methods are either
inaccurate for low frequencies or impractical for high frequencies. The PIs will
develop hybrid algorithms based on a broad toolbox and discover which methods
are most successful for which problems.&lt;br/&gt;&lt;br/&gt;Complementing the
algorithmic work, the PIs will pursue solutions to a series of difficult,
unsolved sound rendering problems that are of value in
applications:&lt;br/&gt;&lt;br/&gt;a) Harmonic fluid sounds. Few sounds are as
distinctive as pouring a glass of water or the babbling of a brook, yet no
algorithms exist to compute these sounds automatically. The PIs will investigate
practical algorithms for harmonic bubble-based sound radiation characteristic of
splashing fluids.&lt;br/&gt;&lt;br/&gt;b) Multi-object sound. Sounds made by
collections of objects in contact (think of a bin of LEGOs or a basket of
blocks) involve close-proximity effects that are often ignored. The PIs will
develop sound rendering methods to approximate multi-object contact sounds with
object-object interactions.&lt;br/&gt;&lt;br/&gt;c) Fracture. Brittle fracture
creates distinctive sounds during destructive processes like breakage of glass.
The PIs will research the efficient generation and excitation of vibrating
fragments, and multi-object sound radiation from vibrating
debris.&lt;br/&gt;&lt;br/&gt;In all aspects of this research, the PIs will
ensure that they are solving problems accurately by comparing every
approximation to a reference solution, and they will also ensure they are
solving the right problems by testing perceptual equivalence between approximate
solutions, reference solutions, and recorded
sounds.&lt;br/&gt;&lt;br/&gt;Broader Impacts: Successful implementation of this
program will lead to practical innovations of immediate relevance to computer
graphics, and applications of acoustic simulation. In the future, the methods
developed in this project or their successors will completely transform how
sound is computed in interactive virtual environments.