* 1622679
* SCH: INT: Collaborative Research: Assistive Integrative Support Tool for Retinopathy of Prematurity
* CSE,IIS
* 10/01/2016,09/30/2020
* Kemal Sonmez, Oregon Health & Science University
* Standard Grant
* Sylvia Spengler
* 09/30/2020
* USD 407,404.00

Retinopathy of prematurity (ROP) is a leading cause of childhood visual loss
worldwide, and the social burdens of infancy-acquired blindness are enormous.
Early diagnosis is critically important for successful treatment, and can
prevent most cases of blindness. However, lack of access to expert medical
diagnosis and care, especially in rural areas, remains a growing healthcare
challenge. In addition, clinical expertise in ROP is lacking, and medical
professionals are struggling to meet the increasing need for ROP care. As point-
of-care technologies for diagnosis and intervention are rapidly expanding, the
potential ability to assess ROP severity from any location with an internet
connection and a camera, even without immediate ophthalmologic consultation
available, could significantly improve delivery of ROP care by identifying
infants who are in most urgent need for referral and treatment. This would
dramatically reduce the incidence of blindness without a proportionate increase
in the need for human resources, which take many years to develop.
&lt;br/&gt;&lt;br/&gt;This project develops a prototype assistive integrative
support tool for ROP, featuring a modular design comprising: (a) image analysis,
(b) information fusion of clinical, imaging, and diagnostic data, and (c)
generative probabilistic and regression models with associated computationally
efficient machine learning algorithms. The outcomes of the project include
disease severity metrics and diagnostic estimates obtained through clinical
evidence classifiers trained jointly over expert-generated labels. These labels
consist of discrete diagnostic labels, as well as comparison outcomes of
relative severity between pairs of images. Random process models for vessel
tortuosity and diameter distributions over the retina, as well as patch-based
vessel-free image analysis through the use of convolutional neural networks on
the entire image, enhance and augment feature extraction. Moreover,
incorporating severity comparison outcomes through novel hard and soft
constraint methods force inferred severity to agree with ordinal information
provided by experts and address inherent uncertainty in expert ground-truth
labels. The above severity inference methods are evaluated and fine-tuned over a
broad array of generative models, both through retrospective analysis, including
cross-validation, longitudinal tests, and tests across multiple sites, as well
as through prospective analysis, evaluating its real-world clinical impact.