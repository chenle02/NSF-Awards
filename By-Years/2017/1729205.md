* 1729205
* Collaborative Research:   CI-P: ShapeNet: An Information-Rich 3D Model Repository for Graphics, Vision and Robotics Research
* CSE,CNS
* 09/01/2017,08/31/2018
* Leonidas Guibas, Stanford University
* Standard Grant
* Roger Mailler
* 08/31/2018
* USD 33,333.00

The goal of this project is to plan the development of a richly annotated
repository of 3D models called ShapeNet that currently exists only in a
preliminary form. ShapeNet will include 3-4 million 3D models of everyday
objects in 4-5 thousand categories, in a variety of representations. Models in
the ShapeNet repository will be annotated with multiple annotation types:
geometric (parts, symmetries), semantic (keywords for the shape and its parts),
physical (weight, size), and functional (affordances, scene context). The
availability of ShapeNet data, capturing the 3D geometry of a significant
fraction of object categories in the world, together with associated detailed
meta-data and semantic information, will catalyze major developments in
graphics, vision and robotics by providing adequate data against which new
proposed techniques and methodologies for shape or scene analysis and synthesis
can be vetted -- and with which machine learning algorithms can be trained.
ShapeNet can be considered an encyclopedia that facilitates the creation of
intelligent systems and agents capable of operating autonomously in the world
--- because they can have deep knowledge of that
world.&lt;br/&gt;&lt;br/&gt;While most of the ShapeNet models will be initially
found on the Web, the annotations will be obtained through an active learning
combination of modest human input (including crowd-sourcing), extensive
algorithmic transport, and human verification. During the planning period the
effort will focus on mathematical representations of the semantic knowledge
associated with 3D models, as well as on a design framework for key algorithms
allowing knowledge transport from one model to another. Further challenges to be
addressed include the quantification of data quality issues and the
specification of all the multimodal (3D, image, language) UIs and APIs needed
for users to be able to exploit and search this wealth of data, or to contribute
additional models and annotations to it.