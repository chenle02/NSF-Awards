* 1937950
* Situated Algorithmic Thinking: Preparing the Future Computing Workforce for Ethical Decision-Making through Interactive Case Studies
* EDU,DUE
* 05/15/2020,04/30/2024
* Aditya Johri, George Mason University
* Standard Grant
* Thomas Kim
* 04/30/2024
* USD 367,789.00

This project aims to serve the national interest by studying how undergraduate
students develop ethical decision-making skills. It will specifically focus on
these skills in the context of algorithmic thinking. Algorithmic thinking solves
problems by identifying step-by-step instructions that can solve the original
problem as well as be used again and again to solve related problems.
Algorithmic thinking is a foundation of computational thinking, information
technology, and computing, all of which have had positive effects on many
aspects of life. However, there is increasing concern about how algorithm-based
technology may harm individuals and society. One concern is the potential for
the algorithms that run software to have unintended outcomes, including
production of biased results. For example, a hiring algorithm designed to
evaluate candidates for an engineering job may be biased toward hiring male
engineers because the data about successful engineers is mostly about successful
male engineers. Therefore, it will be important to integrate ethical decision
making into the computer science curriculum so that future programmers are aware
of and can mitigate unintended algorithmic outcomes. Toward this goal, the
project will develop, implement, and test six interactive case studies to engage
undergraduate students in the ethical aspects of algorithmic thinking and
algorithm design. The case studies will enable students to think through issues
of algorithmic decision making from different perspectives. This experience is
expected to promote student understanding of ethical considerations in the
context of algorithmic thinking. The interactive case studies will be adaptable
for use in other courses, in standalone workshops, and at other institutions.
&lt;br/&gt;&lt;br/&gt;The ability to use algorithmic thinking to design and
develop technology is a core concern for education of the future workforce. The
challenge with algorithmic decision-making at a societal level is that
algorithms can be (1) biased due to the characteristics of the underlying data
used to train different models; (2) unaccountable in that there is no mechanism
to audit them or for redress if an algorithm is misused or makes an error; and
(3) misunderstood regarding how algorithm-driven decisions impact social justice
or ethical issues. Given the importance of algorithms and their complexity, it
is critical that students learn ethical decision-making as part of their
computer science education. Building on the situated cognition paradigm of
learning, this project will develop interactive case studies that provide
students the opportunity to think through issues of algorithmic design. Engaging
with the material from different perspectives and domains will allow students to
develop a well-grounded understanding of the importance of ethics in the context
of algorithm development. The research component of the project will measure how
perspectival understanding develops using interactive case studies. The research
study will use a mixed methods approach involving analysis of student-generated
artifacts such as concept maps and analysis of student explanations, using
coding strategies to document important trends and outcomes. This project is
supported by the NSF Improving Undergraduate STEM Education Program: Education
and Human Resources, which supports research and development projects to improve
the effectiveness of STEM education for all students. Through the Engaged
Student Learning track, the program supports the creation, exploration, and
implementation of promising practices and tools.&lt;br/&gt;&lt;br/&gt;This award
reflects NSF's statutory mission and has been deemed worthy of support through
evaluation using the Foundation's intellectual merit and broader impacts review
criteria.