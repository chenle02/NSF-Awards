* 2232169
* EAGER: Opinion Spam in Digital Rulemaking: Techniques, Effects, and Interventions
* SBE,SES
* 09/01/2022,08/31/2024
* Yifu Li, University of Oklahoma Norman Campus
* Standard Grant
* Sara Kiesler
* 08/31/2024
* USD 300,000.00

One of the pillars of representative government in the United States is people's
ability to participate in setting rules and regulations. Regulatory agencies are
required (with some exceptions) to solicit comments from various publics (e.g.,
general citizenry, affected organizations, interest groups) to learn about the
potential consequences of proposed rule changes. To extend participation and
reduce costs, the commenting process has been digitized and often takes place
through the internet. However, digitization opened the door to opinion spam
(e.g., mass, computer-generated, or fraudulent comments) that may undermine the
rulemaking process by deceiving agency evaluators and manipulating what
citizens' actual attitudes are regarding proposed regulations. Opinion spam
complicates the evaluation that agencies must perform in setting rules and
threatens the legitimacy of the rulemaking process in the eyes of stakeholders.
This project investigates ways in which opinion spam might be prevented and
provides evidence regarding which techniques are most effective, thereby
preserving (or potentially restoring) public trust in digital
rulemaking.&lt;br/&gt;&lt;br/&gt; In three phases, this project examines threats
to digital rulemaking and tests mitigation approaches to reduce opinion spam.
Phase 1 includes a series of interviews with submitters of comments, comment
evaluators, and scholarly experts on mis/disinformation to gauge how these
groups conceive of opinion spam and its prevalence in commenting discourse and
to uncover potential interventions that may limit the submission of opinion spam
or help agencies detect its submission. Phase 2 includes generating machine
learning datasets (e.g., legitimate, fictitious, and automated text replacement
or text recombination comments) and models for distinguishing
fictitious/artificial comments from legitimate comments. Phase 3 integrates the
findings from the prior phases and includes selecting several viable opinion-
spam mitigating strategies and testing their efficacy in randomized, controlled
experiments. This multi-method, interdisciplinary investigation contributes to
the theory of coordinated influence campaigns. The project develops a syntax-
aware deep learning model for detecting fictitious comments and helps determine
which mitigation approaches work better for reducing opinion
spam.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has
been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.