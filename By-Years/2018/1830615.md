* 1830615
* NRI: FND: Connected and Continuous Multi-Policy Decision Making
* CSE,IIS
* 09/01/2018,08/31/2022
* Edwin Olson, Regents of the University of Michigan - Ann Arbor
* Standard Grant
* James Donlon
* 08/31/2022
* USD 654,807.00

The goal of this project is to create methods that allow robots to move and
communicate in close proximity to other robots or humans. In these settings, a
robot must understand how its behavior is likely to influence and change the
behavior of other robots and people nearby. The basic idea of this project is to
allow the robot to select between several different strategies, picking the one
that is most likely to work well in a given situation. For example, a robot
might decide to veer towards the right because it predicts that an approaching
wheelchair requires more room than a typical pedestrian. This project will also
investigate how robots can coordinate with each other, deciding what information
should be transmitted to teammate robots. This type of research is important in
order to build robots that can safely and comfortably interact with regular
people in everyday environments like their homes, schools, and hospitals.
&lt;br/&gt;&lt;br/&gt;The technical approach of this project is to extend a
planning algorithm known as Multi-Policy Decision Making (MPDM). Using an on-
line forward roll-out process, candidate policies are evaluated from a "library"
of options. The core tension in MPDM type systems is that larger libraries allow
more flexible behaviors, but require greater computational resources. This
project achieves expressivity in a different way than previous MPDM approaches:
it allows policies to have one or more continuous parameters, and then
efficiently computes good values of those continuous parameters. For example,
whereas earlier MPDM work might have had several policies representing different
nominal speeds of travel, this work allows robot designers to explicitly
parameterize velocity. This continuous-valued parameter can be tuned using
backpropagation methods similar to those used in deep learning networks. The key
advantage of this approach is that a single policy can generate a wider range of
behaviors, which reduces the number of policies that must be explicitly
considered. In turn, this reduces the computational complexity of the planning
process.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.