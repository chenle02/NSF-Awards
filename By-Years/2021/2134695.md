* 2134695
* Collaborative Research: Image-based Readouts of Cellular State using Universal Morphology Embeddings
* BIO,DBI
* 05/01/2022,04/30/2025
* Juan Caicedo, Broad Institute, Inc.
* Standard Grant
* Jean Gao
* 04/30/2025
* USD 512,731.00

Observing cells under the microscope reveals an incredible amount of information
about cellular processes. For example, images of cells can reveal cell types,
and whether the cells are healthy or sick, among others. This research aims to
develop advanced computational models to measure cellular traits in microscopy
images. Cellular measurements taken from images are useful to conduct biological
research such as understanding how diseases work, diagnosing patients, and
searching for effective cures. All of these applications are fundamental to
advance and promote national health. An important aspect of this project is that
the computational models for measuring cellular traits will be of general
purpose and reusable across many biological applications where microscopy images
are acquired, with minimal or no manual configuration. This research will
design, develop and make publicly available the models and automated tools to
facilitate rapid image-based cellular analysis in basic biological research and
other biotechnology systems. This project will involve diverse researchers
working in an inclusive environment at the intersection of cutting-edge machine
learning technologies and image analysis for cell biology. Diverse graduate
students and postdocs will be trained in an inclusive environment at the
intersection of cutting-edge deep learning technologies and&lt;br/&gt;image
analysis for cell biology.&lt;br/&gt;&lt;br/&gt;Extracting cell morphological
features from images is a complex, ad-hoc process without well established
standards. Typically, imaging projects develop custom approaches from scratch
and measure only a few cellular features given the complexity and diversity of
imaging techniques and experimental goals. This lack of a common methodology to
define and measure the morphological state of single cells prevents researchers
from realizing the full potential of imaging for advancing cell biology. This
project aims to create a universal deep-learning model for collecting single-
cell morphological data. It will readily quantify cell morphology in any
microscopy image, requiring little to no training. The specific goals of this
research are: 1) develop methods for learning and extracting multidimensional
representations of cell morphology from diverse imaging experiments, 2)
formulate strategies for correcting batch effects and removing technical
variation, and 3) develop strategies for analyzing and interpreting the
biological significance of morphological features. For learning representations,
neural networks that can adaptively process multi-channel microscopy images will
be developed and trained using self-supervised learning. Domain adaptation
techniques will be extended for correcting batch effects. Importantly, learned
features will be used to map relations between populations of cells and
explainable methods will be designed to facilitate their interpretation. This
research will prepare imaging datasets from various public sources for training
and evaluation, including the Broad Bioimage Benchmark Collections (BBBC), the
Image Data Resource (IDR), and the Human Protein Atlas (HPA). The models created
in this project will be applicable to most microscopy imaging protocols to
transform images of single cells into quantitative data for biological research.
All the results, software tools and models will be publicly available at
http://broad.io/morphem&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.