* 9711967
* Domain Independent Vision-Based Navigation
* CSE,IIS
* 09/01/1997,07/31/1999
* Gregory Hager, Yale University
* Continuing Grant
* Jing Xiao
* 07/31/1999
* USD 148,069.00

The goal of this research is to develop methods for robust, domain-independent
vision-based navigation suitable for both structured and unstructured
environments. Visual tracking is used to monitor a set of image features
(markers), and vision- based control is used to to guide the robot's motion from
the image trajectory of the markers while avoiding obstacles. An environment is
represented as a graph (map) which may be constructed under human control (e.g.
giving the system a tour) or autonomously as the system explores. As the robot
moves during the process of mapping, markers are automatically selected from the
video stream and tracked. Rather than using prestored models of landmarks,
markers are selected based on image content using a suite of domain-independent
operators. The selected markers will be visually distinctive, unique within the
image, and stable under varying viewpoint and illumination. During passive map
making, the robot is taken on a tour, and it instantiates a graph representing
the paths that the robot can follow; recognition is used to annotate the map.
During active mapping, the robot systematically explores the environment and
incrementally constructs the graph representation. These algorithms will be
tested empirically on two mobile platforms in both indoor and outdoor
environments.