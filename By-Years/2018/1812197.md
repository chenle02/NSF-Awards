* 1812197
* Decision Theoretic Bayesian Computation
* MPS,DMS
* 08/01/2018,07/31/2022
* Harsha Honnappa, Purdue University
* Continuing Grant
* Yong Zeng
* 07/31/2022
* USD 150,000.00

Decision-makers, whether in business, policy-making, or engineering systems,
face the problem of taking action without complete knowledge of the state of the
world. Examples of such situations include controlling industrial plants,
maneuvering autonomous vehicles, developing new drugs, making investment
decisions or staffing decisions in service systems. Modern decision-makers
typically use sophisticated probabilistic models to capture uncertainty, and
take optimal actions within the framework of such models. In general, the models
themselves involve unknown parameters which must be estimated from data. While
large datasets improve the estimation of the parameters, leading to more
accurate decisions, these big-data settings also raise computational challenges
that call for approximations in the estimation. Current methodology typically
proceeds in two steps: (1) use the vast statistical and machine learning
literature to approximately estimate model parameters, and (2) use the resulting
approximations to compute the best possible action. This two-stage procedure can
result in sub-optimality of actions, as the approximations computed in the first
stage are not tailored to the decision-making problem in the second stage. The
objective of this project is to develop and study a methodological framework for
approximate computation that puts decision-making at its center, recognizing
that the ultimate goal of most big-data analyses is to help decide among actions
in the face of uncertainty. The project will provide tools and theory to
accurately account for trade-offs between statistical accuracy, decision-
theoretic utility and computational complexity, and will integrate decision-
making into the computational revolution that has driven much of modern data-
science. The tools and theory potentially impact a large range of data-driven
decision-making problems. &lt;br/&gt;&lt;br/&gt;This project works in the
overarching framework of Bayesian statistics, where the primary object of
interest is the posterior distribution over the unknown parameters and
variables. The research focuses on theoretical and methodological challenges
arising from approximate computation for Bayesian decision theory. The
investigators consider two complementary problems, (a) Decision-theoretic
variational Bayes, and (b) Robust decision-making. The former task analyzes and
extends variational methods, developed in the machine learning community to
approximate intractable Bayesian posterior distributions, from a decision-
theoretic viewpoint. The investigators will theoretically study the optimality
of such algorithms with respect to decision-making rather than prediction, and
develop novel `loss-calibrated' algorithms that search for approximations using
decision-theoretic, rather than inferential criteria. Task (b) recognizes that a
model is always an approximation to reality, and is therefore misspecified. As a
consequence, a Bayesian posterior distribution, even if calculated exactly,
might not actually characterize the distribution over future observations. The
investigators explore connections with approximations from the first task, and
move from uncertainty about parameters and variables under a specified model, to
uncertainty about the choice of model itself. They develop and analyze
methodology that allows robust and principled decisions in the face of such
`Knightian' uncertainty.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.