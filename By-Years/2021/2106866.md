* 2106866
* Collaborative Research: HCC: Medium: TouchBots for Surface Haptics
* CSE,IIS
* 10/01/2021,09/30/2024
* Mary Hipwell, Texas A&M Engineering Experiment Station
* Standard Grant
* Cindy Bethel
* 09/30/2024
* USD 399,999.00

This project will lead to a new class human-machine interfaces that provide
tactile feedback to fingertips. Fingertips are remarkable multimodal sensors
capable of detecting pressure and vibration, local defor-mation such as braille
cells, hardness/softness, warmth/coolness, and endless types of textures. There
are strong reasons to exploit these sensory capabilities in interfaces: making
touch screens more accessi-ble for the vision impaired, making it easier to use
touch interfaces in automobiles, providing touch feedback in augmented and
virtual reality, and supporting remote touch in social, medical and retail
applications. The wealth of commercially important use cases has led to a fast-
growing market for touch feedback (“haptic”) technologies, yet none of the
existing approaches engages more than a small fraction of the fingertips’
capabilities. The new interfaces to be developed – TouchBots – will provide a
greatly expanded suite of haptic feedback modalities. A TouchBot is a
miniaturized module that is placed be-tween a fingertip and a touch surface,
such as a touchscreen or trackpad. It includes two main subsys-tems, one that
guides the finger along a programmable path, and another that provides a sense
of the shape and texture of objects along that path. Together, these subsystems
will enable TouchBots to offer many new haptic interactions such as touch-typing
interfaces without keyboards, realistic surface tex-tures for virtual reality,
and fully programmable braille and tactile graphics anywhere there is a touch
surface. These interactions have the potential to make touch screen devices
accessible to the vision im-paired. Recognizing that a new generation of
technological innovators will be needed to commercialize the fruits of this
research, close ties will be forged to graduate-level curricula in innovation,
leading to impact-minded individuals who are well-positioned to provide
leadership in the growing haptics indus-try.&lt;br/&gt;&lt;br/&gt;The
capabilities of a TouchBot stem from the manner in which it interacts with the
underlying surface. The proposed TouchBot design include: (a) kinesthetic
subsystem that provides feedback via passively rolling, but actively steered,
wheels; (b) a cutaneous module that provides feedback via an array of tiny
"pucks"; (c) selective brake mechanism for each of these pucks using
electroadhesion. This approach, known as “cobotic,” has been thoroughly
developed for macro-scale devices, and will be adapted here to the meso-scale by
careful integration of steering actuation, wheel design, and intent sensing.
Touch-bot will be extremely compact, with a low-power, and high-performance
system for motion guidance. The ability of the TouchBot to provide local shape
and texture will be provided by an array of tiny “pucks,” using the selective
breaking mechanism. This research will leverage prior efforts in areas as
diverse as surface haptics, wall-climbing robots and data storage read-write
heads to realize an electro-adhesive device that is high-force and high-
bandwidth and that can be used to control a high-density tactile array. By
bringing these technologies together into fingertip-scale devices, it will be
possible to demonstrate a wide range of surface haptic interactions including
buttons, toggles, raised line drawings, braille characters, tactile graphics,
and textures. Participatory design methods will be used to identify potential
uses of TouchBot in the areas such as automotive and user interaction design.
Experience proto-type and rapid iteration will be used to create stimuli that
evoke rich feedback.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.