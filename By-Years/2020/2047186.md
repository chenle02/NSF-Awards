* 2047186
* CAREER: When Reality Fails Expectations: Containing Reflective Domain Models for Human-Aware Planning and Learning of Robotic Teammates
* ENG,CMMI
* 06/01/2021,05/31/2026
* Yu Zhang, Arizona State University
* Standard Grant
* Jordan Berg
* 05/31/2026
* USD 569,413.00

This Faculty Early Career Development (CAREER) program will introduce a
transformative paradigm, referred to as Reflective Robotics, for planning and
learning of robotic teammates. Despite significant research into the development
of autonomous robotic agents, humans are still experiencing ambivalence towards
their robotic teammates. The problem lies not only in the limitations of robots
to interacting with humans, but also in the humans’ inability to understand
their robotic partners. Humans tend to be overly optimistic or pessimistic
towards robots, resulting in an unforgiving discordance between reality and
expectations and, ultimately, egregious teaming failures. This study will
address a fundamental cause for such a discordance due to different
understandings of the task domain between the human and the robot. In such
situations, it is crucial for the robot to understand how to reconcile the
discrepancy to maintain proper teaming. The framework to expand the
applicability of robotic technologies aligns with the broad call for co-robot
development. It represents a key enabler of interpretable and safe robots for
human-robot interaction. The educational goal is to innovate robotics education
to excite and attract students, train the next generation of scientists and
engineers in human-robot collaboration, engage the public audience in the
discussion, and boost trust in robotics technologies. The activities will
benefit K-12 students, undergraduate and graduate students, and students from
underrepresented groups.&lt;br/&gt;&lt;br/&gt;The specific research goal is to
address the different understandings of the task domain between the human and
the robot, referred to as reflective domain models, by developing model
reflective planning and learning methods to form the theoretical and algorithmic
foundation of Reflective Robotics. The key to containing such reflective domain
models is for the robot to maintain estimates of the true domain model and the
human’s understanding of it and utilize both to inform its operation. In
particular, 1) Model Reflective Planning contributes uniquely to the paradigm
shift in planning to generalize planning methods to open-world domains for real-
world applications. In contrast to the traditional planning methods that depend
only on a single domain model, model reflective planning also considers the
human’s understanding of it. A Bayesian approach is to actively model such an
understanding while incorporating the hierarchical information as state and
action abstractions to inform planning methods. As such, model reflective
planning contributes to the realization of real-world autonomy for robotic
teammates. 2) Model Reflective Learning advocates a paradigm shift in the design
of learning methods to generalize to situations with reflective models, which
are the norm rather than the exceptions with non-expert users. A framework based
on entropy augmented reinforcement learning integrated with variational
inference will be investigated. It avoids a pitfall by addressing a critical gap
in the existing learning systems where human users can mislead learning in non-
trivial and systematic ways. At the same time, these results will provide an
exciting new foundation for the PI’s long-term career in robotics and generate
new growth and leadership opportunities in the
community.&lt;br/&gt;&lt;br/&gt;This project is supported by the cross-
directorate Foundational Research in Robotics program, jointly managed and
funded by the Directorates for Engineering (ENG) and Computer and Information
Science and Engineering (CISE).&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.