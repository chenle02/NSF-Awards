* 2005209
* E2CDA: Type II: Non-Volatile In-Memory Processing Unit: Memory, In-Memory Logic and Deep Neural Network
* CSE,CCF
* 08/01/2019,08/31/2021
* Deliang Fan, Arizona State University
* Continuing Grant
* Sankar Basu
* 08/31/2021
* USD 117,005.00

The objective of this project is to explore leveraging emerging nanoscale spin-
orbit torque magnetic random access memory (SOT-MRAM) to develop a non-volatile
in-memory processing unit that could simultaneously work as non-volatile memory
and a co-processor for next-generation energy efficient and high performance
computing system. Such energy efficient in-memory computing system integrates
logic and memory units by exploring innovations from emerging spintronic device
technology to non-Von Neumann architecture, which is targeting to tackle power
wall and memory wall bottlenecks in traditional computing system. It will be
crucial for industry and academia to identify next-generation energy efficient
and high performance computing platform design. The project also has education
and outreach components including new curriculum in post-CMOS devices and
circuits for undergraduate/graduate students, engineering outreach to diverse
population and other underrepresented groups at the University of central
Florida. The project will also directly involve minority and female graduate/
undergraduate students.&lt;br/&gt;&lt;br/&gt;The proposed research requires
synergistic exploration spanning from device technology to architecture
innovation. Specifically, it consists of three research thrusts: (i) exploring
novel SOT-MRAM memory array that could implement in-memory logic (AND/OR/XOR)
without add-on logic circuits; (ii) investigating non-volatile in-memory
processing unit (MPU) architecture that could simultaneously work as nonvolatile
memory and co-processor to pre-process raw data within memory to accelerate
data/computing intensive applications without sacrificing memory capacity; (iii)
exploring MPU to implement in-memory convolution to greatly reduce data
communication and accelerate state-of-the-art deep learning convolutional neural
networks.