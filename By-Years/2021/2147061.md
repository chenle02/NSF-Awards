* 2147061
* FAI: An Interpretable AI Framework for Care of Critically Ill Patients Involving Matching and Decision Trees
* CSE,IIS
* 07/01/2022,06/30/2025
* Cynthia Rudin, Duke University
* Standard Grant
* Sylvia Spengler
* 06/30/2025
* USD 625,000.00

This project introduces a framework for interpretable, patient-centered causal
inference and policy design for in-hospital patient care. This framework arose
from a challenging problem, which is how to treat critically ill patients who
are at risk for seizures (subclinical seizures) that can severely damage a
patient's brain. In this high-stakes application of artificial intelligence, the
data are complex, including noisy time-series, medical history, and demographic
information. The goal is to produce interpretable causal estimates and policy
decisions, allowing doctors to understand exactly how data were combined,
permitting better troubleshooting, uncertainty quantification, and ultimately,
trust. The core of the project's framework consists of novel and sophisticated
matching techniques, which match each treated patient in the dataset with other
(similar) patients who were not treated. Matching emulates a randomized
controlled trial, allowing the effect of the treatment to be estimated for each
patient, based on the outcomes from their matched group. A second important
element of the framework involves interpretable policy design, where sparse
decision trees will be used to identify interpretable subgroups of individuals
who should receive similar treatments.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;The
matching techniques developed in this project will be within the new family of
"almost-matching-exactly" (AME) techniques. AME techniques use machine learning
on a training set to determine how to construct high-quality matched groups. In
applying AME techniques to analyze seizure risk and treatment for critically ill
patients, there are two major challenges that this project addresses: how to
incorporate mechanistic models for drug absorption, and how to perform
uncertainty quantification. Importantly, the project also addresses the release
of AME code in several formats to be used by non-experts. The policy design
aspect of the project involves the optimization of sparse decision trees. This
project involves a close collaboration between experts in machine learning,
causal inference, databases, and neurology, with the goal to improve patient
care in high-stakes hospital settings where experiments cannot be conducted, and
the only way to assess causal effects is through the analysis of observational
data.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has
been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.