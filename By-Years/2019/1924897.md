* 1924897
* NRI: FND: Consistent distributed visual-inertial estimation and perception for cooperative unmanned aerial vehicles
* CSE,IIS
* 10/01/2019,09/30/2023
* Guoquan Huang, University of Delaware
* Standard Grant
* Juan Wachs
* 09/30/2023
* USD 380,049.00

This project is in response to the emerging demand for ubiquitous deployment of
autonomous robots in real-world applications. In particular, thanks to their
small size, agile maneuverability, and low-altitude flight ability even in
complex environments, unmanned aerial vehicles (UAVs) have witnessed significant
progress over the last decade. The ubiquitous availability of small and
inexpensive UAVs that are equipped with sensing, processing, and communication
capabilities, will make it possible to deploy them in teams that can collaborate
to accomplish missions more efficiently and robustly than a single vehicle.
Assisted by technological advances in sensing, computing, communication, and
hardware design and manufacturing, in the coming years, cooperative UAVs will
become valuable tools in critical applications ranging from environmental
monitoring and emergency response to precision agriculture. However, when
developing cooperative UAV systems, many challenges remain, among which, one of
the biggest is the stringent resource limitations (such as limited computation
power, communication bandwidth, and energy) that UAVs are faced with. Performing
cooperative estimation and perception under resource constraints, incurs many
challenges that must be addressed during the UAV operations as well as during
the design of UAV systems. &lt;br/&gt;&lt;br/&gt;In this project, the
investigators will design scalable, robust and distributed state estimation and
3D perception for cooperative UAVs using visual and inertial measurements under
computation and communication constraints, thus providing 3D scene understanding
and spatial cognition to support intelligent decision making. To this end,
resource-adaptive consistent visual-inertial estimation will be formulated as
constrained optimization to optimally utilize available resources. Leveraging
deep learning/AI techniques, the project team will design deep neural networks
to power visual-inertial 3D perception in order to semantically and spatially
understand environments. To achieve optimal performance for given resources or
determine cost-effective system design for desired performance, the project team
will develop formal tools for characterization and co-design of UAV hardware and
software systems. By technologically enabling ubiquitous deployment of UAVs, the
results of this project will foster innovative applications in robotics such as
aerial transportation during humanitarian aid and disaster relief, thus boosting
economic development. Moreover, this project will promote hands-on learning in
undergraduate education in mechanical engineering and enrich graduate curriculum
in robotics, as well as create opportunities for students to perform meaningful
research.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.