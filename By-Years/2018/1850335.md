* 1850335
* CRII: CHS: Experimental Studies of Human Trust in Machine Learning
* CSE,IIS
* 04/15/2019,03/31/2023
* Ming Yin, Purdue University
* Standard Grant
* Todd Leen
* 03/31/2023
* USD 174,992.00

Machine learning (ML) has been applied to various domains including finance,
healthcare, urban operations, and targeted news and advertising. They achieve
great success uncovering insights from massive data and advancing decision
making. Despite widespread applications, scientific understanding of peoples'
trust or lack of trust in ML approaches is lacking, while the success of human-
machine collaborations requires a deeper understanding of trust. This project
advances the understanding of lay people's trust in ML through large-scale
randomized human-subject experiments. The project will result in theoretical
insights on the formation and maintenance of trust between humans and ML
systems, and practical insights for designing systems acceptable to people.

Leveraging existing theoretical models of trust in automation, this project will
answer three fundamental questions related to lay people's trust in machine
learning. How does the performance of an ML system (correctness, reliability,
and predictability) affect people's trust in it? How does its interpretability
affect people's trust in it? How do the performance and interpretability
interact with each other to influence trust? The project will:(1) advance
theoretical and empirical understanding about the development and maintenance of
trust in ML systems (and compare with trust in conventional automated systems),
(2) provide design guidelines that help instill trust in ML systems, and (3)
develop an experimental framework for evaluating and benchmarking
trustworthiness of ML systems in a systematic manner.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.