* 2227018
* CAREER: Scalable Computational Seismology for All
* CSE,OAC
* 05/01/2022,06/30/2026
* Eileen Martin, Colorado School of Mines
* Continuing Grant
* Juan Li
* 06/30/2026
* USD 373,414.00

Computational seismology methods analyze data that measure vibrations of the
Earth. These methods allow scientists to understand earthquake hazards, to
measure stability of the ground underneath structures, to monitor groundwater
systems, to study changes in threatened Earth systems such as glaciers and
permafrost, to safely and efficiently explore natural resources underground, and
to monitor civil infrastructure health, among other applications. Seismology has
undergone a radical shift recently; new sensor technologies have made data
collection much easier, enabling hundreds to thousands of times larger datasets
that can be used for detailed studies of larger regions for long periods of
time. Most scientists cannot use these data because: (1) data are only shared
internally among groups that have new sensors, (2) public seismology data
storage facilities cannot support such large data quantities, and (3) most
geoscientists do not have the computational resources to analyze the data.
Because of these three issues, there is an inequitable research environment,
much data remains unexplored, and important geoscience discoveries cannot occur.
While there are ongoing efforts to address the first issue, without major
cyberinfrastructure advances addressing the second and third issues newly
acquired data is unlikely to be fully analyzed. This project aims to create new
computational algorithms, software and models of open data sharing to ensure
that any geoscientist can glean valuable insights from large-scale seismology
data. The education and outreach program will create opportunities for more
people to participate in mathematical modeling and large-scale data analysis for
science and engineering applications. The project PI will develop and strengthen
existing efforts to support diverse and inclusive research and learning
environments. She will continue to develop a program to introduce women
undergraduates to mathematics research, growing it to be a sustainable multi-
faculty course serving more students from underrepresented groups. The project
will increase the impact of the annual data science conference led by the PI.
The conference features research by women data scientists and tutorials on
modern data science techniques, and connects the interdisciplinary data science
community on a rural campus.&lt;br/&gt;&lt;br/&gt;The project will derive and
analyze new geoscience algorithms, develop community software and explore models
of open data distribution. The project goal is to ensure that any seismologist
can gain valuable geophysical insights from extreme-scale seismic data in the
field, at institutions with limited computing resources, and on modern high
performance computing (HPC) systems. Expertise in large-scale seismic sensing,
mathematics, high-throughput computational science, and algorithm design are
necessary to achieve these advances. The project proposes a new model for public
seismology data archives that allows for the storage of lossy-compressed data
and data products, thus creating a new capacity to host ultra-high-density and
large-scale seismic data, without displacing existing systems for high-quality
seismometer data. To address large-scale data analysis, the PI has previously
created several scalable algorithms, and theoretical analyses suggest that a
complete suite of scalable, parallelizable algorithms for multiple types of
passive seismic data processing can be developed. Many of the algorithms operate
directly on compressed information without reconstructing the original data,
which reduces costly data movement. The project will develop fast serial and
parallel software algorithm implementations, and investigate the use of
accelerator hardware for high computational efficiency. For each algorithm the
project will theoretically derive and computationally verify trends governing
tradeoffs between computational efficiency, memory footprint, and end-to-end
accuracy specific to the geophysical analyses. The algorithms will incorporate
error bounds for realistic non-idealized data and will be included in predictive
software for geoscientists to make informed decisions prior to requests for
compressed data or data products. The new methods will be tested by applying
them to cutting-edge passive seismic data at the scale of tens to hundreds of
terabytes. The data will enable seismology analyses in for urban hydrology and
geotechnical engineering, and also analyses to aid in understanding glacier
movements to improve climate models via improved boundary conditions and
mechanistic understanding. In addition to earthquake seismology, hydrology,
geotechnical engineering, and cryosphere studies, the methods developed can be
applied to many high-throughput computational science problems utilizing sparse
or compressed representations (e.g., structural health monitoring, imaging
science, solar physics, radioastronomy, wireless communications, industrial
facility monitoring). To increase adoption of new methods by geoscientists, the
project will develop tutorials, promote scientific community collaboration, and
organize research workshops.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.