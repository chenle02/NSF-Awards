* 1763642
* RI: Medium: Recognizing, Mitigating and Governing Bias in AI
* CSE,IIS
* 09/01/2018,08/31/2023
* Olga Russakovsky, Princeton University
* Standard Grant
* Roger Mailler
* 08/31/2023
* USD 811,016.00

Artificial Intelligence (AI) technologies mediate our interactions with the
world and our daily decision making, ranging from shopping to hiring to
surveillance. The development of rich AI algorithms able to process and learn
from unparalleled amounts of data holds promise for making impartial, well-
informed decisions. However, such systems also absorb human biases, such as
gender stereotyping of activities and occupations. Left unchecked, they will
perpetuate these biases on an unparalleled scale. A steady stream of press
confirms that this is a widespread problem in real-world applications. This
research brings together an interdisciplinary team to develop the science of AI
bias. The findings will impact AI researchers and developers (through novel
methodologies), computational social scientists (through a deeper study of human
biases at web scale), educators and policy makers (through the comprehensive
analysis of bias), and downstream users of AI technology.
&lt;br/&gt;&lt;br/&gt;Compared to applications such as criminal risk scoring
where fairness has traditionally been studied, modern AI systems are
characterized by massive datasets, complex deep models and an unprecedented
breadth of applications. This results in a wider spectrum of biases with complex
propagation pathways, requiring an in-depth scientific investigation. The
project develops the tools and techniques for recognizing, mitigating and
governing bias in AI by combining expertise in deep learning, crowdsourcing and
dataset curation, AI ethics, analyzing inference risk, web measurement, and
science and technology studies. The component on recognizing bias includes an
application of the Implicit Association Test combined with zero-shot learning to
understand the societal bias of web corpora. Mitigating bias includes bridging
active learning with research on adversarial examples for AI models. Governing
bias includes a qualitative and quantitative study of downstream bias effects.
The research is designed to be tightly connected, as for example when the
recognition of curation bias in datasets leads to techniques in mitigating bias
through enforcing group fairness in deep learning to governing bias in deployed
system through developing bias observatories. The study will include
advancements in machine learning (decomposing deep architectures, adapting
reinforcement learning, exploring domain adaptation), human-computer interaction
(developing novel active learning techniques, studying model interpretability),
and digital ethnography (studying the effect of AI bias on culture, establishing
an AI bias taxonomy). It will serve as a bridge between these fields,
establishing tighter connections between them.&lt;br/&gt;&lt;br/&gt;This award
reflects NSF's statutory mission and has been deemed worthy of support through
evaluation using the Foundation's intellectual merit and broader impacts review
criteria.