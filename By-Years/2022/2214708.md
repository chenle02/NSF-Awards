* 2214708
* MRI: Acquisition of the LanguageLens for Large-Scale Language Modeling
* CSE,CNS
* 08/01/2022,07/31/2025
* Joshua Gubler, Brigham Young University
* Standard Grant
* Daniel Andresen
* 07/31/2025
* USD 1,014,815.00

Machine learning is revolutionizing many parts of society, but training the very
best models requires tremendous computing resources that are often out of reach
for academic groups. This project therefore acquires a special-purpose
instrument, named the LanguageLens, that is designed to process vast amounts of
natural language text. The LanguageLens will support research in natural
language processing, deep learning, computational linguistics, crisis
informatics, conversational AI, neural machine translation, and legal corpus
linguistics, and will enable academic research to advance both the machine
learning needed to train large models, as well as societially relevant
applications of those models.&lt;br/&gt;&lt;br/&gt;The LanguageLens is a high-
performance GPU cluster that balances compute, storage and internode
communication to support a variety of demanding NLP-based workloads. The
LanguageLens will be focused on solving research projects that have the
potential for transformational, interdisciplinary impact across a wide variety
of fields. A key area of focus for the instrument is the ability to train new
large-scale language models and to examine their inner workings in real-time.
Language models will be trained with specific downstream applications in mind,
on novel corpora as well as with novel neuro-symbolic architectures, to help
derive insight from the resulting weights. The LanguageLens will prioritize
support for research that addresses pressing societal problems. It will also
provide authentic workforce training and educational experiences for students:
as the resource gap between industry and academia grows, it is increasingly
difficult to give them opportunities to pursue high-impact research that
involves huge models and datasets. Finally, as many companies refuse to release
the pretrained weights of their models, a central goal is to make trained
weights freely available to everyone, subject to ethical considerations, to
drive national impact for both industry and academia. Project resources such as
code, publications, datasets and pretrained models will be available through the
LanguageLens website at https://ll.cs.byu.edu/.&lt;br/&gt;&lt;br/&gt;This award
reflects NSF's statutory mission and has been deemed worthy of support through
evaluation using the Foundation's intellectual merit and broader impacts review
criteria.