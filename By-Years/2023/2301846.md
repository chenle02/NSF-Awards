* 2301846
* ERI: Developing a Trust-supporting Design Framework with Affect for Human-AI Collaboration
* ENG,CMMI
* 07/01/2023,06/30/2025
* Ting Liao, Stevens Institute of Technology
* Standard Grant
* Kathryn Jablokow
* 06/30/2025
* USD 200,000.00

This Engineering Research Initiation (ERI) project aims to understand the role
of affect in developing trust during collaborations between users and Artificial
Intelligence (AI) system for engineering design, which will then inform design
guidelines for improving trust and collaboration outcomes. Modern AI systems
have become more interactive and sophisticated than legacy automated systems.
However, trust between humans and AI systems is in a potential crisis. While
affect is an essential element of trust development and can significantly
influence people’s tendency to collaborate, it has not been studied
quantitatively in human-AI collaboration or modeled holistically with respect to
system design attributes. To address this gap, this research will: (1) examine
the influence of affect in user trust during interactions with an AI-powered
conversational agent; (2) investigate how trust in AI influences human-AI
collaboration; and (3) develop a value model that considers affect and system
attributes comprehensively. This research will advance knowledge of trust
development with an emphasis on affect and the design of AI systems. The
knowledge will inform a design framework that enables AI systems to be trusted,
accepted, and utilized more to augment human capabilities in completing complex
tasks. Improved human-AI collaboration will enhance the quality of human life
and potentially benefit disadvantaged populations, such as senior citizens, who
are not early technology adopters, as well as telehealth applications, where
trust can be tenuous.

The overarching goal of this project is to advance knowledge about the nature of
trust development in human-Artificial Intelligence (AI) collaboration and how
engineering designers can enhance trust in the design of AI systems to improve
collaboration outcomes. The research examines the effect of affect, system
performance, and system characteristics on user trust in an AI-powered
conversational agent for a collaborative design task, and investigates how
human-AI trust influences design outcomes. The research will holistically model
users’ value judgments using a modified conjoint analysis of both affect and
system-related attributes. The results will inform an innovative design
framework that indicates the relative importance of the attributes and favorable
design directions for human-AI collaboration. The research has the potential for
broad societal impact by providing tangible guidelines for how to improve and
maintain trustworthy human-AI collaborations, which augment the human capability
of completing cognitively demanding tasks and may particularly benefit
disadvantaged populations. The research serves as the basis for a broader range
of design applications beyond web interfaces and dialogues, and will provide
transformative knowledge of human-AI interactions in virtual environments and
for complex systems.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.