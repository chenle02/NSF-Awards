* 2145198
* CAREER: Overcoming bias in computer vision: Building fairer systems and training diverse leaders
* CSE,IIS
* 06/15/2022,05/31/2027
* Olga Russakovsky, Princeton University
* Continuing Grant
* Jie Yang
* 05/31/2027
* USD 124,737.00

Artificial Intelligence (AI) systems have become an integral part of daily life.
These systems provide access to information about current events, guide shopping
experiences, and allow communication across language boundaries. For example,
computer vision systems (which make automated decisions based on visual
information from photos or videos) are becoming increasingly deployed in high-
stakes applications such as autonomous driving or medical diagnosis. However,
automated AI systems have been known to capture, propagate and even amplify
historical biases, stereotypes, and disparities: known issues in computer vision
include racial bias in face recognition, geographic bias in object detection,
and gender bias in activity understanding, to name a few. This project focuses
on developing practical bias mitigation strategies for computer vision systems.
The work is integral to ensuring the ethical and equitable deployment of
computer vision in high-stakes applications. &lt;br/&gt;&lt;br/&gt;There is a
rich and growing literature on mitigating social bias in AI systems generally.
Much of it studies bias in models with tabular or text input, such as criminal
justice records or resumes. Mitigating bias in computer vision requires unique
approaches: since the input tokens (single pixels) are uninformative, revealing
problematic patterns in data and models is particularly challenging. The project
focused on bias in the form of inappropriate correlations between visual
protected attributes and predictions of recognition models. It features a multi-
pronged approach, which includes developing strategies for mitigating bias in
the data (improving data collection processes and leveraging synthetic data),
studying how bias propagates from data into downstream models (designing novel
interpretability techniques that are well-suited for this goal), and developing
strategies for directly mitigating bias in the models (leveraging novel
benchmarks and metrics to inform model design). In addition, the project also
tackles the problem of homogeneity among current AI researchers, which is one of
the root causes of AI bias. Going beyond the technical innovations, the
educational component focuses on training and providing leadership pathways for
students from historically underrepresented groups starting as early as high
school, in partnership with the national nonprofit
AI4ALL.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has
been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.