* 2131946
* SHF: Small: Holistic Design of High-performance and Energy-efficient Accelerators for Graph Neural Networks
* CSE,CCF
* 10/01/2021,09/30/2024
* Ahmed Louri, George Washington University
* Standard Grant
* Danella Zhao
* 09/30/2024
* USD 500,000.00

Graph Neural Networks (GNNs) have emerged as one of the most powerful techniques
for next-generation learning systems, and are gaining attention in many high-
impact domains such as graph mining (graph machine, graph clustering), biology
(drug discovery, disease classification), traffic networks (traffic prediction),
recommendation systems (user-item prediction, social recommendation), e-commerce
analysis, stock market prediction, natural language processing (text
classification, neural machine translation), image processing (image
classification, object detection, semantic segmentation), and autonomous
systems, among many others. The explosive growth of these applications has
created an enormous demand for customized accelerator design to satisfy the
computational requirements of GNNs, since many of these applications require
high-throughput and energy-efficient GNN inference. Conventional deep neural
network (DNN) accelerators cannot efficiently process GNNs due to the
combination of irregular memory accesses, dynamic parallelism imposed by the
graph structure, and the dense computation in learning algorithms. This project
addresses these challenges with a holistic design framework spanning
architecture study, Network-on-Chip (NoC) design, machine-learning algorithms
development, and algorithm-architecture co-optimization with the aim of
designing energy-efficient and high-performance accelerator architectures for
GNNs. The cross-cutting nature of this project will offer valuable insights and
solutions to many critical problems in GNN accelerator design. The research will
also play a major role in education by integrating discovery with teaching and
training. The outcomes of this project will be widely disseminated to
researchers, engineers, and educators through technical publications and
presentations. &lt;br/&gt;&lt;br/&gt;The goal of this project is to develop GNN
accelerators with much-improved performance and energy efficiency for a wide
variety of graph-based machine learning applications. To achieve this goal, this
project proposes: (1) the design of a morphable GNN accelerator architecture and
a reconfigurable NoC to satisfy the computational demands of various GNNs, (2)
the development of a GNN accelerator/algorithm co-optimization exploration
framework to maximize both inference accuracy and performance (latency, area,
energy, etc.) for given graph-based machine learning tasks, (3) the development
of an extensive modeling and simulation framework for GNN accelerators that will
be used to validate the proposed design approach, and (4) the implementation of
a small-scale prototype of the proposed accelerator using Field Programmable
Gate Arrays (FPGAs) and its application to real-world problems. This timely
research will greatly advance the state-of-the-art of GNN acceleration, benefit
both the computing and machine-learning communities, and provide strong
implications on advancements in society and the US computing industry-at-
large.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has
been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.