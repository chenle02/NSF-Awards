* 2052394
* SBIR Phase I:  Technology Translation of a Universal Summarization System
* TIP,TI
* 08/01/2021,07/31/2022
* Mehraveh Salehi, SUMMARY ANALYTICS INC.
* Standard Grant
* Peter Atherton
* 07/31/2022
* USD 276,000.00

The broader impact of this Small Business Innovation Research (SBIR) Phase I
project is to make machine-learning (ML) and artificial intelligence (AI) less
costly, less biased, more accurate, more scalable, and easier to use through the
process of commercializing “universal data summarization.” This summarization
process works on any kind of data and significantly reduces dataset size without
loss of information. Cost reductions include computational, core memory,
storage, labor, and energy, all while reducing AI's environmental impact to
provide "green AI." Universal summarization can also be used to measure and
remove bias in data used to train AI/ML systems. Biases, caused by concepts in
the data that are vastly over-represented while others are under-represented,
will be reduced since for a small summary to be representative, it must be
diverse and inclusive. In addition, accuracy will be increased by improving
human analytics. Many data science tasks involve analysis by humans who must
examine data to discover insight. These are arduous, expensive, time-consuming,
and error-prone tasks made worse by human alert and decision fatigue caused by
redundancy and repetitiveness. By reducing size and eliminating redundancy,
human fatigue is reduced, human accuracy and efficiency are increased, and
annotation costs are mitigated. &lt;br/&gt;&lt;br/&gt;This Small Business
Innovation Research (SBIR) Phase I project will develop and commercialize the
ability to simply and affordably perform universal summarization of massive
datasets. A summarization is a process that selects from a dataset a small
subset of data items – the few selected summary items accurately represent the
information contained in the many remaining unselected items. The innovation is
called “calibrated submodular summarization,” a technology that involves
quickly, cost-effectively, and accurately measuring information in subsets of
data, and then algorithmically selecting small subsets that have mathematical
information content guarantees. This technology strips away redundancy, leaving
behind an efficient representation of the core information in the dataset. The
proposed activities will create a commercial service that can summarize massive
amounts of data (of any kind) quickly, easily, and without requiring user
expertise in machine learning, data science, or submodularity. This will greatly
reduce costs, time-to-market, environmental impact and data bias for any data-
rich industry.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission
and has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.