* 1255314
* EAGER: Characterizing and Exposing Bias in Social and Mainstream Media
* CSE,CNS
* 09/01/2012,08/31/2013
* Nicholas Feamster, University of Maryland, College Park
* Standard Grant
* Nina Amla
* 08/31/2013
* USD 185,000.00

An increasing number of organizations and information conduits, ranging from
news outlets to information intermediaries like search engines can censor or
manipulate citizens' access to information. The practices of these
intermediaries can create "filter bubbles'', whereby the information any user
sees is highly controlled by an information intermediary and depends largely on
factors that may not be immediately apparent, such as the user's geographic
location or past behavior. &lt;br/&gt;&lt;br/&gt;This project will study the
effects of filter bubbles on the availability and sentiment of news sources in
different geographic regions, for both social and mainstream media. To study
these effects, this project will build a large-scale, distributed monitoring
system to discover and view news sources from different geographic regions, and
for users with different context. The first portion of the project, which will
be to characterize filter bubbles in news media, will involve two separate
studies: one for information intermediaries for mainstream news media, and one
for social media. The second portion of our project will involve developing and
deploying a prototype system that exposes bias in news sources, to provide users
with systematic ways to observe and evaluate the extent of bias that may exist
in media sources. The last component of our project will investigate how the
presenting evidence of bias or information manipulation affects users'
perceptions of and attitudes towards bias in both mainstream and social media.
To do so, the project will design and instrument user studies through software
distribution, recruitment, and laboratory-based studies, where cases of bias or
information manipulation are presented to users through different types of
interfaces. These studies will highlight instances of bias using different
visualizations and interfaces and observe how users' attitudes change depending
on whether and how this information is presented.