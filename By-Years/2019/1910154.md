* 1910154
* III: Small: Towards Explainable Recommendation Systems
* CSE,IIS
* 10/01/2019,04/30/2023
* Chirag Shah, Rutgers University New Brunswick
* Standard Grant
* Sylvia Spengler
* 04/30/2023
* USD 507,735.00

Recommendation systems are essential components of our daily life. Today,
intelligent recommendation systems are used in many Web-based systems. These
systems provide personalized information to help human decisions. Leading
examples include e-commerce recommendations for everyday shopping, job
recommendations for employment markets, and social recommendations to make
people better connected. However, most recommendation systems merely suggest
recommendations to users. They rarely tell users why such recommendations are
provided. This is primarily due to the closed nature algorithms behind the
systems that are difficult to explain. The lack of good explainability
sacrifices transparency, effectiveness, persuasiveness, and trustworthiness of
recommendation systems. This research will allow for personalized
recommendations to be provided in more explainable manners, improving search
performance and transparency. The research will benefit users in real systems
through researchers? industry collaboration with e-commerce and social networks.
New algorithms and datasets developed in the project will supplement courses in
computer science and iSchool programs. Presentation of the work and demos will
help to engage with wider audiences that are interested in computational
research. Ultimately, the project will make it easier for humans to understand
and trust the machine decisions.&lt;br/&gt;&lt;br/&gt;This project will explore
a new framework for explainable recommendation that involves both system
designers and end users. The system designers will benefit from structured
explanations that are generated for model diagnostics. The end users will
benefit from receiving natural language explanations for various algorithmic
decisions. This project will address three fundamental research challenges.
First, it will create new machine learning methods for explainable decision
making. Second, it will develop new models to generate free-text natural
language explanations. Third, it will identify key factors to evaluate the
quality of explanations. In the process, the project will also develop
aggregated explainability measures and release evaluation benchmarks to support
reproducible explainable recommendation research. The project will result in the
dissemination of shared data and benchmarks to the Information Retrieval, Data
Mining, Recommender System, and broader AI
communities.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission
and has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.