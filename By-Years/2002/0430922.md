* 0430922
* Capacity and Coding Techniques for Channels with Memory and Feedback
* CSE,CCF
* 09/01/2004,08/31/2007
* Sekhar Tatikonda, Yale University
* Continuing Grant
* Sirin Tekinay
* 08/31/2007
* USD 200,001.00

Abstract:&lt;br/&gt;&lt;br/&gt;The field of distributed networking and
computation is on the verge of a technological revolution. Emerging applications
in national security, transportation, communication, and commerce require
distributed networks to be capable of multi-user communication and collaborative
signal and information processing. One very important component of these
networks is the underlying communication channel. These channels have memory,
are often time-varying, and are often poorly modeled. Furthermore, in many of
these networks, the nodes are power limited and only have modest computational
resources. Feedback is a very important, though poorly understood, feature of
modern communication systems. Feedback is useful because it can increase the
capacity of a given channel with memory; it can increase the error exponent and
hence decrease latency; it often leads to simpler coding schemes; and it allows
the encoder to adapt to unknown channel variations.&lt;br/&gt;&lt;br/&gt;This
research involves: (1) determining the fundamental limits and tradeoffs between
the quality of channel feedback and the resulting Shannon capacity of the
channel; (2) developing the sequential rate distortion theory for joint-source
channel coding; (3) analyzing the convergence and accuracy of message-passing
algorithms in general; and (4) developing message-passing, error-correcting
codes specialized for channels with memory and feedback. The investigators use
tools from the study of graphical models to jointly treat communication
complexity and computational complexity.&lt;br/&gt;&lt;br/&gt;