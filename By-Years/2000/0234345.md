* 0234345
* SOFTWARE:     Compiler Techniques for High-Performance Computing in Java
* CSE,CCF
* 02/01/2003,01/31/2006
* Ken Kennedy, William Marsh Rice University
* Continuing Grant
* Almadena Chtchelkanova
* 01/31/2006
* USD 320,000.00

Since its debut in 1995, Java has gained acceptance rapidly among software
developers as the language of choice for many applications where portability and
reliability are paramount. Java's support for clean object-oriented (OO) design,
write once, run anywhere portability, comprehensive static type checking,
automatic storage management, and safe execution semantics have dramatically
improved programmer productivity and software reliability. Despite of this high
level of interest, Java has made little headway in the arena of high-performance
computing because it is too slow. The performance penalty is particularly acute
when Java programs are written in a clean, object-oriented style that makes
extensive use of polymorphism. Our recent studies of Java performance show that
applications written in this object-oriented style incur performance penalties
of a factor of ten or more over applications coded in a more tedious style
similar to Fortran and C. If this performance gap cannot be bridged, the object-
oriented benefits of Java will not be realized for compute-intensive
applications, squandering an opportunity to revolutionize high-performance
programming. We propose to address this problem by conducting research into
compiler technologies that make it possible to develop applications and
component libraries using the full power of the Java language without
sacrificing significant run-time performance. Although these strategies are
suitable for use in a compiler, we will incorporate the resulting technologies
into a source-to-source optimization tool. This tool will use application
developer interaction to help optimize and package the Java software. We believe
that the development of Java implementation technology suitable for high-
performance software could catalyze a revolution in the way compute-intensive
applications are constructed enabling the solution of more difficult scientific
problems and the development of web applications that have heretofore been out
of reach. A large number of computational scientists share this vision, as
evidenced by the experimental use of Java reported in the Java Grande Forum. The
optimization of object-oriented programs has been an active area of programming
language research for nearly twenty years, but little attention has been focused
on the optimization technology required for high-performance numerical
computation. Prior to Java, type-safe object-oriented languages were not
considered candidates for numerical applications. To achieve high performance
for polymorphic numerical code, the language implementation must perform class
specialization, which clones a type-specific version of a class containing
polymorphic fields, object inlining, which replaces a variable containing a
reference to an object by a tuple of variables containing the object's fields
and method inlining, which replaces method calls by specialized versions of the
correspondingmethod body. We believe that a judicious application of these three
transformations combined with standard instruction-level code optimization can
translate polymorphic object-oriented source programs to machine code comparable
in quality to optimized Fortran. In addition to these necessary optimizations,
we propose two novel compilation strategies: almostwhole-program compilation,
which relaxes the above optimizations' requirement of whole-program compilation
to allow for more programming flexibility, and semantics modifying
transformations which improve the communication between the compiler and the
programmer to allow for even more aggressive optimizations. We also propose to
apply the technologies resulting from this research to optimize several
scientific applications written in Java.