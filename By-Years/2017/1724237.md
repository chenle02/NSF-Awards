* 1724237
* S&amp;AS: FND: COLLAB: Learning Manipulation Skills Using Deep Reinforcement Learning with Domain Transfer
* CSE,IIS
* 09/01/2017,08/31/2022
* Kate Saenko, Trustees of Boston University
* Standard Grant
* Jie Yang
* 08/31/2022
* USD 316,000.00

This project develops new methods of using deep reinforcement learning to solve
real world robotics problems. The project focuses on robotic manipulation tasks
such as grasping, opening doors, helping out in the home, performing repairs
aboard Navy ships, etc. The key operation in all of the above is the ability for
the robot to reliably manipulate objects, parts, or tools with its hands in
order to perform a task. The project leverages deep reinforcement learning: a
new approach to robotic learning that is capable of learning both perceptual
features and control policies simultaneously. This project could have important
benefits for a variety of practical applications including: explosive ordnance
disposal for our military, materials handling aboard Navy ships, dexterous
robotic assistants for NASA astronauts in space, assistive technologies that
could help seniors age in place longer, better capabilities for handling
radioactive materials during nuclear cleanup, assistance for ergonomically
challenging tasks in manufacturing, and general assistance in the office and the
home.&lt;br/&gt;&lt;br/&gt;This research investigates novel deep reinforcement
learning approaches for robotic grasping and manipulation that work well in
previously unseen, unstructured environments and compose end-to-end tasks from
simpler sub-task controllers. The research is built on two main results from
research team's recent work, the deep learning approach to grasping and domain
adaptation methods for deep neural networks. The research is guided by the
following three key ideas: 1) learning in simulation and then using domain
transfer techniques to adapt the solutions to reality; 2) simplifying learning
for visuomotor control by using planning to estimate the value function; and 3)
using symbolic task and motion planning to perform end-to-end tasks by
sequencing learned controllers and planned arm/hand motions. The research team
performs extensive evaluations to ensure that the system is able to perform
novel instances of a task, e.g., those in a context that the robot has not seen
before.