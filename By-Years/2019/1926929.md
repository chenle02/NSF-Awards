* 1926929
* EAGER AI-DCL Collaborative Research: Understanding and Overcoming Biases in STEM Education Using Machine Learning
* CSE,IIS
* 09/01/2019,08/31/2022
* Nilanjana Dasgupta, University of Massachusetts Amherst
* Standard Grant
* Todd Leen
* 08/31/2022
* USD 23,998.00

Diversity is the cornerstone of innovation and essential for the progress of
science. However, the number of female students in engineering, computing, and
physical sciences in the United States remains strikingly low. The lack of
diversity in science, technology, engineering, and mathematics (STEM) education
is, to a significant extent, due to biases at different stages of schooling
(e.g., different perceptions of math achievements by male and female students,
lack of encouragement for female student enrollment in advance placement
classes, stereotypes influencing college course selection). These biases appear
as early as middle school: a critical period when student's educational
experience can significantly influence their academic choices in high school
and, ultimately, in deciding whether or not to enroll in STEM majors in college.
In order to broaden the participation of women in STEM, it is critical to
identify factors and practices in middle school learning environments that may
attract (or repel) students into science. This award will use machine learning
(ML) to develop new, automated, and data-driven methods for discovering and
monitoring biases in STEM classrooms, focusing on middle school and early
adolescence science and mathematics education.&lt;br/&gt;&lt;br/&gt;The project
combines methods from social psychology, machine learning, and information
theory to create algorithmic tools that monitor middle school student, teacher,
and school-level data for factors that impact students' engagement in STEM.
These tools will (i) help identify pedagogical or socio-economic factors that
have a disparate impact on the decisions made by female students, (ii) predict
which students are most vulnerable to being discouraged from pursuing STEM
fields, and (iii) inform effective interventions that help close the gender gap.
Despite its potential, the use of ML in education is a double-edged sword: while
ML algorithms may be able to flag discriminatory patterns, they can also
propagate biases and have an unwarranted disparate impact if left unchecked.
Thus, in parallel, this project also aims to characterize the fairness
challenges involved in deploying ML in education settings. The proposed approach
will be validated on a dataset collected during a five year period from middle
school students from across the United States.&lt;br/&gt;&lt;br/&gt;This award
reflects NSF's statutory mission and has been deemed worthy of support through
evaluation using the Foundation's intellectual merit and broader impacts review
criteria.