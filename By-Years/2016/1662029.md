* 1662029
* Integrated Computer Vision System Based on Human Eye Motion
* ENG,CMMI
* 07/01/2017,06/30/2021
* Jun Ueda, Georgia Tech Research Corporation
* Standard Grant
* Eva Kanso
* 06/30/2021
* USD 399,020.00

The goal of this project is to build a robotic vision system that mimics human
eye motions. In particular, this research will lead to an enhanced vision system
that can achieve quick scanning capability (saccadic eye motion) and smooth
object following capability (smooth-pursuit) with minimal computational overhead
and using an inexpensive generic hardware. Current state-of-the-art systems
require significant computer post-processing and expensive hardware. This
project will lead to a novel camera positioning system (hardware) and real-time
vision (software) system that does not require any post-processing and produces
ready-to-use images in real-time. To achieve this goal, the project draws upon
the biomechanical and cognitive principles of human vision. The innovative
methods and algorithms that can produce motions with speed, accuracy, and
smoothness to mimic human eye can greatly enhance capabilities of autonomous
vehicles used in a wide variety of applications such as agriculture, military,
security, and traffic monitoring. The project will integrate research and
outreach activities for K-12 and undergraduate students.
&lt;br/&gt;&lt;br/&gt;This project studies a bio-inspired dynamics-based method
for coordinating motion control and image processing where the system can
mechanically displace the field of view by a large angle between frames. The
concept behind this research is to merge the system dynamics area and image
processing area while previous studies focused solely on either mechanical
design or image processing. The method is motivated by the principles of human
vision for effective image de-blurring and panoramic image stitching. In
coordination with inherently discrete and rapid ocular movements, the developed
image processing methods inspired by ocular physiology will mimic saccades and
smooth-pursuit in a fast-moving robotic eye. A piezoelectrically driven robotic
camera positioning mechanism will be employed to demonstrate the effectiveness
of this ocular physiology-inspired approach. Hardware architecture that can
synchronize image processing and real-time motion control will be configured and
tested. A panoramic image of a scene will be generated from multiple images
acquired during saccades by removing motion blur and stitching images within a
single frame rate. The system architecture will be optimized to best coordinate
hardware and software for real-time motion control.