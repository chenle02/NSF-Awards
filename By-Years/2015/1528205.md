* 1528205
* SHF: Small: Development of Integrated Memristive Crossbar Circuits for Pattern Classification Applications
* CSE,CCF
* 07/15/2015,06/30/2018
* Dmitri Strukov, University of California-Santa Barbara
* Standard Grant
* Sankar Basu
* 06/30/2018
* USD 524,950.00

Building artificial neural networks capable of matching the performance and
functionality of their biological counterparts is one of the grand challenges in
computing. The broad goal of this research project is to address one important
aspect of this grand challenge, e.g., creating efficient hardware for
implementing artificial neural networks. Artificial neural network based
information processing, suitable for low precision applications, may indeed be
particularly important in the present day context of energy efficient computing.
If successful, this research has the potential to have broad and long lasting
societal impact by improving energy efficiency and enriching functionality of
existing electronics, and creating a large number of novel applications. The
project will involve graduate and undergraduate students, include members of
underrepresented groups and will thus help enlarge the workforce in information
and communication technologies.&lt;br/&gt;&lt;br/&gt;The high complexity,
connectivity and parallelism of neural networks make conventional technology
hardware implementations rather inefficient. The core idea of this project is to
utilize emerging memory devices, specifically memristors, which are essentially
super-dense analog nonvolatile memory devices, to implement compact and energy
efficient artificial neural networks. A particular experimental focus of the
project is on demonstration of a hybrid memristive crossbar circuit
implementation of small-scale (hundreds of neurons, thousands of synapses)
multilayer perceptron performing pattern classification task. Although such a
demonstration may only have a rather simple functionality, the resulting
classifier would have all the key features of state-of-the-art deep learning
convolutional neural network classifiers. The major focus is on the development
of training algorithms compatible with memristor switching kinetics and
investigation of the tradeoffs between complexity of hybrid circuits and
classification performance. Theoretical modeling will guide experimental work
towards most efficient implementations as well as ensure scaling of the approach
to perform practical applications. Resolving hardware challenges for relatively
simple neural networks would be essential for the development of more advanced
neural networks capable of performing complex cognitive tasks.