* 2232299
* Collaborative Research: RI: Small: Motion Fields Understanding for Enhanced Long-Range Imaging
* CSE,IIS
* 04/01/2023,03/31/2026
* Suren Jayasuriya, Arizona State University
* Standard Grant
* Roger Mailler
* 03/31/2026
* USD 149,995.00

Data-driven computer vision approaches suffer from deteriorated performance when
the input images are captured from long distance. For example, images from
unmanned aerial vehicles (UAVs), satellites, and reconnaissance cameras lack
stereo information causing 3D reconstruction and depth estimation to fail.
Turbulence caused by air and water also causes light rays to deflect from their
original path and introduces noticeable motion artifacts like blurriness and
distortion. This project develops a generalizable motion field estimator using
neural networks coupled with specific hardware settings to enhance computer
vision tasks in long-range imaging. Successful development of such a motion
field estimator can enable applications of computer vision systems at long
distances and/or under turbulent environments including UAV navigation, object
tracking and detection, and long-range monitoring. The project has broader
impact in industrial applications which leverage such technologies. In addition,
research results will be integrated into new course materials for physics-
informed computer vision and computational photography classes. The project will
provide training to underrepresented students and outreach to K-12 students
throughout its duration. &lt;br/&gt;&lt;br/&gt;This project will develop
computational solutions to decouple the entangled motion fields and use
turbulence motion to enhance visual computing applications in long-range
imaging. This research is motivated by the observation that turbulence-induced
motion fields can provide depth and sub-pixel color information, which is
crucial in restoring scenes with high-frequency details. To achieve this goal,
the project will pursue three research thrusts: 1) neural field decoupling of
object and turbulence motion; 2) reconstructing turbulence strength and flows
from passive visual imagery; and 3) motion field guided intelligent foveation
for long-range imaging. The first thrust will develop algorithms for estimating
and recovering motion fields with both object and turbulence motion by
investigating physics-based velocity fields. The second thrust will develop
tractable quantitative turbulence motion models that can be applied to both air
and water environments using deep neural networks. The third thrust will
integrate the turbulence motion field into different visual computing pipelines
to benefit long-range computer vision tasks. This project will collect a large
motion field dataset with true turbulent parameters of different media types and
turbulence strengths, which can facilitate the development of data-driven
machine learning algorithms for long-range computer
vision.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has
been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.