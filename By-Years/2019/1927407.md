* 1927407
* EAGER:AI-DCL: Understanding the Relationship between Algorithmic Transparency and Filter Bubbles in Online Media
* CSE,IIS
* 08/15/2019,12/31/2022
* Mustafa Bilgic, Illinois Institute of Technology
* Standard Grant
* Todd Leen
* 12/31/2022
* USD 299,871.00

Computer algorithms are widely used by online sites to determine the content
users see, for example, by curating news articles or recommending social media
posts. These algorithms are primarily designed to improve user experience by
showing to users the content that they are likely to be interested in. However,
there is growing evidence that these algorithms may have unintended side
effects. For example, by showing users only content that conforms with their
preexisting perceptions and beliefs, users may receive a biased subset of all
content, possibly increasing intellectual isolation, a phenomenon known as a
"filter bubble." This project promotes the progress of computational science by
investigating how and why filter bubbles form and developing new algorithms to
prevent them. Additionally, this award supports the cross-disciplinary training
of two PhD students at Illinois Tech, jointly advised by computer science and
political science faculty, and will result in new curricula for courses in
online social network analysis, algorithmic transparency, and public
policy.&lt;br/&gt;&lt;br/&gt;The technical approach of the project focuses on
two enhancements to content recommendation algorithms: 1) improving transparency
by informing the users of their reading habits, what the recommendation model
thinks of them, and why particular items are recommended; and 2) supporting rich
user interactions by enabling the user to provide feedback on model predictions
and explanations. New algorithms are developed to support transparency and
interaction for modern, neural network-based recommendation systems, scalable to
high-dimensional text domains. The project conducts extensive user studies to
measure the impact that transparency and interactions have on the formation and
severity of filter bubbles. A key aspect of this project is the development of
an open-source platform and accompanying datasets that will foster additional
research to better understand and ultimately mitigate filter bubbles. This
platform includes tools not only for identifying user preferences and making
content recommendations, but also for conducting user studies to measure how
changes to the recommendation system affect filter bubble
formation.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.