* 1525919
* III: Small: Collaborative Research: Towards Interpretable Machine Learning
* CSE,IIS
* 09/01/2015,08/31/2021
* Kilian Weinberger, Cornell University
* Standard Grant
* Wei Ding
* 08/31/2021
* USD 250,000.00

This research project investigates the design and development of machine
learning algorithms that make decisions that are interpretable by humans. As
predictions of machine learning models are increasingly used in making decisions
with critical consequences (e.g., in medicine or economics), it is important
that decision makers understand the rationale behind these predictions. The
project defines interpretable algorithms through three key properties;
Simplicity: intuitively comprehensible by users who are not experts in machine
learning, Verifiability: a clear relationship between input features and model
output, and Actionability: For a given input and desired output, the user should
be able to identify changes to the input features that transform the model
prediction to the desired output. The project investigates how to design
distance metrics supporting simplicity and verifiability, as well as algorithms
to identify input changes to change outputs. The project will be evaluated in a
medical context, addressing the problem of early detection of hospital patients
at risk of sudden deterioration.&lt;br/&gt;&lt;br/&gt;This work builds on the
well-understood k-Nearest-Neighbor classifier, which would inherently seem to
provide simplicity and verifiability. The challenge is in high dimensions, e.g.,
when used for document classification; differences are spread across more
dimensions than are humanly comprehensible. The project uses novel
dimensionality reduction approaches to create dissimilarity metrics that are
interpretable and accurate. Visualization techniques to present this data will
be explored, including techniques supporting more complex classification
approaches such as ensembles. The project investigates novel methods for
delivering actionability in machine learning algorithms by identifying changes
that can truly transform an entity's class membership - a problem that has
recently been identified as surprisingly difficult. A secondary outcome will be
improvements in classifier robustness, as small changes that change class
membership are a good indication of non-robustness.