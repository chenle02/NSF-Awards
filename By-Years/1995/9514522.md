* 9514522
* Effects of Spatiotemporal Pooling on Perceived Motion
* NONE,NONE
* 08/15/1996,07/31/2000
* James Todd, Ohio State University Research Foundation -DO NOT USE
* Continuing grant
* Rodney R. Cocking
* 07/31/2000
* USD 259,871.00

9514522 LINDSEY Objects moving within a human's field of view stimulate a good
many neurons, which differ with regard to the region of the field they represent
and with regard to the local characteristics of a moving object, such as color,
orientation, speed, and depth, that each signals. Human perception of objects in
motion suggests that the human visual system somehow unifies the responses of
these many neurons into a single perceptual whole, using a process known as
pooling. This process is spatiotemporal in nature, because it extends across
neurons responding, as moving objects are observed, to different properties of
the object and to different regions of visual space, as well as across responses
that occur in the recent past as well as in the present. This research is
concerned with spatiotemporal pooling by the human visual system and is
motivated by a three-stage, quantitative model of motion perception. The stages
of the model are Detection, Integration, and Decision. The first two stages
simulate the acquisition and collation of motion information from low-level
motion sensors analogous to those thought to exist in humans. The Decision stage
simulates a neural network designed to compute an appropriate velocity from the
pooled responses of the low-level motion sensors. The model is designed to
resolve not only the motion of single objects moving against a background, but
also to resolve two overlapping transparent objects moving at different
velocities relative to one another. This research will involve four series of
psychophysical experiments on human subjects. The research will flesh out
various functional aspects of the pooling process in humans and of the computer
simulation of these processes. The first series will determine the
spatiotemporal ranges over which pooling occurs and will determine whether
motion pooling is "hard-wired" or whether the visual system has the capacity to
adjust its pooling parameters flexibly when additio nal image information is
present in the visual scene. The second series of experiments will determine how
motion information from many different potential sources, e.g., spatial
frequency, orientation, color, disparity, is pooled and represented in velocity
space. The third and fourth series of experiments will determine how finely or
coarsely image velocity information is represented in velocity space and will
determine the robustness of object velocity resolution in the presence of noise.
This research will enhance our current understanding of the processes underlying
motion perception in humans. The research may be of ultimate utility in
robotics, in the design and construction of visual prosthetics, and in the
clinical assessment of visual dysfunction. ***