* 1439570
* BCC: Collaborative Research: Community Building for Research on Mathematics Learning Using Data-Intensive Sources
* EDU,DGE
* 09/01/2014,08/31/2017
* Carolyn Maher, Rutgers University New Brunswick
* Standard Grant
* John Cherniavsky
* 08/31/2017
* USD 604,661.00

Video data is ubiquitous in STEM education research and development. Yet the
potential for these data to be used outside the initial project in which they
are developed has been limited by the labor intensive methodology to index and
categorize video segments in ways that support use by external researchers. This
project will build the community to determine the taxonomy by which videos might
be characterized. The researchers and a strong advisory board will work with the
programmers of inVideo, a tool and software for indexing language and non-
language objects in video data sets. Working with video of students and teachers
in mathematics classrooms from the Robert B. Davis Institute for Learning, the
project will determine which categories of videos from the collection are
amenable for indexing by introducing successively more complex video samples.
The project will push the boundaries of computer science algorithms for video
search, benefiting both the computer science community and the mathematics
education research and development communities.&lt;br/&gt;&lt;br/&gt;There is
currently no automated method for accessing the content data locked within a
video format that is cost effective and available for education purposes. The
researchers in this project will determine whether application of automated
indexing to generate high precision and high recall retrievals is possible; what
human-augmented annotation generates towards more effective searching; and,
advisable practices for obtaining IRB approval to share video resources among a
wider community of researchers to facilitate a fine-grained analysis on other
data sets. The project will train the audio-to-text translation function of
inVideo to recognize speech patterns of people recorded in the videos using
translations that currently exist. The second stage of the project will address
the process of testing new samples of videos for which human-generated
transcripts do not exist. The project will also develop a web interface for
inVideo to facilitate transcript editing, time-stamped commenting and tagging by
remote users. The results of this study will enhance the utility of educational
video to a wide community of researchers.