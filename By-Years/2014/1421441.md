* 1421441
* CSR: Small: Telescopic Analysis for Black-Box Troubleshooting of Distributed Systems
* CSE,CNS
* 09/01/2014,08/31/2018
* Michael Cafarella, Regents of the University of Michigan - Ann Arbor
* Standard Grant
* Marilyn McClure
* 08/31/2018
* USD 498,241.00

This project is developing scalable mechanisms to debug, monitor,
and&lt;br/&gt;assess the quality of the complex distributed systems that
represent&lt;br/&gt;the backbone of modern software infrastructure. These
methods are&lt;br/&gt;necessarily highly-automated; they reason about the
operation of&lt;br/&gt;distributed systems while treating the components of such
systems as&lt;br/&gt;black boxes. This means that the methods do not require
source code,&lt;br/&gt;programmer annotation, or developer input to troubleshoot
a&lt;br/&gt;distributed system. Instead, they rely on detailed
information&lt;br/&gt;gleaned from pre-existing log messages that are nearly
ubiquitous in&lt;br/&gt;every large-scale distributed system and data extracted
via binary&lt;br/&gt;analysis of components as they
run.&lt;br/&gt;&lt;br/&gt;These new methods, termed telescopic analysis, combine
the ability to&lt;br/&gt;collect extremely detailed, low-level information about
systems&lt;br/&gt;executing large numbers of requests with "big data" analysis
that&lt;br/&gt;mines insights and create models of system operation from the
corpus&lt;br/&gt;of detailed observations. Telescopic analysis uses
targeted,&lt;br/&gt;sample-based logging and/or binary analysis to generate
substantial&lt;br/&gt;quantities of high-precision data about specific runs of
the system&lt;br/&gt;under observation. It then combines these observations into
models&lt;br/&gt;that capture the aggregate behavior of the system. Comparing
the&lt;br/&gt;general model with the detailed observations of each run
allows&lt;br/&gt;understanding of how that run conforms to or deviates from the
common&lt;br/&gt;operation of the system. The project is also developing tools
and&lt;br/&gt;query languages that allow understanding of the results of
such&lt;br/&gt;comparisons, both in aggregate and as pertains to specific runs,
for&lt;br/&gt;performance analysis, debugging data quality failures,
understanding&lt;br/&gt;outlier behavior, and performing "what-if" analysis.