* 1462245
* EAGER-DynamicData: Real-time Discovery and Timely Event Detection from Dynamic and Multi-Modal Data Streams
* ENG,ECCS
* 09/01/2015,08/31/2019
* Mihaela van der Schaar, University of California-Los Angeles
* Standard Grant
* Lawrence Goldberg
* 08/31/2019
* USD 266,773.00

Emergency responders (police, fire, ambulance services) have more and more
access to more and more data stream: sensor readings, security cameras, personal
reports (via cellphone, texts, tweets), GPS data etc. The availability of these
data streams presents enormous opportunities - but also poses fundamental
challenges: * Data streams arrive from a wide variety of sources and contain
many diverse features; this makes it difficult to extract information from the
streams, and especially, to integrate information from different streams. *
Knowledge learned from past events must be transferred to knowledge about
present (and future) events. Because no two events are ever identical, the
knowledge learned from past events must be transferred to knowledge about
present events that are not identical but only "similar" - and in ways that may
not be known in advance and so must be discovered. * Learning and detection -
and the actions that follow learning and detection ? must take place in a timely
fashion: it is of little use to learn how to respond to an emergency only long
after the emergency has passed. To accomplish this, the proposed work relies on
new methods to discover what is relevant both in each individual data stream and
across data streams, and to learn and exploit the similarities between the past
and the present. This work is transformative and success in this project has the
potential to lead to enormously enhanced, even life-saving, responses to
emergencies of many sorts.

Existing approaches treat individual data streams by exploiting particular
physical characteristics of the signal, and treat multiple data streams in an
ad-hoc fashion. These approaches miss the fact that it is not the physical
characteristics of the signal that are important but rather the (semantic)
information in the signal, and that there are connections between the
information in different data streams. This project transforms the problem of
learning from multiple (multi-modal) data streams by focusing on the relevance
of information in each data stream, across data streams, and through time. The
relevant information will generally be different for different events and
different purposes and will not be known in advance, so relevance must be
learned. To do this, this project organizes the information available at each
moment in time in terms of contexts which encode exogenous metadata (e.g., when,
where and by whom data was gathered) and endogenous metadata (e.g., features and
statistics extracted from the data). In general, there are an enormous number
and variety of contexts, but the most relevant information is embedded in only a
few contexts. Because these most relevant contexts will not generally be known
in advance and will be different in different scenarios, this project will
develop a new class of methods and algorithms to discover the relevant contexts
from multiple dynamic, multi-modal and high-dimensional data streams, and to use
what is discovered to learn, detect and respond in a timely fashion. Because no
two events are exactly the same, this project will develop of a new class of
methods and algorithms for the discovery of relevant semantic similarities and
their application, making it possible to transfer knowledge learned from past
events to knowledge about present events. This work requires the development of
highly innovative methodology and techniques that go far beyond existing work
(high risk) and are potentially transformative for a wide variety of
applications ranging from event detection to actionable intelligence.