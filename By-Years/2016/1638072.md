* 1638072
* NRI: Collaborative Research: Learning Adaptive Representations for Robust Mobile Robot Navigation from Multi-Modal Interactions
* CSE,IIS
* 10/01/2016,09/30/2021
* Matthew Walter, Toyota Technological Institute at Chicago
* Standard Grant
* Erion Plaku
* 09/30/2021
* USD 332,728.00

Most existing autonomous systems reason over flat, task-dependent models of the
world that do not scale to large, complex environments. This lack of scalability
and generalizability is a significant barrier to the widespread adoption of
robots for common tasks. This research will advance the state-of-the-art in
robot perception, natural language understanding, and learning to develop new
models and algorithms that significantly improve the scalability and efficiency
of mapping and motion planning in large, complex environments. These
contributions will impact the next generation of autonomous systems that
interact with humans in many domains, including manufacturing, healthcare, and
exploration. Outcomes will include the release of open source software and data,
workshops, K-12 STEM outreach efforts, and undergraduate and graduate education
in the unique, multidisciplinary fields of perception, natural language
understanding, and motion planning.&lt;br/&gt;&lt;br/&gt;As robots perform a
wider variety of tasks within increasingly complex environments, their ability
to learn and reason over expressive models of their environment becomes
critical. The goal of this research is to develop models and algorithms for
learning adaptive, hierarchical environment representations that afford
efficient planning for mobility tasks. These representations will take the form
of probabilistic models that capture the rich spatial-semantic properties of the
robot's environment and are factorable to enable scalable inference. This
research will develop algorithms that learn and adapt these representations by
fusing knowledge conveyed through human-provided natural language utterances
with information extracted from the robot's multimodal sensor streams. This
research will develop algorithms that then reason over the complexity of these
models in the context of the inferred task, thereby identifying simplifications
that enable more efficient robot motion planning. &lt;br/&gt;