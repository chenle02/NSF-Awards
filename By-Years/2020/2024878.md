* 2024878
* NRI: FND: Semi-Supervised Deep Learning for Domain Adaptation in Robotic Language Acquisition
* CSE,IIS
* 10/01/2020,09/30/2024
* John Winder, University of Maryland Baltimore County
* Standard Grant
* Tatiana Korelsky
* 09/30/2024
* USD 748,723.00

This project will enable robots to learn to perform tasks with human teammates
from language and other human modalities, and then transfer the learned
knowledge across heterogeneous platforms and tasks. This will ultimately allow
human-robot teaming in domains where people use varied language and instructions
to complete complex tasks. As robots become more capable and ubiquitous, they
are increasingly moving into complex, human-centric environments such as
workplaces and homes. Being able to deploy useful robots in settings where human
specialists are stretched thin, such as assistive technology, elder care, and
education, has the potential to have far-reaching impacts on human quality of
life. Achieving this will require the development of robots that learn, from
natural interaction, about an end user's goals and environment. This work is
intended to make robots more accessible and usable for non-specialists. In order
to verify success and involve the broader community, tasks will be drawn from
and tested in conjunction with community Makerspaces, which are strongly linked
with both education and community involvement. The award includes an education
and outreach plan designed to increase participation by and retention of women
and underrepresented minorities (URM) in robotics and computing, engaging with
UMBC's large URM population and world-class programs in this
space.&lt;br/&gt;&lt;br/&gt;This award addresses how collaborative learning and
successful performance during human-robot interactions can be accomplished by
learning from and acting on grounded language. To accomplish this, this project
will revolve around learning structured representations of abstract knowledge
with goal-directed task completion, grounded in a physical context. There are
three high-level research thrusts. In the first, new perceptual models to learn
an alignment among a robot's multiple, heterogeneous sensor and data streams
will be developed. In the second, synchronous grounded language models will be
developed to better capture both general linguistic and implicit contextual
expectations that are needed for completing tasks. In the third, a deep
reinforcement learning framework will be developed that can leverage the
advances achieved by the first two thrusts, allowing the development of
techniques for learning conceptual knowledge. Taken together, these advances
will allow an agent to achieve domain adaptation, improve its behaviors in new
environments, and transfer conceptual knowledge among robotic
agents.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has
been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.