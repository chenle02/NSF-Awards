* 1528087
* NeTS: Small: Addressing End-system Bottlenecks in High-speed Networks
* CSE,CNS
* 10/01/2015,09/30/2019
* Dipak Ghosal, University of California-Davis
* Standard Grant
* Darleen Fisher
* 09/30/2019
* USD 514,616.00

The rate at which a single processor in a computer can execute instructions has
not changed much in years, and major technological breakthroughs will be
required to double the current best rates. On the other hand, the rate at which
the network can deliver data is increasing rapidly and is expected to grow by an
order of magnitude in the next few years. Because of the widening gap between
the rate at which the network can deliver data and the rate at which a processor
can process the data, it is becoming increasingly difficult for a single
processor to keep up using current protocols and computer architectures.
Computer architects have compensated for the fact that processor speeds are no
longer increasing by putting multiple processor cores on each die, and while
these multicore systems have high aggregate processing capacities, attaining
predictable performance for the commonly adopted communication protocols
requires complex manual tuning. In prior work, the concept of affinity
(intelligently binding processes to processors) was leveraged to exploit the
hardware parallelism of current and next generation computers. This project will
build upon this prior expertise and leverage statistical and control theoretic
methods to manage end-to-end performance of high-speed flows. The process of
careful characterization of current technology, followed by analysis, and
finally middleware tool development will affords the maximum impact on shaping
best practices while minimizing any impact on distributed application
development processes.&lt;br/&gt;&lt;br/&gt;This project will characterize the
end-system bottlenecks that arise during data transfers required in different
distributed scientific and business applications. What is learnt will drive the
development of introspective end-system aware models, which will allow the auto-
tuning of data transfers. This tuning will consider both latency and throughput
requirements of the applications. Flow striping methods that exploit multicore
end-systems and adapt to the end-system bottlenecks will be developed. This will
require addressing many new issues, such as assigning flows to cores while
taking into account various (application, cache, and interrupt) affinities.
Additionally, the underlying topology of the cache (inclusive vs. exclusive),
the memory organization, and the heterogeneity of the cores will be considered
when controlling the end-to-end flows. Memory-mapped network channels, such as
Remote Direct Memory Access over Converged Ethernet will be investigated, for
data transfers over wide-area networks. Towards this end, memory management,
message synchronization and end-to-end flow control to enable remote messaging
for different types of network flows will be designed, implemented and
evaluated. From the end-system architectural perspective, cache architectures
that can significantly improve the network I/O performance will be proposed and
investigated.&lt;br/&gt;&lt;br/&gt;Broader Impacts: This project, which lies at
the intersection of computer networks, computer systems, operating systems, and
distributed applications, will provide a platform to train graduate students in
both analytical and experimental methods. Senior Design projects for
undergraduates will be defined that will be closely related to the project and
involve profiling distributed applications in high-speed network testbeds.
Industry partnerships will be established to design new protocols and optimize
the performance of distributed applications, as well as contribute to the design
of next generation networked computer system.