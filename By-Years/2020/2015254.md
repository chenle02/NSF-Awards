* 2015254
* CAREER: Programming the Existing and Emerging Memory Systems for Extreme-scale Parallel Performance
* CSE,CCF
* 10/01/2019,01/31/2024
* Yonghong Yan, University of North Carolina at Charlotte
* Continuing Grant
* Almadena Chtchelkanova
* 01/31/2024
* USD 498,674.00

High performance computing (HPC) focuses on using numerical model to simulate
complex science and engineering phenomena, such as galaxies, weather and
climate, molecular interactions, electric power grids, and aircraft in flight.
Over the next decade the goal is to build HPC parallel system capable of
extreme-scale performance (one exaflop (1018)operations per second) and
processing exabyte (1018) of data. However, one of the biggest challenges of
achieving extreme-scale performance is what is known as the hardware memory
wall, which is about the growing gap between the speed of computation performed
by CPU and the speed of supplying data to the CPU from memory systems (about
x100 time slower). The low performance efficiency of modern HPC system (average
&lt;60% and could be as low as 5%) manifests the memory wall impact since a huge
amount of computation cycles are wasted for waiting for the arrival of input
data. It becomes very critical to create effective software solutions for
achieving the computation potential of hardware and for improving the efficiency
and usability of the existing and future computing system. Such solutions will
significantly benefit a broad range of disciplines that use parallel computers
to solve scientific and engineering problems, and accelerate scientific
discovery and problem solving to improve quality of life of the society.
&lt;br/&gt;This CAREER project develops innovative software techniques to
address the programming and performance challenges of the existing and emerging
memory systems: 1) a portable abstract machine model for programming, compiling
and executing parallel applications, 2) new programming interface and model for
data mapping, movement, and consistency, and 3) machine-aware compilation and
data-aware scheduling techniques to realize an asynchronous task flow execution
model to hide the latency of data movement. It addresses the memory wall
challenge by developing a memory-centric programming paradigm for helping
achieve extreme-scale performance of parallel applications with minimum
impairment to programmability. For education, the project involves a broader
community starting from high school in the area of HPC and computer science.