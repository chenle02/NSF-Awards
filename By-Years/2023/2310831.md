* 2310831
* Toward Automated Uncertainty Quantification in Causal Inference
* MPS,DMS
* 07/01/2023,06/30/2026
* Yixin Wang, Regents of the University of Michigan - Ann Arbor
* Continuing Grant
* Yong Zeng
* 06/30/2026
* USD 74,028.00

When studying cause-and-effect relationships or making important decisions based
on data, researchers and decision-makers often encounter uncertainties that can
impact the reliability and trustworthiness of their conclusions. Understanding
and quantifying these uncertainties is crucial for making informed choices,
whether in scientific experiments, policy-making, or designing machine learning
systems. To this end, the project aims to develop algorithms that can
effectively address the challenge of uncertainty quantification in causal
inference. In particular, many current approaches to quantifying uncertainty in
causal relationships rely on sophisticated mathematical techniques that may not
align well with real-world scenarios. This project seeks to change the situation
by designing algorithms that are both theoretically sound and practically
applicable across a wide range of situations. This project also provides
research training opportunities for graduate students.

Technically, the project will focus on uncertainties in causal inference arising
from two sources: uncertain causal graphs and limited informativeness of
available data, both of which have significant implications for causal
conclusions and downstream decision-making. To tackle these challenges, this
project will develop algorithms that provide flexible and statistically valid
uncertainty estimates, minimizing their dependence on specific causal problems.
Leveraging recent advancements in algorithmic stability and private data
analysis techniques, confidence intervals for causal estimates will be
constructed, even when the causal graph is uncertain or learned from data.
Additionally, these confidence intervals will be integrated with the available
domain knowledge to further quantify the uncertainty arising from limited domain
knowledge and the identification power of the data. Taken together, this project
will facilitate the integration of different uncertainties, ultimately leading
to more reliable and automated uncertainty quantification in causal inference.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.