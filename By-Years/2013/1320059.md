* 1320059
* RI: Small: Binaural Sound Source Separation Robust to Listener Head Movements
* CSE,IIS
* 08/01/2013,07/31/2016
* Jonas Braasch, Rensselaer Polytechnic Institute
* Standard Grant
* Tatiana Korelsky
* 07/31/2016
* USD 186,624.00

The goal of this project is to develop a new binaural model to separate sounds
in complex environments. The new aspect of the model is that it can utilize head
movements to improve its localization performance by analyzing dynamic
localization cues and combining these with information about its own head
position. In addition, the model uses a dual approach to eliminate the influence
of room reflections on sound source localization and segregation. In the first
stage, specular reflections are eliminated using an autocorrelation- based
algorithm. In the second stage, diffuse reverberation is removed by measuring
interaural cross correlation across time/frequency bins, knowing that these
values decrease with decreasing direct-to- reverberant energy ratio. The model
development is accompanied by a behavioral study to better understand the
underlying principles of how humans can perform robustly in complex scenarios.
The results are also used as a benchmark test for the model algorithms.

This project intends to bridge the gap that exists between fundamentally knowing
how the auditory system processes binaural tasks for simple multiple-sound-
source scenarios, and understanding and modeling how it performs when the
environment reaches real-life complexity. The resulting model is expected to
operate in real time to localize sound sources in robot or surveillance
applications or serve as a front end for sound- source separation algorithms,
speech recognizers, predictors for acoustical quality of rooms, and
Computational Auditory Scene Analysis (CASA) models.