* 1814880
* CIF: Small: Collaborative Research: Generative Adversarial Privacy: A Data-driven Approach to Guaranteeing Privacy and Utility
* CSE,CCF
* 10/01/2018,09/30/2021
* Ram Rajagopal, Stanford University
* Standard Grant
* Phillip Regalia
* 09/30/2021
* USD 200,000.00

There is a growing need to publish datasets for both public benefit (via data-
driven research) and private gains (enterprise data sharing). However, consumer
privacy concerns have largely stymied such efforts since large datasets also
contain confidential information about participating individuals. This project
leverages recent advancements in learning generative models directly from the
datasets to introduce a novel framework called generative adversarial privacy
(GAP). GAP formalizes adversarial learning as a game between a privatizer that
wishes to learn the optimal privacy mechanism and any statistical adversary
intent on learning the confidential features. This formalization is crucial to
evaluate data-driven approaches against adversaries with strong inferential
capabilities. This project will include interactions with Honeywell Labs as well
as outreach and dissemination with Stanford industry partners in the electricity
and smart cities sector. Outreach programs include exposing middle- and high-
school girls to social network privacy challenges at ASU and K-12 teacher
training on data science through the Stanford Office of Science Outreach
Program.&lt;br/&gt;&lt;br/&gt;The project will focus on three foundational
problems. The first two ensure privacy of confidential features in the published
data and involve developing: (i) theoretical limits of the GAP formulation for a
large class of loss functions that capture a range of adversarial capabilities;
and (ii) convergence guarantees of the proposed GAP model. The third problem
focuses on guaranteeing identity privacy via synthetic datasets using a
combination of generative models (to generate synthetic data from training data)
and classes of statistical adversaries to understand the efficacy of generating
synthetic datasets with both utility and privacy guarantees. A key element of
this project involves testing on both publicly available datasets as well as
proprietary data.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.