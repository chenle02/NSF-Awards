* 2119849
* Measuring and Reducing Algorithmic Discrimination with Quasi-Experimental Data
* SBE,SES
* 09/01/2021,08/31/2024
* Peter Hull, Harvard University
* Standard Grant
* Cheryl Eavey
* 08/31/2024
* USD 400,000.00

This research project will develop new tools to measure and reduce algorithmic
discrimination in several high-stakes settings. Algorithms guide an increasingly
large number of decisions. Alongside this rise is a concern that algorithmic
decision-making will entrench or worsen discrimination against legally protected
groups. However, quantifying algorithmic discrimination is often hampered by a
selection challenge: an individual's qualification for a decision, which is
often used to define discrimination, is typically only available for the group
of individuals who were selected for treatment by an existing human or
algorithmic decision-maker. This project will overcome this fundamental
selection challenge by developing new tools to measure algorithmic
discrimination. The project also will develop alternative algorithms that
minimize or reduce discrimination. The researchers will apply these tools in
multiple high-stakes settings, including pretrial detention, employment
screening, medical testing, and child welfare investigations. The research is of
considerable policy interest given the rapid adoption of algorithms in a variety
of settings. The investigators are committed to increasing diversity in the
economics research community by recruiting, training, and mentoring women,
under-represented minorities, and first-generation college students as
undergraduate research assistants and predoctoral fellows. Code produced by this
project will be made publicly available.&lt;br/&gt;&lt;br/&gt;This research
project will develop tools to measure algorithmic discrimination. The project
also will develop alternative non-discriminatory algorithms when qualification
is unobserved for a subset of individuals. For example, in the employment
context, whether an individual would be hired after an interview is not observed
for applicants screened out before the interview is held. The investigators will
show that this selection challenge can be overcome with knowledge of average
qualification rates across different groups. Further, these average
qualification rates can be estimated by utilizing random assignment of decision-
makers to individuals. This insight can be used not only to measure algorithmic
discrimination, but to develop alternative algorithms that reduce or eliminate
discrimination. The project will consider several extensions. The investigators
will utilize experimentation to measure algorithmic discrimination and improve
accuracy. The interaction between algorithms and human decision-making also will
be explored, as human discretion remains important in most real-world settings.
The results of this research will have implications for more accurately
quantifying the trade-offs between algorithmic transparency, accuracy, and
fairness.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.