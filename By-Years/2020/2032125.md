* 2032125
* RAPID: Human Sound Localization and Analytics
* CSE,CNS
* 06/01/2020,05/31/2024
* Lili Qiu, University of Texas at Austin
* Standard Grant
* Alhussein Abouzeid
* 05/31/2024
* USD 100,000.00

COVID-19 is spreading at an unprecedented rate resulting in the death of so many
people all over the world. Social distancing is so far the most effective method
to limit its spread. However, manually enforcing social distancing is not only
labor-intensive but also error-prone and even dangerous due to possible physical
contact. This project proposes to develop techniques and mobile systems that
localize human sound such as cough and voice and alarm a user when someone is
within the social distance. If successful, this work will significantly advance
the state-of-the-art in wireless sensing and localization. To maximize the
impact, the researchers will collaborate with industry and local community and
release software to the public. The research outcome will also be incorporated
into the graduate and undergraduate curriculum. &lt;br/&gt;&lt;br/&gt;The
proposed research aims to develop algorithms and systems to localize
uncontrolled and unknown human sound. A unique advantage is that it does not
require cooperation from other phones and whoever uses it can immediately
benefit from it. It exploits the phone mobility as the user moves to enable
localization. The multi-resolution analysis will be performed on low-frequency
voice signals to further enhance accuracy. When another phone is cooperating, it
will further leverage the time of flight between the two phones to improve the
performance.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission
and has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.