* 2324389
* Bridging the Generalization and Interpretation Gaps in Deep Neural Networks
* MPS,DMS
* 09/01/2023,08/31/2026
* Yuan Ke, University of Georgia Research Foundation Inc
* Continuing Grant
* Yong Zeng
* 08/31/2026
* USD 58,238.00

This project focuses on enhancing the reliability and understandability of
advanced artificial intelligence (AI) systems, specifically deep neural networks
(DNNs) - a type of AI that uses layered structures of interconnected elements,
or "neurons," to process and interpret data in sophisticated ways. Currently,
these AI systems face two main challenges. Firstly, they may struggle to apply
what they've learned in one situation to a different one. This issue, known as
the "generalization gap," is similar to a student who has crammed for an exam
but struggles to apply the knowledge in a real-world scenario. Secondly, DNNs,
like many AI systems, work in ways that can be difficult for humans to
understand. This "interpretation gap" is like using a complicated machine
without a user manual, which can make it hard to correct mistakes or explain why
specific decisions were made. These challenges could have implications for any
sector where AI is used, from healthcare to autopilot. If AI makes mistakes
because of the generalization gap or if it's not clear why a decision was made
due to the interpretation gap, it could lead to significant errors, lack of
trust, or even potential harm. This project aims to study these issues,
enhancing the reliability and transparency of AI systems, enabling us to apply
these technologies more confidently and effectively. By doing so, it will
advance our scientific understanding of AI, support education in this vital
field, and benefit society by ensuring AI technologies are more dependable and
understandable. The project also provides research opportunities for graduate
students.

This project aims to develop a new framework to address the generalization and
interpretation gaps in DNNs by investigating a series of well-defined research
problems. The work includes the development of novel statistical theories for a
better understanding of generalization errors in DNNs, the creation of robust
and computationally efficient algorithms, and the promotion of innovative
approaches for out-of-distribution generalizations. This project will advance
our understanding of DNNs, develop new methods and algorithms, and provide
insights into practical applications in diverse fields. The principal
investigators will incorporate the research findings of this project into their
educational endeavors.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.