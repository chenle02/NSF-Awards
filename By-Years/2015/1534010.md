* 1534010
* STTR Phase II:  An Assistive Tool to Locate People and Objects with a Multimodal Thermogram Interface
* TIP,TI
* 09/15/2015,02/28/2019
* Nicholas Giudice, Moai Technologies L.L.C.
* Standard Grant
* Muralidharan Nair
* 02/28/2019
* USD 890,856.00

The broader impact/commercial potential of this project is the assistive use by
blind people of thermal imaging. The resulting product provides a person who is
blind or visually impaired with the relevant information about the layout of an
unfamiliar public space in order to assist blind users in everyday activities.
Thermal imaging can differentiate people and objects from their background
without the need for complex image analysis. The shape and the temperature of
the human body allows the location of people to be easily determined. The
societal impact will be assisting users in navigation of complex public spaces.
A blind person can use a smartphone?s haptic touchscreen display to examine the
thermal image to determine the location of people in front of them. Information
about the layout of an unfamiliar public space can be learned from the heat and
shape of materials. Examples would be locating vending machines like ATMs and
train passes. The market sector for this technology will likely extend beyond
assisting blind users, to include additional commercial opportunities as
well.&lt;br/&gt;&lt;br/&gt;This Small Business Technology Transfer Research
(STTR) Phase 2 project will leverage past National Science Foundation Funded
research to develop a product that a blind/low vision user can use to receive
practical navigation and interaction information about their environment from a
multimodal thermogram (thermal image) interface on a smartphone. There are no
practical assistive technologies for blind or low vision users that allow them
to locate people, objects, and the layout information of their surroundings
other than exploring with a cane. This development will address the objective of
creating an interface that provides both practical utility and will be accepted
by the target demographic of blind users. This project represents an excellent
translational path from NSF-sponsored research programs to a product that is
built from the ground up on solid theoretical underpinnings and empirical
findings from multimodal human information processing. This development will use
thermal radiation from people, machines, lighting and heat retention differences
in building materials and convert this data into a user interface to facilitate
blind navigation and environment interaction. The product resulting will be a
multimodal (kinesthetic, vibro-tactile, and auditory) interface for blind users
of a smartphone to interpret and gain useful value from thermal image
information.