* 9711770
* Learning From Demonstration
* CSE,IIS
* 02/01/1998,01/31/2001
* Christopher Atkeson, Georgia Tech Research Corporation
* Continuing Grant
* Vladimir J. Lumelsky
* 01/31/2001
* USD 255,000.00

The goals of the research are to develop new robot learning algorithms for
qualitatively more complex robots and tasks than have been attempted so far, and
to greatly increase the level of automation of implementing robot learning. The
research will focus on: 1: tasks and robots with many degrees of freedom, 2:
having one robot learn to perform multiple tasks, and generalize appropriately
between tasks, 3: learning over a long time span, in which the robot, the task,
and the environment change, and 4: combining multiple approaches to robot
learning. The research will contribute to a more automatic process for selecting
task structure, representations, and adjustable parameters and functions. Two
types of learning will be emphasized: learning from demonstration, where the
robot learns from a demonstration of how to perform a task, and reinforcement
learning, where the robot learns by optimizing a reward function. Flexible
methods to represent knowledge will be emphasized, including locally weighted
learning and other nonparametric learning techniques. The techniques developed
in implementing learning from demonstration will form the basis of the approach
to more general learning problems, such as reinforcement learning. This research
will be conducted in collaboration with Dr. Mitsuo Kawato at the Advanced
Telecommunications Research Human Information Processing Laboratory in Japan.
The expected significance of this research is that it will make it easier and
less expensive to program robots and machine-based systems in general. From an
engineering point of view the goal is to reduce the amount of expensive expert
human input into robot programming. From a psychological point of view the goal
is to understand how people learn, and this kind of work leads to models of how
learning behavior might be accomplished.