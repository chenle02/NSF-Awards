
* 1712970
* Gene Golub SIAM Summer School: Data Sparse Approximations and Algorithms
* DMS,COMPUTATIONAL MATHEMATICS
* 01/01/2017,11/22/2016
* James Nagy,GA,Emory University
* Standard Grant
* Leland Jameson
* 12/31/2017
* USD 10,000.00

This project supports the participation of U.S. based PhD students to
participate in the 2017 Gene Golub Society for Industrial and Applied
Mathematics (SIAM) Summer School on Data Sparse Approximations and Algorithms,
which will be held at Akademie Berlin-Schmockwitz in Germany, May 29 through
June 9, 2017. Detailed information can be found at http://www3.math.tu-
berlin.de/numerik/G2S3/index.html. The topic of this summer school is motivated
by the observation that in numerous modern applications throughout business,
science and engineering, it is extremely challenging to efficiently and stably
acquire, analyze, and process massive amounts of data. Recent mathematical
advances have shown that massive data sets, and functions associated with them,
can often be represented or accurately approximated by only a small number of
relevant features; that is, massive data can be represented by a sparse set of
features. The summer school will expose PhD students to recent mathematical and
computational techniques used in the area of data sparse approximations, and
this project ensures participation of well qualified students from U.S. based
institutions.

Techniques from several different mathematical fields have been used and
continue to be developed in the context of data sparse representations and
approximations. Among them are applied harmonic analysis, approximation theory,
convex analysis, frame theory, graph theory, imaging science, inverse problems,
probability theory, random matrix theory, reduced order modeling, and tensor
analysis. In all applications, the outcome of the modeling, simulation,
optimization, or approximation is a linear algebraic problem that encodes the
underlying functions, the data, and thus also the resulting sparsity. Together
with appropriately chosen regularizations and metrics or norms, a key role in
the process is played by the fields of numerical linear algebra and
optimization. A solid knowledge of these fields is required for working with,
and making further advances in the field of data sparse approximations and
algorithms. The school will consist of four courses over the two-week period of
the summer school: Two courses in the first week of the school will focus on the
theory of sparse representation and approximation as well as tensor methods, and
two courses in the second week will deal with sparse numerical linear algebra as
well as optimization methods in the sparse context. The courses will include
lectures as well as computational exercises and small group projects for the
participants.
