* 2341135
* I-Corps: A Software Platform to Customize, Inspect and Improve Artificial Intelligence (AI) Systems
* TIP,TI
* 09/15/2023,02/29/2024
* Soheil Feizi, University of Maryland, College Park
* Standard Grant
* Ruth Shuman
* 02/29/2024
* USD 50,000.00

The broader impact/commercial potential of this I-Corps project is the
development of a software platform to make Artificial Intelligence (AI) models
more reliable. Artificial intelligence is rapidly becoming a part of everyday
businesses and organizations. However, key concerns in using AI systems are
their lack of reliability and explainability, and their lack of transparency
with respect to internal workings where output inferences and predictions are
not interpretable. This makes the process of developing AI models and inspecting
and mitigating their failure modes time-consuming and challenging. The proposed
technology is designed to automate developing, inspecting and improving AI
models using another AI system that uses human feedback in its optimization.
Understanding and mitigating reliability issues of AI models may mitigate the
risks of their deployment in practice. In addition, these efforts may
democratize the reliable use of AI systems by non-experts and increase human
trust in these systems.

This I-Corps project is based on the development of an automated and unified
software platform that provides multi-modal interpretability and reliability
analysis and monitoring tools to design, train, inspect, and improve Artificial
Intelligence (AI) systems. The proposed technology is designed to automatically
uncover and address hidden reliability issues within AI models employing the
userâ€™s unique data. It simplifies the complex process of identifying and
mitigating potential reliability risks and explainability challenges, which may
help to ensure AI models deliver trustworthy and accurate results. In addition,
users may compare hundreds of AI models and select the ones with the maximum
efficiency and reliability for their specific applications. It also
interactively incorporates user feedback in its optimization to improve
reliability and explainability of AI models while reliability becomes
transparent and manageable, empowering users to make informed decisions with
increased confidence.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.