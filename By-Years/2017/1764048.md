* 1764048
* RI:Medium:Collaborative Research: Developing a Uniform Meaning Representation for Natural Language Processing
* CSE,IIS
* 08/01/2018,12/31/2022
* James Martin, University of Colorado at Boulder
* Standard Grant
* Tatiana Korelsky
* 12/31/2022
* USD 399,894.00

The use of intelligent agents that can communicate with us in human language has
become an essential part of our daily lives. Today's intelligent agents can
respond appropriately to many things we say or text to them, but they cannot yet
communicate fully like humans. They lack our general ability to arrive quickly
at accurate and relevant interpretations of what others communicate to us and to
form appropriate responses, particularly in sustained interactions. The typical
way we teach a machine to acquire such ability is to provide it with
approximations of the meanings of utterances in the contexts in which they have
occurred in the past. Over the years these approximations have become
increasingly rich and detailed, enabling ever more sophisticated systems for
interacting with computers using natural language, such as searching for
information, getting up-to-date recommendations for products and services, and
translating foreign languages. The goal of this project is to bring together
linguists and computer scientists to jointly develop a practical meaning
representation formalism based on these rich approximations that can be applied
to a much more diverse set of languages. This will allow us to use machine
learning to develop techniques to automatically translate human utterances into
our meaning formalism. In turn, this will enable intelligent agents to acquire
more advanced communication capabilities, and for a wider range of languages.
The languages considered for the project include those spoken by large
populations such as English, Chinese and Arabic, as well as native tongues of
smaller groups such as Norwegian, and Arapaho and Kukama-Kukamira, two
indigenous languages of the Americas. As such, this project will help bring
modern technology to smaller groups so that all people can benefit equally from
technological advancement. The project will also contribute to the development
of the US workforce by training a new generation of researchers on cutting-edge
technologies in artificial intelligence. &lt;br/&gt;&lt;br/&gt;This project
brings together an interdisciplinary team of linguists and computer scientists
from three institutions to jointly develop a Uniform Meaning Representation
(UMR). UMR is a practical, formal, computationally tractable, and cross-
linguistically valid meaning representation of natural language that can impact
a wide range of downstream applications requiring deep natural language
understanding (NLU). UMR will extend existing meaning representations to include
quantifier types and relations, modality, negation, tense and aspect, and be
tested on a typologically diverse set of languages. Methods and techniques for
UMR annotation, parsing and generation, and evaluation will be uniform across
languages. The project will also develop novel algorithms and models for UMR-
based broad-coverage and general-purpose multilingual semantic parsers. Students
participating in the project will receive training in the full cycle of
conceptualizing, producing, processing, and consuming meaning representations at
the sites of participating institutions. This project will help to build a
community of NLP researchers that will contribute to the development of UMR-
based data and tools and advance the state of the art in Natural Language
Processing (NLP) in particular, and Artificial Intelligence (AI) in
general.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.