* 1618039
* SHF: Small: Latency Tolerance Aware Runtime Optimization for General-Purpose GPU Architectures
* CSE,CCF
* 08/01/2016,07/31/2021
* Carole-Jean Wu, Arizona State University
* Standard Grant
* Yuanyuan Yang
* 07/31/2021
* USD 346,000.00

Computing touches almost all aspects of our modern day lives -- from gene
sequencing to physics simulations to powering the Internet, from real-time image
and voice recognition to predicting stock market trends. The programmability
advancement of high-performance accelerators, such as graphics processors, has
enabled a large, diverse set of general-purpose algorithms to enjoy performance
acceleration on GPUs. However, because the unique latency tolerance GPU design
feature is often not taken into account, the state-of-the-art solutions lead to
sub-optimal performance improvement. The proposed Latency Tolerance Aware
runtime optimization framework (LATTE) can help the computing industry realize
its high performance and high energy efficiency vision. Performance acceleration
of important general-purpose algorithms with large and diverse input data sets
has a profound impact on the advancement of all research domains and on society.
The research agenda is complemented by an education agenda focusing on
heterogeneous computing.&lt;br/&gt;&lt;br/&gt;The LATTE framework proposed in
this project aims to explore and propose architectural solutions and to create
system supports to accelerate the execution of important general-purpose
applications on GPUs. The proposed LATTE runtime optimization framework revolves
around identifying and designing optimization techniques that are fully latency
tolerance aware in order to maximize performance improvement for GPGPUs. The
pitfalls for directly adapting CPU-centric optimization to GPU architectures are
analyzed and used to motivate the need to proactively manage the highly time-
multiplexed computation and memory resources considering the critical latency
tolerance characteristic of GPUs. The findings can serve as foundations for
future performance optimization research to avoid blind replication, leading to
important scientific research contributions for GPGPU acceleration.