* 1948752
* Doctoral Dissertation Research In DRMS:  Reinforcement Learning and Attention in Decision Making
* SBE,SES
* 03/01/2020,02/29/2024
* Andrew Caplin, New York University
* Standard Grant
* Robert O'Connor
* 02/29/2024
* USD 40,219.00

Decision makers often consider information from a variety of sources, but since
processing information is effortful not all information is always taken into
account. This project investigates the contributions of two major sources of
information to decision-making: any available information on the reward that an
action will produce, and the history of rewards obtained from taking this action
in the past. The extent to which decision makers rely on either of these sources
of information is fundamental to understanding commonly observed choice patterns
that economize on learning: Present information is often (at least partially)
ignored and substituted for by relying on prior experience. Recent advances in
economics model this trade-off, but do not typically provide an account of prior
experience. Neuroscience and artificial intelligence, however, provide an
account of learning from prior experience which is relevant to the formation of
habits, for instance. This project aims to combine neuroscientific and economic
accounts in one coherent theoretical framework, and to quantify experimentally
the extent to which decisions rely on present information and prior experience,
respectively. Such a measurement is crucial for understanding the circumstances
under which a decision maker reassesses a recurring decision and breaks a habit.
It will suggest policies that help incentivize decision makers to make
deliberate decisions rather than following persistent habits. This is of great
importance given the central role habits play in anxiety disorders, addiction,
and arguably also in consumption decisions. &lt;br/&gt;&lt;br/&gt;The relative
contributions of present information and prior experience are assessed in an
experiment that is firmly rooted in the economic theory of rational inattention
as well as computational models of reinforcement learning from cognitive
neuroscience. The experiment combines observed choice behavior with a
measurement of neural activity, in order to establish whether the latter is
correlated with probabilistic beliefs. The rationale is that dopaminergic
activity in the midbrain is – consistent with reinforcement learning theory –
believed to encode a reward prediction error, which can be observed in the
striatum using functional magnetic resonance imaging. If this neural measurement
can be validated as a proxy for probabilistic beliefs, it could be leveraged for
inference on unobservable beliefs. This provides further evidence on the extent
to which subjects’ decisions rely on present information and prior experience,
depending on the characteristics of these two sources of
information.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission
and has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.