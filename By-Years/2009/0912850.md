* 0912850
* CSR: Small: Core Scheduling to Improve Virtualized I/O Performance on Multi-Core Systems
* CSE,CNS
* 09/01/2009,08/31/2014
* Laxmi Bhuyan, University of California-Riverside
* Standard Grant
* Marilyn McClure
* 08/31/2014
* USD 460,789.00

This project focuses on reducing the overhead and increasing throughput of
network processing in multi-core platforms. In particular, packet processing
functions are proposed to be balanced across the cores so as to facilitate
virtualization in next-generation systems.&lt;br/&gt;&lt;br/&gt;Low-cost multi-
core architectures that put many CPU cores on the same chip are abundantly
available in the market today. Researchers are developing a range of programming
techniques for different applications to efficiently utilize the parallelism
available in such multi-core architectures. However, research into how to
alleviate the I/O bottleneck, where protocol-processing overhead dominates the
CPU execution time, is sparse.&lt;br/&gt;&lt;br/&gt;Multicore has enabled broad
interest in virtualization for diverse uses including server consolidation and
sharing of various resources. Studies have shown that virtualization brings
significant extra overhead to network I/O. The objective of this project is to
develop techniques to optimize the performance of virtualized I/O with high-
speed networks. In particular, the research team explores new software
techniques in virtualized environments, that may reduce the network I/O overhead
in multi-core processors, through the following approaches:
&lt;br/&gt;&lt;br/&gt;1. Life of a Packet Analysis: this involves a measurement
technique to trace the life of a packet in a virtualized environment with 10
Gigabit Ethernet. The study instruments the OS software, and should reveal
potential bottleneck functions that contribute heavily to packet latency.
&lt;br/&gt;&lt;br/&gt;2. Mutithreading the protocol stack: Based on life-of-a-
packet analysis, the TCP/IP protocol stack in the guest O/S and virtual machine
monitor (VMM) will be divided into multiple threads that can execute in parallel
on multiple cores and cut down the latency. Core scheduling techniques are
developed to allocate these threads to different cores so as to exploit the
cache locality of the multi-core architecture. &lt;br/&gt;&lt;br/&gt;3. Pipeline
Scheduling: Instead of splitting the protocol stack in terms of latency
bottleneck, tasks are partitioned based on code size and multiple threads
developed. Techniques are developed to schedule the threads appropriately so
that the cache misses are reduced. &lt;br/&gt;&lt;br/&gt;4. Combined Scheduling
for Virtualized Environment: Although the parallel/pipeline techniques are
developed separately from the TCP/IP stack and VMM, they are combined to create
multiple threads in a virtualized environment and various code scheduling
optimizations are applied to reduce latency and increase I/O throughput.
&lt;br/&gt;&lt;br/&gt;A complimentary project to the one described here has been
partly supported by grants from the Intel Corporation. Hence, the research
results obtained from this project may have strong potential for technology
transfer. The PI has mentored several Ph.D. graduates who later developed
reputations for architecture research and he has mentored four female Ph.D.
graduates during the last two years, contributing to increasing the
representation of women in computing in the country. Such efforts continue under
this NSF project. UCR is recognized as a minority serving institution. Hence,
involving undergraduate students will enable minority participation in the
project. &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;