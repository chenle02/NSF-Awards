* 1814969
* SHF: Small: A Scalable Architecture for Ubiquitous Parallelism
* CSE,CCF
* 10/01/2018,09/30/2022
* Daniel Sanchez Martin, Massachusetts Institute of Technology
* Standard Grant
* Danella Zhao
* 09/30/2022
* USD 450,000.00

With cost-performance gains predicted by Moore's Law slowing down, future
computer systems will need to harness increasing amounts of parallelism to
improve performance. Achieving this goal requires new techniques to make massive
parallelism practical, as current multicore systems fall short of this goal:
they squander most of the parallelism available in applications and are
exceedingly hard to program. To address these challenges, this project is
investigating a novel parallel architecture that efficiently scales to thousands
of cores and is almost as easy to program as sequential systems. It achieves
these benefits by exploiting ordered parallelism, which is general and abundant
but is hard to mine in current systems. The technologies being investigated will
make future parallel systems more versatile, scalable, and easier to program.
These techniques will especially benefit hard-to-parallelize irregular
applications that are key in emerging domains, such as graph analytics, machine
learning, and in-memory databases. The prototyping efforts will bring the
benefits of ordered parallelism to existing systems. Finally, the infrastructure
developed as part of this project will be released publicly, enabling others to
build on the results of this work.&lt;br/&gt;&lt;br/&gt;Towards the goal of
efficiently parallelizing the vast majority of applications while retaining the
programming simplicity of sequential systems, this project is investigating and
developing the following techniques: (1) distributed data-centric execution,
which scales fine-grained ordered parallelism and speculative execution to rack-
scale systems with tens of thousands of cores; (2) an expressive execution model
that supports seamless combinations of speculative and non-speculative tasks,
improving efficiency and parallelism; (3) adaptive speculation and resource
management techniques that avoid performance pathologies, reduce wasted work,
and make more efficient use of this novel architecture; and (4) an FPGA-based
prototype of this architecture that leverages these techniques to exploit
ordered parallelism and accelerate important applications. In this architecture,
programs consist of tiny tasks with order constraints. The system executes tasks
speculatively and out of order, and efficiently speculates thousands of tasks
ahead to uncover ordered parallelism. Tasks are distributed to run close to
their data, reducing data movement and allowing the system to scale across
multiple chips and boards. An early 256-core design demonstrates near-linear
scalability on programs that are often deemed sequential, outperforming state-
of-the-art algorithms by one to two orders of
magnitude.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.