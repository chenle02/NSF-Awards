* 2309751
* Learnable Tensor Algebras for Harnessing Implicit Correlations in Multiway Data
* MPS,DMS
* 09/01/2023,08/31/2026
* Elizabeth Newman, Emory University
* Continuing Grant
* Yuliya Gorb
* 08/31/2026
* USD 75,065.00

Big data has revolutionized the kinds of problems we can tackle, enabling
unprecedented personalization and innovation across commercial, scientific, and
healthcare applications. The ever-growing amount of data has created a pressing
need for new methodologies to reduce storage demands and extract representative
features for downstream analysis. Many data, such as those arising in computer
vision and imaging, neuroscience, networks (e.g., epidemic tracking, cyber
security), and more, are natively represented as multiway arrays, or tensors. As
a result, tensor-based approaches have become increasingly attractive for
dimensionality reduction and feature extraction. However, many tensor-based
approaches suffer from a so-called “curse of multidimensionality;” that is, that
fundamental mathematical properties break down when applied to multiway data.
Recent advances in tensor algebra have overcome this limitation by reframing
tensors as mathematical operators rather than stagnant arrays of data. This
project will take these advancements to the next level by learning the optimal
mathematical operations required to drive down storage costs further while
increasing the accuracy of tensor representations. The methods developed in this
project will be useful for a wide range of high-impact applications, including
precision medicine, climate simulations, and engineering. All algorithms and
methods produced will be made available to the public in well-documented, open-
source code.

This project focuses on developing new methods to maximize the benefits of
matrix-mimetic tensor frameworks- multidimensional frameworks that preserve
linear algebraic properties. Such frameworks yield theoretical and empirical
advantages over traditional matrix-based approaches and alternative tensor-based
approaches. The matrix mimeticity arises from interpreting tensors as t-linear
operators that multiply using tensor-tensor products. The choice of tensor-
tensor product, given by an underlying tensor algebra, is crucial to
representation quality, and thus far, has been made heuristically. This project
will develop a unifying optimization framework to learn tensor algebras and
efficiently represent multiway data with implicit correlations (i.e.,
relationships unknown a priori and thus challenging to capture heuristically).
The learned tensor-tensor products will introduce algorithmic advantages (e.g.,
fast evaluations and low storage costs) while preserving theoretical guarantees
of the matrix-mimetic framework. The main thrusts of this project are (1) to
optimize tensor algebras by exploiting the coupling between matrix-mimetic
tensor factorizations and tensor-tensor products, (2) to capture nonlinearity in
multilinear algorithms by designing novel nonlinear tensor-tensor products, and
(3) to extend the proposed algorithms using new, scalable strategies to increase
the applicability of matrix-mimetic tensor approaches to massive multiway data
applications.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.