* 2221943
* FAI: Measuring and Mitigating Biases in Generic Image Representations
* CSE,IIS
* 10/01/2021,02/29/2024
* Baishakhi Ray, William Marsh Rice University
* Standard Grant
* Sylvia Spengler
* 02/29/2024
* USD 361,281.00

Visual recognition is a remarkable task performed by the human brain.
Computational methods trained to emulate this capability rely on observing
millions of examples of visual input paired with human annotations. These
computational methods have made great progress and are being increasingly
adopted in many user-facing applications such as image search, automated image
tagging, semi-autonomous navigation systems, smart virtual assistants, etc.
However, the underlying visual recognition models in these systems often produce
errors by associating sensitive variables of societal significance with their
predictions. The goal of this project is to measure and mitigate such errors in
a systematic fashion. For example, if a method is able to recognize images of
scenes such as 'classroom', the goal of this project is to ensure that such
predictions are obtained based on cues such as the presence of a whiteboard,
chairs, desks, and other elements typically needed for a space to function as a
classroom and not based on incidental elements such as the characteristics or
attributes of people present in the classroom. To this end, this project aims to
make it easier to determine to what extent methods for computational visual
recognition rely on spurious associations with incidental
elements.&lt;br/&gt;&lt;br/&gt;This project will provide a study of societal
biases present in current methods and models for computational visual
recognition that are widely used as a source of generic visual representations.
The developed methods will be based on solid foundations drawn from both the
machine learning, computer vision, and software testing communities. The project
introduces association tests to probe models trained under a variety of
conditions to systematically disentangle the biases introduced during generic
visual representation learning. The project will be 1) developing a general
assessment methodology to measure various types of biases in generic visual
representation learning, 2) proposing methods to diminish the impact of these
biases in existing generic visual representation extraction models, and 3)
measuring the impact of these biases on some key downstream tasks. These three
research aims will be complemented by a comprehensive evaluation plan and
broadening participation activities. This research effort will bring novel
insights into the sources of biases in the predictions of computer vision models
and methodologies to make informed decisions about the risks in the deployment
of such models.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission
and has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.