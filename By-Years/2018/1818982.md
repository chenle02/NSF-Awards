* 1818982
* SBIR Phase I:  Situational Awareness in Autonomous Agriculture
* TIP,TI
* 06/15/2018,02/28/2019
* Jianfei Chen, Aware Vehicles, Inc
* Standard Grant
* Muralidharan Nair
* 02/28/2019
* USD 225,000.00

The broader impact/commercial potential of this project is to enable real-time
situational awareness in autonomous vehicles. With the global population
expected to reach 9 billion by 2050 and the uncertain climate changes that
create concern over the resources allocated to farming activities, precision
agriculture has become the ultimate solution to increase agricultural
productivity and efficiency. The proposed system, aiming to integrate aerial and
terrain robotics and provide high-throughput crop imaging, will push precision
agriculture to the next evolutionary stage ? fully autonomous agriculture. With
the R&amp;D efforts in this project, the integrated aerial-terrain robotics and
high-throughput imaging system will be ready for commercialization under the
proposed sustainable business model and impact farming industries globally.
Moreover, the system prototype enabled by smart and mobile docking can be
readily adapted to accommodate needs in a variety of other industries, where
geospatially large-scale sensing and analytics are in demand, such as
transportation network monitoring, civil infrastructure and urban monitoring,
logistics and freight management, and monitoring of environmental hazards. The
proposed invention and its future robotic products are expected to impact all
these sectors by imparting automation in terms of high-dimensional data
collection and real-time analytics. &lt;br/&gt;&lt;br/&gt;This Small Business
Innovation Research Phase I project provides a technology leap that furnishes
state-of-the-art terrain robotics with long-range and real-time situational
awareness, including pre-operation reconnaissance and post-operation evaluation.
A smart docking platform will be developed that provides an unlimited energy
supply while serving as an ad-hoc computing engine and enables the possibility
of high-throughput imaging for single plants or plant groups. Such a
systematically coupled docking-imaging-computing platform is not found to date.
The docking will be realized through three independent mechanisms, including
kinetic sensing and calculation, low-cost stereo vision, and radar ranging; and
real-time positioning algorithms based on the three mechanisms will be developed
through a fail-safe data fusion process. The aerial imaging drone, charged by
the docking platform, can perform two modes of imaging activities either towards
conventional terrain/field mapping or the novel 4-dimensional (4D)
reconstruction proposed in this project. The reconstruction algorithms will be
developed based on the fusion of the stereo data and the hyperspectral data,
which produces the first-of-its kind 4D spatial-spectral models for high-
throughput phenotyping.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.