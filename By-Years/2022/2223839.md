* 2223839
* EFRI BRAID: Principles of sleep-dependent memory consolidation for adaptive and continual learning in artificial intelligence
* ENG,EFMA
* 10/01/2022,09/30/2026
* Hong Lei, University of California-San Diego
* Standard Grant
* Edda Thiels
* 09/30/2026
* USD 2,000,000.00

Artificial Neural Networks (ANNs) are a form of Artificial Intelligence (AI)
used in applications from self-driving cars to medicine to robotic systems.
Although they can match and even exceed human performance on some learning
tasks, they fail to reproduce important characteristics of the human mind, such
as quick and continual learning, transfer of knowledge to the new tasks, and
energy efficiency. Indeed, ANNs commonly forget what they knew when new
information is learned, and so they need to be taught from scratch to re-learn.
In real-life applications in changing and unpredictable environments, ANNs can
only reach near human-level performance if they are trained on all possible
scenarios that could happen in life. This level of training is inefficient and
unrealistic. In natural brains, sleep is thought to be important for
intelligence. During sleep, the brain repeats and replays what was learned
during the day, and this helps to prevent forgetting, to generalize to new
situations, and to create new emerging knowledge. In this project, principles
learned from the biology of sleep will be used to develop powerful new
algorithms for AI systems that can learn continuously and from few examples,
transfer knowledge learned from old tasks to new tasks, and be robust and
efficient. Because AI and ANNs are so fundamental to the modern world, from
healthcare to electronics to national defense, this project has the potential to
make a significant societal impact. The project takes a multi-disciplinary
approach and supports broader participation of underrepresented groups in STEM
research through a range of educational activities focused on high school,
undergraduate, including community college, and graduate
students.&lt;br/&gt;&lt;br/&gt;This project aims to translate insights from the
study of sleep to improvements in deep-learning systems necessary for continual
learning, generalization, and transfer of knowledge in artificial intelligence
(AI). Taking advantage of the architectural similarities between information
processing in ANNs and the honeybee brain, the main goals of this project are:
(a) to characterize multi-phasic sleep in the honeybee brain in vivo and in
biophysical in silico models in fine spatio-temporal detail to reveal the
critical principles of the role of sleep in memory consolidation, and (b) to
apply these results to support the development of novel machine-learning
algorithms for adaptive and continual learning in complex and dynamic
environments. The study will develop an empirically grounded theory of multi-
phasic sleep that will be then applied to artificial neural networks, and the
process of developing “sleep for AI” will help to strengthen connections between
engineering, computational neuroscience, and neuroethology for researchers at a
range of career stages. To accomplish this goal, the project team also plans a
four-tiered educational approach targeting students in high schools, community
colleges, bachelor’s degree programs, and graduate-level programs to introduce a
wider range of students to the topics in AI, sleep biology, and computational
neuroscience. &lt;br/&gt;&lt;br/&gt;This project is funded jointly by the
Emerging Frontiers in Research and Innovation Brain-Inspired Dynamics for
Engineering Energy-Efficient Circuits and Artificial Intelligence Program of the
Engineering Directorate and the Neural Systems/Modulation Program of the
Biological Sciences Directorate.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.