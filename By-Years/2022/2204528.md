* 2204528
* Human-centered Robot Manipulation Planning for Solving Object Handover Tasks in the Real-World
* CSE,IIS
* 09/01/2022,08/31/2025
* Ahmed Qureshi, Purdue University
* Standard Grant
* Jie Yang
* 08/31/2025
* USD 389,468.00

Robots aiming to assist people in their daily lives need to have robust skills
in handing over arbitrary, unknown objects to and from their interacting
partners in various environments. Older people, especially those with a
disability, often have difficulty maneuvering and need assistance even for minor
chores such as handing over the TV remote, fetching water bottles, and other
items such as medicines. This need for assistance has become even clearer from
the COVID-19 outbreak, requiring collaborative robots with object handover
skills to keep the affected person and their caretakers at a safe distance.
Similarly, such robot abilities in factories can significantly improve work
efficiency by handing over various tools to and from their collaborating
workers. However, despite the significance of having robots with object handover
skills, such a fundamental task remains unsolved. This proposal presents a
framework to solve the human-robot handover tasks with arbitrary daily-life
objects in uncontrolled environments and explicitly considers the most-used
items by patients with motor impairments such as Amyotrophic Lateral
Sclerosis.&lt;br/&gt;&lt;br/&gt;The technical contributions of this proposal are
divided into three research thrusts. First, a novel task-aware, 3D pose
forecasting approach will be introduced to predict future poses of the full
human body and their handheld objects from raw sensory information. During
inference, various human body parts that are crucial for robot decision-making
and control in solving human-robot object handover tasks will also be
highlighted through learning-based attention models. Second, the proposal will
formalize, represent, and learn the task-specific physical human-object and
object-object interactions to predict socially feasible target object poses for
handovers concerning the expected human behaviors and robot’s kinematic
reachability during manipulation. Third, the predicted human behaviors and
desired object handover poses will be used to determine human-friendly robot
grasp and generate informed human-aware robot motion sequences. Finally, the
proposed research thrusts will be integrated into a unified framework to solve
human-to-robot and robot-to-human handover tasks with arbitrarily unknown
objects from raw visual observations. The proposal’s outcomes will also exhibit
new, proof-of-concept, human-robot handover demonstrations in the real-world
using various most-used items by people with motor
impairments.&lt;br/&gt;&lt;br/&gt;This project is supported by the cross-
directorate Foundational Research in Robotics program, jointly managed and
funded by the Directorates for Engineering (ENG) and Computer and Information
Science and Engineering (CISE).&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.