* 2221009
* Collaborative Research: CIF: Medium: Statistical and Algorithmic Foundations of Efficient Reinforcement Learning
* CSE,CCF
* 01/01/2022,09/30/2025
* Yuxin Chen, University of Pennsylvania
* Continuing Grant
* Phillip Regalia
* 09/30/2025
* USD 300,000.00

As a data-driven paradigm for sequential decision making in unknown
environments, Reinforcement Learning (RL) has received significant interest in
recent years owing to its potential ability to solve difficult problems
associated with future societal and scientific developments. However, the
explosion of both model dimensionality and complexity in current and emerging
applications exacerbates the challenge of achieving efficient RL in sample-
starved situations, where data collection is expensive, time-consuming, or even
high-stake, e.g., in clinical trials, online advertising, and autonomous
systems. As a result, understanding and improving the sample and computational
efficiencies of RL algorithms, sometimes under additional resource and system-
level constraints, are rightly understood as critical to the successful
deployment of RL in the future. In this project the PIs are involving students
at all levels with diverse backgrounds in Electrical and Computer Engineering,
and in Statistics, are developing education modules on RL to enrich the
curriculum, and are co-organizing workshops and outreach activities to enable
the broader dissemination of the project outcomes.&lt;br/&gt;&lt;br/&gt;Despite
decades-long research efforts, the statistical and computational underpinnings
of RL are still far from being well understood, especially when it comes to
finite-sample and finite-time issues which are of crucial operational value.
This research project is bridging the theory-practice gap of modern algorithmic
approaches to RL. It is doing so by (i) characterizing fundamental limits for
the sample and computations complexities in various RL settings, (ii) by
developing performance guarantees and uncertainty quantification schemes, and
(iii) by designing new computationally efficient algorithms that are provably
near-optimal in terms of sample complexity in both single-agent and multi-agent
settings. The expected outcomes will enable the trustworthy adoption of RL
algorithms in sample-starved environments. The complementary expertise of the
research team is being leveraged to enrich the statistical and algorithmic
foundations of RL through model-, policy-, and value-based approaches. New
efficient algorithms that rely on function approximation schemes are being
developed in order to address the curse of dimensionality; the resulting
techniques are intended to lead to non-asymptotic analysis tools that deal with
the complicated statistical dependencies present in RL. This rich research
agenda is expected to foster multidisciplinary efforts at the intersection of
high-dimensional statistics, non-convex optimization, control theory,
information theory, and machine learning.&lt;br/&gt;&lt;br/&gt;This award
reflects NSF's statutory mission and has been deemed worthy of support through
evaluation using the Foundation's intellectual merit and broader impacts review
criteria.