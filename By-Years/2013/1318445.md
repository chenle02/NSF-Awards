* 1318445
* SHF: Small: Collaborative Research: Modeling and Analyzing Big Data on Peta- and Exascale Distributed Systems supported by MapReduce Methodologies
* CSE,CCF
* 09/01/2013,08/31/2017
* Michela Taufer, University of Delaware
* Standard Grant
* Almadena Chtchelkanova
* 08/31/2017
* USD 459,000.00

Current petascale platforms can perform large-scale simulations and generate
massive amounts of data at unprecedented rates. These rates are expected to
increase as exascale platforms are introduced. The generation of more and more
data presents new challenges for scientists who struggle with the analysis,
sorting, and selection of scientifically meaningful results. When very large
amounts of data records are located across a large number of nodes in a
distributed memory system, even a small number of comparisons can be costly or
even impossible. Therefore, new methodologies are necessary to analyze large
scientific datasets at scale.&lt;br/&gt;&lt;br/&gt;The goal of this project is
to develop a transformative analysis method to model the properties of large
scientific datasets in a distributed manner on petascale systems today and
exascale systems in the future. The research activity includes (1) the design of
new algorithms for encoding properties embedded in distributed data in a
parallel manner by using space reduction techniques; (2) the design of new
algorithms for clustering and classifying these properties by using distributed
paradigms such as MapReduce; (3) the deployment of the algorithms for diverse
datasets in structural biology and astronomy; and (4) the tuning of the
algorithms for both result performance and accuracy on emerging storage
technologies. &lt;br/&gt;&lt;br/&gt;The analysis method will provide the
scientific community with infrastructures and instrumentations to identify
features that can be used to predict class memberships; find recurrent patterns
in datasets; and identify class memberships from a specific feature or property.
By effectively and accurately capturing scientific information in a scalable
manner, these infrastructures and instrumentations will break the traditional
constraint of data centralization and allow scientists to overcome the
difficulties associated with the fully distributed nature of the data
considered.&lt;br/&gt;&lt;br/&gt;The project's educational component promotes
training and learning in computational modeling and analysis techniques as well
as data-intensive algorithms and platforms by involving undergraduate and
graduate students in research activities and integrating big data analytics into
the undergraduate curriculum at the University of Delaware. The research-based
educational materials developed in this project will be made available to the
scientific community through the project portal and through tutorials at XSEDE
and Supercomputing (SC) conferences.