* 9209773
* Recovery of Viewer-Centered and Object-Centered Depth from  2-D Projections
* SBE,BCS
* 08/15/1992,07/31/1996
* Myron Braunstein, University of California-Irvine
* Continuing Grant
* Jasmine Young
* 07/31/1996
* USD 189,138.00

Perceiving the three-dimensional environment on the basis of the two-
dimensional images projected onto the retinas of the two eyes requires
integration of different sources of depth information. This project will examine
the integration of two types of depth information, i.e., viewer-centered
information, which provides relative distances between an observer and objects
in the environment, and object-centered information, which provides relative
distances within an external scene, independent of viewer location. The viewer-
centered information that will be studied will include binocular disparity
(differences in the object's projection onto the retinas of the two eyes as a
function of relative distances from the observer) and motion parallax
(variations in the velocities projected onto the eye as a function of distance
from the observer). The object-centered information of primary interest is
structure-from-motion (use of changing distances in the projection to recover
distances between features on a three-dimensional object, under an assumption of
rigid motion). One series of experiments will examine how the perceived three-
dimensional shapes of objects are determined by the partitioning of motion in
the retinal images into viewer-centered and object-centered components (motion
parallax and structure-from- motion). A second series of experiments will
examine integration of shape recovered from object-centered information into a
viewer- centered representation of the three-dimensional environment. A third
series of experiments will examine the changes in the perceived shapes and
orientations of objects that occurs when information indicating lack of depth is
added to a three- dimensional scene. A fourth series of experiments will
determine the minimum number of visible features on an object needed to detect a
surface from a combination of viewer-centered information (binocular disparity)
and object-centered information (structure- from-motion). The objective of this
research is to understand how different types of depth information are combined
to provide an integrated perception of the three-dimensional environment. This
has relevance for such issues as optimizing human performance in object
recognition in actual three-dimensional environments and designing artificial
three-dimensional displays, including displays for flight simulators and
aircraft displays that represent the virtual environment.