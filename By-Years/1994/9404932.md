* 9404932
* Post Doctoral:  Probabilistic Models for Hierarchical       Neural Networks
* CSE,EIA
* 09/01/1994,08/31/1996
* Michael Jordan, Massachusetts Institute of Technology
* Standard Grant
* Tse-yun Feng
* 08/31/1996
* USD 43,488.00

9404932 Jordan The Associateship in Experimental Science will support a program
of interdisciplinary research at the Massachusetts Institute of Technology. The
proposed research will focus on probabilistic models for hierarchical neural
networks. Two specific architectures will be studied in detail: hierarchical
mixtures-of-experts (HME) and Boltzmann trees. HME networks that model mixtures
of more complicated probabilistic processes, such as hidden Markov chains and
optimal observers will be developed. The expectation-maximization (EM) principle
from statistics will be utilized to develop learning algorithms for these
architectures. The behavior of these EM algorithms will be analyzed by
exploiting the relationship of EM to mean-field theories from statistical
physics. Boltzmann machines are a general class of probabilistic model for
constraint satisfaction whose development has been hindered by the lack of an
efficient learning algorithm. Boltzmann machines with tree-like architectures
have simplifying features that make them faster and more efficient. Further work
on Boltzmann trees will lead to more powerful algorithms for supervised and
unsupervised learning. Various parallels between Boltzmann trees and belief
networks for probabilistic reasoning will be explained. ***