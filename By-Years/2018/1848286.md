* 1848286
* CAREER: Understanding and Advancing Fair Representation in Algorithmic Systems
* SBE,SES
* 07/01/2019,06/30/2024
* Malte Ziewitz, Cornell University
* Continuing Grant
* Frederick Kronz
* 06/30/2024
* USD 400,300.00

Understanding the social consequences of algorithmic systems has become a key
concern for policy makers, engineers, and academics due to reports of bias,
discrimination, and misrepresentation in areas such as credit scoring, hiring,
and policing. This project will focus on understanding how ordinary citizens are
affected by, cope with, and challenge algorithmic systems. The investigator will
do so by using qualitative, historical, and ethnographic methods to understand
how people interact with web search engines, the effects search engine
optimization schemas, and how the situation of those who have been negatively
affected by algorithmic systems might be improved. In addition to primary
research, this proposal will fund an intervention among multidisciplinary teams
of graduate students to educate next generation experts to address issues of
fair representation and accountability in algorithmic
systems.&lt;br/&gt;&lt;br/&gt;Algorithmic systems are a pervasive aspect of
modern life in areas such as web searches, hiring decisions, credit rankings,
and determining the cost of health insurance policies. Important social issues
arise when the data and information produced by algorithmic systems turns out to
be inaccurate, biased, or discriminatory. This situation is made more
complicated because algorithmic systems are "black boxes," the inner workings of
which are often kept secret for proprietary reasons. This project will
investigate how algorithmic systems shape the lives of ordinary citizens, and
how citizens work to cope with and challenge them. Study 1 will combine in-depth
interviews and self-reflections to understand the lived experiences of data
subjects. Study 2 will blend document analysis and oral history interviews to
detail the history of search engine optimization. Study 3 will rely on
ethnography participant observation to investigate the ethics of algorithmic
design. Data and insights from these studies will then be used to create an
educational intervention aimed at informing graduate students from relevant
fields about fair representation and accountability in algorithmic
systems.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.