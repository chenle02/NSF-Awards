* 2146448
* CAREER: Empowering White-box Driven Analytics to Detect AI-synthesized Deceptive Content
* CSE,CNS
* 10/01/2022,09/30/2027
* Shuang Hao, University of Texas at Dallas
* Continuing Grant
* Dan Cosley
* 09/30/2027
* USD 96,488.00

This award is funded in whole or in part under the American Rescue Plan Act of
2021 (Public Law 117-2).&lt;br/&gt;&lt;br/&gt;Artificial intelligence (AI)
synthesis techniques that automatically produce realistic images, videos, and
other content have significantly improved over the past few years. Although
there are promising legitimate applications of these techniques, they also raise
serious trust and security threats. Cybercriminals increasingly weaponize AI
synthesis techniques to deceive users and manipulate opinions without having to
invest heavily in manual content generation. For instance, AI-synthesized
profile photographs are abused to create fake accounts, while deepfake videos
that simulate real people can give cybercriminals the ability to defame or
impersonate others. Existing detection work mostly relies on "black-box"
approaches that analyze content without considering the way the AI synthesis
techniques work. This project's goal is to use "white-box" methods that consider
how the techniques work, both to systematically detect AI-synthesized content,
and to outline general principles that underlie how broad classes of AI
synthesis algorithms work that will help detection algorithms adapt as new
synthesis techniques are developed. The results of this research will reinforce
user trust in online content and help social media sites and other Internet
platforms mitigate deception through AI-synthesized content. The project team
will integrate the new datasets and techniques developed in this research into
undergraduate and graduate courses as well as online exercises to train future
cybersecurity workers. The team will also support diverse participation in the
research, actively recruiting and mentoring women and people from other under-
represented groups.&lt;br/&gt;&lt;br/&gt;This research aims to advance AI
synthesis detection in terms of efficacy, generalizability, and robustness. The
work focuses on detecting AI-synthesized images and videos, as humans are more
likely to be attracted to and deceived by visual content. The developed
analytics principles are envisioned to inspire new work in these areas and
expand to detection of other types of AI-synthesized content. The project is
organized around three research thrusts. First, the team will develop a unified
analytic framework to systematically dissect AI-synthesis models and gain deep
understanding of synthesis patterns common across the models. Second, based on
these findings, the team will design generalizable approaches based on the
frequency and pixel domains to efficiently detect AI-synthesized images and
videos and operate at scale. Third, it will enhance detection robustness by
proactively investigating adversarial evasion strategies and prioritizing
detection techniques resistant to those strategies. The framework and the
developed techniques will be thoroughly evaluated with large-scale real-world
data. This research will contribute to establishing a principled detection
paradigm and provide insights to prevail over future forms of AI-based deception
and propaganda.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission
and has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.