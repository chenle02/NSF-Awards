* 1613026
* Computer-Intensive Methods for Nonparametric Analysis of Dependent Data
* MPS,DMS
* 07/01/2016,06/30/2019
* Dimitris Politis, University of California-San Diego
* Continuing Grant
* Gabor Szekely
* 06/30/2019
* USD 249,955.00

Ever since the recognition of the role of the computer in modern statistics, the
bootstrap and other computer-intensive statistical methods have been developed
extensively for inference with independent data. Such methods are even more
important in the context of dependent data, where the distribution theory for
estimators and test statistics may be difficult or impractical to obtain.
Furthermore, the recent information explosion has resulted in datasets of
unprecedented size that call for flexible, nonparametric, computer-intensive
methods of data analysis. Time series analysis in particular is vital in many
diverse scientific disciplines, including economics, engineering, acoustics,
geostatistics, biostatistics, medicine, ecology, forestry, seismology, and
meteorology. This research project aims to develop efficient and robust methods
for the statistical analysis of dependent data that will enable more accurate
and reliable inferences to be drawn from datasets of practical import, resulting
in appreciable benefits to society. Examples include data from
meteorology/atmospheric science (e.g. climate data), economics (e.g. stock
market returns), biostatistics (e.g. fMRI data), and bioinformatics (e.g.
genetics and microarray data). &lt;br/&gt;&lt;br/&gt;The project focuses on the
development of methods of inference for the analysis of time series and random
fields that do not rely on unrealistic or unverifiable model assumptions. In
particular, the investigator and colleagues are working on: (a) Markov-type
resampling and linear process bootstrap for stationary random fields; (b) local
block bootstrap for inference with inhomogeneous marked point processes; (c)
estimation of the degree of smoothness and support of the common density of
stationary data; (d) improved nonparametric estimation via the use of flat-top
kernels; (e) a bootstrap test for the null hypothesis of time series "over-
differencing;" (f) seasonal block bootstrap for almost-periodic data; (g) model-
free point predictors and prediction intervals for locally stationary time
series; (h) smooth estimation of time-varying covariance matrices for locally
stationary multivariate time series; and (i) different aspects of resampling
with functional data, including the difficult open problem of appropriately
studentizing a functional statistic.