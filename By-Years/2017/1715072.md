* 1715072
* Neural Mechanisms of Probabilistic Prediction in Language Comprehension
* SBE,SMA
* 06/01/2017,05/31/2018
* Emily Morgan, Morgan                  Emily          I
* Standard Grant
* Josie S. Welkom
* 05/31/2018
* USD 69,000.00

This award was provided as part of NSF's Social, Behavioral and Economic
Sciences Postdoctoral Research Fellowships (SPRF) program. The goal of the SPRF
program is to prepare promising, early career doctoral-level scientists for
scientific careers in academia, industry or private sector, and government. SPRF
awards involve two years of training under the sponsorship of established
scientists and encourage Postdoctoral Fellows to perform independent research.
NSF seeks to promote the participation of scientists from all segments of the
scientific community, including those from underrepresented groups, in its
research programs and activities; the postdoctoral period is considered to be an
important level of professional development in attaining this goal. Each
Postdoctoral Fellow must address important scientific questions that advance
their respective disciplinary fields. As the world becomes more interconnected,
it is increasingly important to be able to communicate with people from
different linguistic backgrounds. Learning to communicate within new linguistic
norms is not merely a feature of early childhood language learning but continues
throughout the lifetime. It is thus essential to study how speakers incorporate
statistical knowledge in new linguistic environments. This project takes a first
step towards understanding the neural mechanisms that enable comprehenders to
adapt to new linguistic norms. In particular, this project studies how
comprehenders use their statistical knowledge about the language and the world
(i.e. what things people tend to talk about, and what language they use to do
so) to make predictions about upcoming words, and how these predictions adapt to
a changing environment. The project focuses on three neural mechanisms: 1.
Retrieval of words from long-term memory. 2. Selection between competing
alternatives by activating one word and suppressing others. 3. Conflict
resolution when a prediction is violated by the actual linguistic input. The
project will further our understanding of language comprehension by developing
computational models of how these neural mechanisms adapt to changing statistics
in the linguistic environment (e.g. an interlocutor who tends to say very
predictable versus very unpredictable things) and testing these models against
electrophysiological data. Ultimately, the project will elucidate how these
neural mechanisms underlie language comprehension and how they allow for
lifelong language learning.&lt;br/&gt;&lt;br/&gt;In order to comprehend language
rapidly in a noisy and ever-changing world, comprehenders must leverage their
statistical knowledge about the language to resolve uncertainty. This project
studies how neural mechanisms make probabilistic predictions about upcoming
words and how these predictions adapt to changes in the linguistic environment.
The project combines computational modeling with cognitive neuroscience to make
quantitative predictions about the role of distinct mechanisms in language
processing, with a focus on testing the hypothesis that prediction in language
comprehension is a rampant, probabilistic process. First, the project will
develop a hierarchical generative model of probabilistic prediction in language
processing to make quantitative predictions about distinct neural mechanisms
using principled information theoretic measures. The project will then
investigate how the brain can implement this computational theory using
relatively recently discovered event-related potential (ERP) components, beyond
the time window of the classic N400 effect, crucially using these ERP components
to further our functional understanding of how these neural mechanisms implement
algorithmic processes hypothesized by the computational framework. Finally, the
project will use the computational framework and further ERP experiments to
investigate whether and how these mechanisms adapt to environments in which
unexpected events occur frequently. These experiments will elucidate the neural
mechanisms that underlie predictive processes in language comprehension, and how
such mechanisms allow for lifelong language learning. The project will advance
our understanding of language comprehension by unifying disparate theories from
computational psycholinguistics and cognitive neuroscience. The project includes
substantial methodological innovation beyond the current state-of-the-art, using
generative models to make quantitative predictions both about neural mechanisms
broadly and about learning curves during language adaptation. The investigators
will also develop methods for trial-by-trial ERP data analysis which are
particularly powerful for studying ongoing adaptation in changing environments.