* 2321649
* SaTC: CORE: Small: Study, Detection and Containment of Influence Campaigns
* CSE,CNS
* 10/01/2023,09/30/2026
* Bogdan Carbunar, Florida International University
* Standard Grant
* Sara Kiesler
* 09/30/2026
* USD 529,609.00

Influence operations are increasingly relying on social networks to distribute
and amplify misinformation and hate speech with significant societal impact.
Although social networks implement policies and attempt to stem the spread of
such undesirable content and the accounts that promote it, their efforts can
only succeed given an accurate understanding of influence operations resources
and strategies, and of user beliefs and reasons to distribute undesirable
content. Existing knowledge of influence operations has been collected through
limited journalistic investigations that lack scientific method, and forensic
analysis of social networks that increasingly limit researcher access. Further,
much knowledge of user interaction with undesirable content comes from lab
experiments that do not accurately model real life behaviors. This project
introduces a novel approach to study influence campaigns and improve our
understanding of the threats they pose, and will leverage gleaned insights to
develop solutions that detect and reduce the reach and impact of campaigns. This
project has the potential to minimize the attack surface to undesirable content
and influence campaigns for vulnerable social network users who lack the
background required to recognize and safely react to such content. Developed
solutions may further reduce perception of bias for people who distribute
undesirable content and give them a sense of fairness toward content moderation
techniques.

This project builds on the thesis that efforts to study and contain influence
campaigns need to involve the individuals who distribute undesirable content. To
achieve this aim, the project team designs and conducts informed-consent studies
with participants’ in-the-wild exposure to undesirable content, to understand
their goals, motivation, resources, strategies, and perceptions. The project
further develops a framework to detect influence campaigns, attribute
undesirable content and the accounts that post it to their organizers, and
characterize their strategies. The team also designs interventions that empower
selective audiences to reduce the reach and impact of undesirable content,
distribute responsibility for intervention outcomes, and obscure details from
adversaries. The project further develops protocols to recruit relevant
participants, triangulate findings, and evaluate solutions in the context of
participants’ in-the-wild exposure to and distribution of undesirable content.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.