* 2007036
* CIF: Small: Online Learning and Optimal Experiment Design with a Budget
* CSE,CCF
* 10/01/2020,09/30/2024
* Maryam Fazel, University of Washington
* Standard Grant
* Alfred Hero
* 09/30/2024
* USD 500,225.00

Machine learning is routinely used in science and industry to make inferences
about a phenomenon that cannot be observed directly, but can be probed through a
series of experiments. For instance, the chief metric when optimizing a chemical
reaction may be the yield of the desired output, but many experimental
conditions such as pH and ambient temperature may affect the yield. Adaptive
experimental design provides a framework to exploit observed measurements of the
past to plan measurements in the future in a closed loop. It has been shown to
require far fewer overall measurements to achieve the same inference goals
compared to any fixed plan chosen in advance. However, a limitation is the
implicit assumption that every possible measurement is available at all times.
In practice this is rarely true - for example chemical reagents can run out and
restrict the possible experiments. This forces a tradeoff on practitioners: if
only a subset of measurements are possible at the current time and you have a
fixed budget of experiments, is it worth it to take one of the available
experiments, or abstain in the hope of better opportunities in the future? The
focus of this research is to formalize such questions and develop a framework
for addressing online adaptive experimental design in the sequential setting of
unpredictable measurement availability. The project also includes a plan to
vertically integrate robust data collection techniques across the university
touching all levels and disciplines, as well as outreach that starts with K-12
students and extends to the community at large.&lt;br/&gt;&lt;br/&gt;This
project amalgamates insights from adaptive experimental design, multi-armed
bandits, and online algorithms. Current adaptive experimental design methods,
for instance in stochastic optimization and best-arm identification, assume
access to a fixed batch of experiments to choose from at each time, and
explicitly plan to evolve the allocation of measurements over this batch using
optimal design techniques such as G-optimal design. However, if the measurement
set is changing at each time, potentially adversarially, such planning is
extremely difficult. Motivated by progress in specific cases that leverage
advances in convex optimization, the project seeks to provide a general
framework for experimental design including optimization and multiple testing in
online settings.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.