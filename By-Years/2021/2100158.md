* 2100158
* RI: Small: Uncertainty Quantification for  Nonconvex Low-Complexity Models
* CSE,IIS
* 10/01/2021,03/31/2022
* Yuxin Chen, Princeton University
* Standard Grant
* Rebecca Hwa
* 03/31/2022
* USD 450,000.00

Emerging applications in data science often involve estimating an enormous
number of parameters from a highly incomplete and noisy set of measurements. In
order for these applications to support modern scientific discovery and decision
making, however, it is necessary to seek not merely reasonable estimations for
the parameters, but perhaps more crucially, a trustworthy interpretation of the
estimations and their implications. For instance, what reassurances can we offer
about the quality of the estimates in hand? Can we quantify the uncertainty of
our estimates due to the imperfectness of the data? Providing valid and
quantitative answers to such questions is a crucial step in ensuring that: the
scientific discovery and decision made based on our estimate are informative and
trustworthy. Nevertheless, the existing statistical toolbox remains highly
inadequate in providing measures of uncertainty for large-scale estimation
methods, particularly in those scenarios where the availability of data samples
is severely limited. This limits the overall value of the estimates and hampers
scientific and decision-making processes. Some example application areas
include: joint shape matching in computer vision and water-fat separation in
medical imaging.&lt;br/&gt; &lt;br/&gt;Motivated by the above issues, the
overarching goal of this project is to develop new foundational theory that
integrates statistical assessment and algorithm design in an end-to-end manner,
allowing for optimal inferential procedures for various nonconvex low-complexity
models. Blending large-scale optimization techniques with statistical thinking,
the proposed project seeks to develop a novel suite of distributional theory
that enables valid uncertainty assessment for various nonconvex low-complexity
models. Specifically, this project consists of the following research. First,
develop a principled approach to construct optimal confidence intervals for
unknown continuous parameters, on the basis of novel nonconvex estimation and
de-biasing methods. Second, develop fast nonconvex algorithms and efficient
uncertainty assessment procedures to reason about unknown discrete variables.
Third, investigate the intimate connection between convex relaxation and
nonconvex optimization, thus enabling a unified uncertainty quantification
framework to accommodate both approaches. All research thrusts are motivated by,
and will ultimately be tested on concrete practical applications. This project
will significantly advance the fundamental techniques of uncertainty
quantification in data-driven applications, and will enrich the foundations for
mathematical optimization, data analytics, and statistical
modeling.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.