* 2327143
* EAGER: Building Language Technologies by Machine Reading Grammars
* CSE,IIS
* 06/15/2023,05/31/2024
* Antonios Anastasopoulos, George Mason University
* Standard Grant
* Eleni Miltsakaki
* 05/31/2024
* USD 99,294.00

Recent years have seen incredible advances in natural language processing (NLP)
technologies, which now make it possible to perform numerous tasks through,
with, or on language data. However, this progress has been limited to the
handful of languages for which abundant data are available, because the neural
models that facilitate the recent improvements are particularly data hungry.
This work suggests that we should move away from the current data-inefficient
learning paradigm, and instead attempt to also model languages by relying on the
human mode of describing them: the grammar of each language. Put simply, we will
aim to incorporate the grammars of languages, as written by linguists and
treated as symbolic knowledge bases, in the process of training neural language
models.

Specifically, this work will focus on the first step towards this goal, namely
extracting the necessary information from grammar descriptions and other
linguistic documents. We will explore several alternative modeling approaches,
first by relying on retrieval-based models. We will additionally attack the
problem through a machine-reading and question-answering framework. Ultimately,
the success of these methods will enable the creation of linguistically-informed
models, which will in turn facilitate the creation of technologies especially
for under-served language communities.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.