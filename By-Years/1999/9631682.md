* 9631682
* Visual Perception as Statistical Inference
* SBE,BCS
* 10/01/1996,10/31/2000
* Daniel Kersten, University of Minnesota-Twin Cities
* Continuing Grant
* Rodney R. Cocking
* 10/31/2000
* USD 204,159.00

9631682 KERSTEN One of the great mysteries of science is how the human visual
system determines what and where objects are just by looking. When viewing a
scene, the visual system solves, in an instant, the problems of recognizing
objects, deciding what they are made of, and where they are relative to each
other and the viewer. The seeming effortlessness of this achievement is all the
more remarkable because the image input to the eye is locally ambiguous, i.e.,
in any patch of an image, there is rarely an unequivocal cue to how far away it
is, what it is made of, or how it is illuminated. Somehow, the brain makes its
best bet as to what is out there from this ambiguous image, and these decisions
are rarely wrong. In addition, the image of an object is highly variable
depending on illumination and viewpoint. For example, illuminating an object
from the left or right has relatively little effect on our perception of the
object, despite the fact that the object's two images are quite different. This
research stems from the hypothesis that vision solves the problem of ambiguity
by exploiting the constraints on how images are formed and on the a priori
statistical regularities inherent in object and scene structure. From this point
of view, vision is a process of statistical inference that makes good bets based
on available information and solves the problem of variability, in part, by
constraints that are determined by the task itself, such as determining where,
rather than what, an object is. This research will investigate human perception
of the spatial layout of objects and object properties. Vision determines
spatial layout from well over a dozen sources of depth information, including
cast shadows. It is well-known to artists that the closer the image of an
object's shadow is to the object itself, the closer the object is to the surface
receiving the shadow. How visual perception makes this inference is not clear,
because local image informatio n does not uniquely specify whether a local
brightness change is a shadow or not. This research will identify constraints in
the image and scene that resolve the ambiguities in the perception of depth from
shadows. As for the perception of spatial layout, determining object properties
and identity is also confounded by local ambiguity as well as by variability in
illumination. Experiments comparing the performance of human and statistically
optimal observers for inferences about object shape, material and identity will
tease apart the relative roles of prior knowledge and image cues in removing
uncertainty about the properties of objects. Visual perception is a major way in
which we acquire knowledge of the world. Computer scientists have yet to produce
a machine that can recognize objects in natural images. Understanding how human
vision resolves ambiguity about object location and identity promises to guide
the development of artificial vision systems and help to unravel the mysteries
of the brain itself. ***