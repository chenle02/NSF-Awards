* 9057896
* Presidential Young Investigators Award: Fast Neural Network Like Optimization Techniques
* ENG,ECCS
* 06/01/1990,03/31/1998
* Mohamad Hassoun, Wayne State University
* Continuing Grant
* Paul Werbos
* 03/31/1998
* USD 312,500.00

The P.I.'s currently interested in research in massively parallel, disturbed,
and collective computations, artificial neural systems, learning machines,
associative neural memories, photonic computing, and optical neural network
implementations. In the area of neural networks, he plans to investigate the
performance of various associative neural memory architectures and related
recording/learning algorithms. He has introduced new high-performance
recording/learning algorithms for associative memories, and is currently
investigating the dynamics of such neural memories for various
recording/learning algorithms. In the Computation and Neural Networks
Laboratory, he and his students are developing unsupervised learning self-
optimizing neural net architectures for clustering and unsupervised pattern
classification. In another project, neural net architectures will be employed in
solving complex optimal path finding problems in two- and higher-dimensions. He
will also be investigating the optical implementations of artificial neural
systems. He holds a patent for the first integrated optical threshold gate
("optical neuron") and has developed fiber optic cross-bar network fabrication
techniques, which are potentially useful in optical neural network
implementations. He has recently completed the design and implementation of a
fiber optic-base high-performance dynamic associative neural memory prototype.
He is also interested in the application of neural networks in signal processing
and parallel computing. In a joint effort with researchers at Wayne State's
Neurology Department, he is developing a neural-network-based technique for
automatic quantification of the clinical Electromyogram (EMG) for clinical
diagnostic purposes. His future research will focus on adaptive unsupervised
synthesis techniques for high- performance dynamic artificial neural networks.
He will also be investigating ways of speeding up learning in multiple-layer
neural nets through self-optimizing neural architectures. His future research
will also involve proposing and implementing large scale high- performance fiber
optic interconnected dynamic associative neural memories and other neural
network paradigms.