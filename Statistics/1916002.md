
* 1916002
* Privacy-Preserving Bayesian Inference: Foundations and Extensions
* DMS,STATISTICS
* 09/01/2019,07/30/2019
* Ruobin Gong,NJ,Rutgers University New Brunswick
* Standard Grant
* Pena Edsel
* 08/31/2022
* USD 100,000.00

This project provides a theoretical foundation and computational methodologies
to conduct Bayesian statistical inference using differentially private data.
Differential privacy is a mathematical framework that allows the release of
potentially sensitive data in such a way that protects the confidentiality of
individual records without unduly sacrificing its overall usefulness for
statistical analysis. As our society today grapples with the privacy
implications that accompany the exploding growth of large-scale datasets, the
invention of differential privacy provides a solution to protect personal
demographic and biological information without deterring the accumulation of
public knowledge. The U.S. Census Bureau has officially adopted differential
privacy as the disclosure avoidance method for the 2020 Census. Other data
collectors and curators are expected to follow suit in the near future. This
project answers the pressing need for new statistical theory and methods to
appropriately understand and efficiently analyze differentially private data.
The project will expand the repertoire of tools available to researchers, and
contribute to the cause of creating a better informed and more transparent
society while respecting individual privacy. The PI will work on a theoretical
formulation of the definitions of differential privacy using imprecise
probability constructions, including interval of measures and coherent upper-
lower probability measures. In the Bayesian context, such a formulation delivers
a robust-likelihood conception of the model and allows for the computation of
bounds on posterior quantities based on differentially private data for
arbitrary prior specifications. The PI also proposes the differentially private
approximate Bayesian computation (ABC) algorithm, a noisy ABC algorithm that
delivers exact posterior inference given differentially private observations
subject to arbitrary additive noise. The algorithm permits differentially
private inference from large-scale Bayesian models with intractable likelihoods.
The project bridges the classic theories of robust Bayes and generalized Bayes,
with the novel literature on statistical privacy, and derives practical
implementations based on privacy-preserving data releases. The project will
supply analysts and researchers in a timely fashion with inferential
methodologies tailored for differentially private input that are both
theoretically sound and computationally efficient.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.
