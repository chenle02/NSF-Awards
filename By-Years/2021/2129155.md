* 2129155
* Collaborative Research: HCC: Small: Leveraging a Wrapped Haptic Display to Communicate Robot Learning and Accelerate Human Teaching
* CSE,IIS
* 10/01/2021,09/30/2024
* Laura Blumenschein, Purdue University
* Standard Grant
* Todd Leen
* 09/30/2024
* USD 249,489.00

Humans excel at teaching physical activities and tasks through demonstration and
physical correction (think of a coach guiding an athlete through a desired
motion), and human learners often use verbal and nonverbal signals to
communicate their understanding or confusion. Similar approaches to teaching
have been used between humans and robots, allowing humans to naturally
demonstrate tasks, like cooking or furniture assembly, and correct errors in the
motions of the robots. While robots have made great advances in understanding
the demonstrations and corrections from human teachers, they have lacked an
effective way to communicate what they do and do not understand, so human
teachers may not know when or if a robot is ready to carry out a task by itself.
This project will address this communication gap by developing new ways for
robot arms to communicate to human teachers as they learn. The investigators
will attach haptic skin displays (arrays of controllable bubbles) to a robotic
arm and create touch sensations to communicate the robot’s understanding or
confusion to the human teacher. Better and more understandable communication
from robots as they learn will allow users to train or retrain robots more
efficiently, and to better know when they are ready to deploy, without needing
specialized knowledge about how robots function. These features will make robot
arms more attractive tools for small and mid-sized manufacturers, allowing them
to flexibly automate some manufacturing tasks. The lessons learned about
communicating the learning state of robotic arms can also be applied to other
computer and robotic systems, making the opaque process of robot and computer
learning more comprehensible and giving the opportunity to catch and correct
errors.&lt;br/&gt;&lt;br/&gt;The goal of this project is to characterize how
humans perceive haptic skin displays wrapped around robot arms, and to formalize
how robots capture and communicate feedback through these haptic arrays. Prior
work enables robots to learn from physical demonstrations; however, it is
equally important to make this learning transparent to the human teacher. This
project will advance transparent and interpretable robot learning from an
algorithmic and haptic perspective. The team of investigators will i)
characterize the types and patterns of exploratory haptic feedback the human
perceives, ii) embed the robot's complex and high-dimensional reward learning
into low-dimensional haptic feedback, and iii) model how humans interpret the
robot's feedback. These steps will ultimately provide human teachers with an
awareness of the robot’s understanding and thereby improve their demonstrations.
Each contribution will be evaluated in human subject studies with a commercial
robot arm. This project has the potential to advance robotics in small and mid-
sized manufacturing by making the process of teaching robot arms intuitive,
transparent, and user-friendly.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.