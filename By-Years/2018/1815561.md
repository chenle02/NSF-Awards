* 1815561
* RI: Small: A Unified Compositional Model for Explainable Video-based Human Activity Parsing
* CSE,IIS
* 09/01/2018,08/31/2023
* Ying Wu, Northwestern University
* Standard Grant
* Jie Yang
* 08/31/2023
* USD 449,000.00

An ultimate goal of computer vision is understanding scene and activities from
images and video. This task involves many perceptual and cognitive processes at
various semantic levels. A next step beyond visual classification is visual
interpretation, that is, to explain the relations among visual entities through
visual inference and reasoning. Due to the enormous variability across instances
of this problem, semantic parsing for explaining a visual scene and activities
is highly challenging. This project studies how the structural composition of
visual entities can be used to overcome the diversity in the visual scene and
activities. It advances and enrich the basic research of computer vision, and
brings significant impact on many merging applications, including autonomous or
assisted driving, intelligent robots, and intelligent video surveillance. This
research also contributes to education through curriculum development, student
training, and knowledge dissemination. It includes interactions with K-12
students for participation and research opportunities.
&lt;br/&gt;&lt;br/&gt;This research is to develop a unified visual compositional
model that can effectively learn complex semantic concepts in a scalable end-to-
end fashion, while achieving good generalizability and providing explainable
parsing of the visual data. The project is focused on: (1) a principled model
and its theoretical foundation, by designing a stochastic grammar based on the
probabilistic And/Or-Graph to model the structural composition; (2) an effective
computational approach for learning and parsing, by exploiting data-driven
pattern mining to discover structural components and by exploring how the
patterns may be self-formed; (3) a solid case study on video human activity
parsing and interpretation, by inferring the complex compositions of human
actions, body movements, and interaction with the environment; and (4) tools and
prototype systems for human articulated body pose estimation, contextual object
discovery, and video-based human activity analysis and
interpretation.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission
and has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.