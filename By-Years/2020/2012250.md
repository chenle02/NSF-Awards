* 2012250
* Multifidelity Nonsmooth Optimization and Data-Driven Model Reduction for Robust Stabilization of Large-Scale Linear Dynamical Systems
* MPS,DMS
* 06/01/2020,05/31/2024
* Michael Overton, New York University
* Continuing Grant
* Yuliya Gorb
* 05/31/2024
* USD 400,000.00

Autonomous systems play an increasingly important role in engineering
applications and in society as a whole, from cars to airplanes to medical
devices. Truly autonomous systems will have to be able to act and make decisions
under uncertainty. The key component that decides what action an autonomous
system takes is the controller of the system, which guarantees that the system
always remains in stable and safe states. Thus, designing controllers to
stabilize systems is an important problem in a wide range of applications that
include virtual or physical systems acting in an environment. The computational
methodologies that will be developed in this project aim towards a reliable
stabilization of large-scale systems from data alone, even when only little data
and data polluted with noise are available. These algorithms have the potential
to have significant impact on critical issues such as efficiency, safety, and
reliability of autonomous systems. The project will promote cross-disciplinary
collaborations from machine learning to control theory to numerical analysis to
scientific computing and will support education and diversity by creating novel
courses and outreach activities that integrate underrepresented groups in the
above disciplines.&lt;br/&gt;&lt;br/&gt;Robust stabilization typically requires
solving nonsmooth, nonconvex optimization problems that are computationally and
mathematically challenging. Furthermore, in many situations, models of the
systems of interest are unavailable. Rather, data are sampled from the systems
and stabilization has to be achieved via learning from these data. This project
develops and integrates new methods for nonsmooth optimization via gradient
sampling and data-driven (nonintrusive) model reduction via the Loewner
framework. The first contribution will be a multifidelity version of the
gradient sampling algorithm for nonsmooth optimization that exploits low-cost,
low-fidelity gradient approximations of a computationally expensive objective to
accelerate the estimation of gradients. If successful, this multifidelity
approximation has the potential to make tractable gradient sampling for large-
scale optimization problems and at the same time maintain the rigorous
convergence guarantees that gradient sampling is known for. The second
contribution is to exploit the stability radius of robust controllers to reduce
the number of data points (samples) that are required to learn reduced models
for stabilizing systems. To that end, a new approach for learning reduced models
from data is proposed that allows the learned models to divert from the real
system dynamics by as much as can be compensated for by the robustness
(stability radius) in favor of reducing the number of data points. If the
project is successful, the developed methodologies will enable efficiently and
rigorously stabilizing systems that are large-scale and from which few data
points and/or high-noise data are available.&lt;br/&gt;&lt;br/&gt;This award
reflects NSF's statutory mission and has been deemed worthy of support through
evaluation using the Foundation's intellectual merit and broader impacts review
criteria.