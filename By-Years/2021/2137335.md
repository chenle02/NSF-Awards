* 2137335
* EAGER: Towards Fair Regression under Sample Selection Bias
* CSE,IIS
* 09/01/2021,08/31/2023
* Xintao Wu, University of Arkansas
* Standard Grant
* Sylvia Spengler
* 08/31/2023
* USD 150,000.00

Decision making models are ubiquitous in applications like employment, credit,
and insurance. Increasingly, there are worries of inaccurate decisions or even
discrimination from predictive decision models that have been trained on a
collection of data. Fair machine learning has been an increasingly important
topic. Fair machine learning models aim to learn a function for a target
variable while ensuring the predicted value is fair based on a given fairness
criterion. Much of the existing work focuses on fair classification. This
project researches fair regression where the decision such as loan amount is
continuous and focuses on the scenario where the existing data for building the
model have different distributions from the model's future data. In particular,
this project deals with the sample selection bias where the values for the
dependent variable from the training dataset are missing. The project aims to
develop a unified framework and practical solutions for achieving rigorous
fairness and high accuracy of the built regression model via bias correction and
optimization techniques. &lt;br/&gt;&lt;br/&gt;The technical aims of this
project are divided into three thrusts. The first thrust develops the unified
framework for fair regression under sample selection bias. The framework adopts
the classic Heckman model to correct bias and enforces multiple advanced
fairness notions via constrained optimization. The second thrust applies the
Lagrange duality theory and develops reduction approaches to solve constrained
optimization. Theoretical studies of achieving strong duality for fairness
notions and research of deriving approximation techniques for efficient
optimization will be conducted in this thrust. The third thrust conducts
empirical evaluation of the developed framework and algorithms in terms of
prediction accuracy and fairness with benchmark datasets and real applications,
implements and integrates the algorithms into open source libraries for fair
machine learning. The research findings expect to advance theoretical
understanding of fair regression, improve its applicability for handling sample
selection bias, and help transition of fair regression algorithms to use in real
systems.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.