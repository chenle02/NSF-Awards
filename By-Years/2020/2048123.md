* 2048123
* CAREER: Provable Patching of Deep Neural Networks
* CSE,CCF
* 07/01/2021,12/31/2026
* Aditya Thakur, University of California-Davis
* Continuing Grant
* Pavithra Prabhakar
* 12/31/2026
* USD 326,080.00

Deep neural networks (DNNs) have been successfully applied to a wide variety of
problems, including image recognition, natural-language processing, medical
diagnosis, and self-driving cars. As the accuracy of DNNs has increased so has
their complexity and size. Moreover, DNNs are far from infallible, and mistakes
made by DNNs have led to loss of life, motivating research on verification and
testing to find mistakes in DNNs. In contrast, the central goal of this research
is to develop techniques and tools for repairing a trained DNN once a mistake
has been discovered. &lt;br/&gt;&lt;br/&gt;Provable Patching of DNNs computes a
minimal change (patch) to the parameters of a trained DNN to correct its
behavior according to a given specification. The project is interdisciplinary,
combining the areas of Formal Methods and Machine Learning. The project develops
theoretical foundations, designs efficient algorithms, and evaluates practical
applications of Provable Patching of DNNs. The intellectual merits are (i)
ensuring that the patching techniques are provably effective, generalizing,
local, and efficient, and (ii) supporting different classes of safety and
fairness specifications. The broader impacts of the project include (i)
developing new undergraduate and graduate courses related to program correctness
and formal methods, and (ii) broadening the participation of Computer Science
undergraduate students by developing education and research activities targeting
community college and transfer students.&lt;br/&gt;&lt;br/&gt;This award
reflects NSF's statutory mission and has been deemed worthy of support through
evaluation using the Foundation's intellectual merit and broader impacts review
criteria.