* 2005884
* SHF: Small: Automatic, adaptive and massive parallel data processing on GPU/RDMA clusters in both synchronous and asynchronous modes
* CSE,CCF
* 07/01/2020,06/30/2024
* Hao Wang, Ohio State University
* Standard Grant
* Danella Zhao
* 06/30/2024
* USD 539,783.00

The computing ecosystem in both hardware and software is in a critical
transition time, coming from several technology crises and inevitable trends.
First, the continued performance improvement in general-purpose processors is no
longer realistic. Second, conventional processors are increasingly inefficient
in both performance and power consumption for various data-intensive
applications. Finally, the deep software stack that has been developed for
several decades, from instruction-set architecture all the way to the
programming layer in the existing ecosystem, has added cumbersome processing and
even unnecessary overhead in computing. To address the above-mentioned issues,
this project remedies the computing ecosystem in an accelerator-based way. GPU
(Graphic Processing Unit) and RDMA (Remote Data Memory Access) are the two
external hardware accelerators considered in the project. It aims to turn
efficient asynchronous computing into a reality on clusters of hardware
accelerators of GPU and RDMA adaptively and automatically by removing three
technical barriers in the existing ecosystem: (1) the programming-model barrier,
(2) the hardware abstraction barrier, and (3) the automation barrier. The
project strives to make broad and transformational impact. It is expected to
influence the data-processing research community with new algorithms and
effective systems implementation, and influence industries to improve their
production systems in their daily computing operations serving society. The
developed algorithms, source code and measurements are available online for a
public and wide usage, benefiting both industrial and academic researchers. The
research training to both undergraduate and graduate students address the
concerns of lacking hardware-acceleration and data-analytics professionals in
information technology and computing industries. The curriculum development
introduces related research results to classrooms and the outreach activities
encourage high school students to be interested in computing related college
education. &lt;br/&gt;&lt;br/&gt;The existing computing environment does not
provide programming models for asynchronous execution. It is even harder for
asynchronous programming on GPU/RDMA clusters. The execution-model difference
between CPUs and GPUs makes the system lack a common hardware abstraction for
GPU computing and for RDMA communication and management. Asynchronous
programming is hard, and an automatic tool to ensure its correctness and
efficiency is highly desirable. This research project bridges the gap between
asynchronous computing and GPU/RDMA. It develops an autonomous memory pool (AMP)
interfacing GPU/RDMA clusters, where an intermediate representation is proposed
to abstract the GPU execution and AMP constructed by an RDMA. A set of
intermediate representations are developed to support asynchronous programming,
so that users can easily express asynchronous computing in programming. In
addition, an intermediate representation is developed to allow conventional
synchronous programming to become automated asynchronous execution code. The
system is tested and evaluated using representative data-processing workloads on
large GPU/RDMA clusters.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.