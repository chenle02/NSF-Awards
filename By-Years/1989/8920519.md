* 8920519
* Developing and Understanding Methods for Nonlinear          Optimization
* CSE,CCF
* 04/15/1990,03/31/1992
* Richard Byrd, University of Colorado at Boulder
* Standard Grant
* S. Kamal Abdali
* 03/31/1992
* USD 119,726.00

This project is devoted to research in unconstrained and constrained
optimization. The project has five parts: First, tensor methods will be
developed for constrained optimization and for large, sparse systems of
nonlinear equations. These methods show great promise of yielding general
purpose algorithms that are highly efficient on nonsingular and singular
problems. Second, trust region methods will be developed for nonlinearly
inequality and equality constrained optimization problems that have satisfactory
local and global convergence theory even in the presence of linearly dependent
constraint gradients, and perform efficiently and robustly in practice. Third, a
thorough analysis will be performed of several secant methods for nonlinearly
constrained optimization, with the goal of guaranteeing local and superlinear
convergence with an arbitrary positive definite initial Hessian approximation.
In particular, methods will be investigated that utilize the full Hessian of the
Lagrangian, including some new, promising augmented Lagrangian methods that will
also be investigated computationally. Fourth, algorithms will be developed to
solve the implicit nonlinear least squares problem, an optimization problem that
arises in curve fitting or in data fitting when there is no dependent variable.
This problem results in a nonlinear equality constrained optimization problem
which is expected to be solved by trust region methods. Fifth, some parallel and
sequential methods will be investigated for global optimization. These are
stochastic algorithms which adaptively partition the feasible region, and lead
to improvements in both parallel and sequential computation.