* 9530666
* Interactive Multimodal Interfaces:  Designing for Human Performance
* CSE,IIS
* 04/15/1996,06/30/2001
* Philip Cohen, Oregon Health & Science University
* Continuing Grant
* Ephraim Glinert
* 06/30/2001
* USD 480,950.00

*** 9530666 Oviatt A foundation is provided by this research for the development
of substantially more robust, flexible, accessible, and user-centered interfaces
for multimodal/multimedia systems that incorporate human language technology.
Specific objectives include: (1) modeling users' adapted language during error
resolution, and applying this information to the design of better error
avoidance and resolution techniques, (2) examining the impact of different types
and qualities of complex visual display on users' linguistic input to
interactive systems, and designing interfaces that effectively but transparently
guide users' input to match system processing capabilities, and (3) developing a
refined metric of cognitive workload that can be applied to the design of well-
integrated multimodal interfaces. To pursue these objectives, a rapid, semi-
automatic simulation technique is being used that supports the collection of
high-fidelity data during multimodal human-computer interaction. This research
will significantly advance the empirical, theoretical, and applied foundations
needed for the design of multimodal interfaces, and will be critical to
establishing usable systems that can succeed in actual field settings. In
particular, it can have a major impact on improving the commercial viability of
next-generation communications devices and mobile technology for a wide range of
applications. ***