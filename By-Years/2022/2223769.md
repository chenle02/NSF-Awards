* 2223769
* Collaborative Research: III: Small: Graph-Oriented Usable Interpretation
* CSE,IIS
* 10/01/2022,09/30/2025
* Jundong Li, University of Virginia Main Campus
* Standard Grant
* Sylvia Spengler
* 09/30/2025
* USD 280,000.00

Interpretation holds great promise in gaining the trust of end-users by
understanding how machine learning models work. In graph-based machine learning,
although various interpretation methods have been proposed, the potential of
interpretation has not been fully unleashed to make it a really useful tool. For
example, existing interpretation methods can identify the important graph
components (e.g., subgraph patterns and node features) given a model prediction,
but they are not well equipped to shed light on other critical model properties,
especially trustworthiness (e.g., fairness and robustness) that is crucial in
many real-world applications. In addition, although the interpretation of graph
models provides friendly visualization to humans for understanding, it remains
nascent how the interpretation will inform the design of better models. To
bridge the gap, this project takes a paradigm shift from traditional
interpretation methods development, aiming to improve the usability of
interpretation in graph learning system deployment, model training and data
preparation. The results of this project will boost the overall value of
interpretation in graph-based information systems. Furthermore, this research
will play an integral part in educating and training undergraduate and PhD
students. It will also be tightly integrated with multiple courses related to
data mining and machine learning.&lt;br/&gt;&lt;br/&gt;This project aims to
systematically explore usable interpretation in three different stages of a
graph learning pipeline in backward order, ranging from system diagnosis, model
improvement, back to data refinement. The project approaches interpretability
through a novel perspective, which goes beyond conventional paradigms of simply
understanding model predictions, towards explaining higher-level model
properties and exploring how models could actually benefit from interpretation.
First, it develops post-hoc interpretation tools to diagnose trustworthiness of
graph learning models in various aspects, including fairness, robustness, and
causality. Second, it develops interpretation-guided training algorithms and
textual generative modules to comprehensively improve graph learning models in
terms of effectiveness, robustness, and interactivity. Third, it utilizes
interpretation to refine graph data from two complementary directions, including
graph augmentation via a counterfactual Mixup strategy and graph compression via
data distillation, which provide the fundamental basis of effective and
efficient graph learning. The project will also result in the dissemination of
shared data and open-source software to broader data mining and graph machine
learning communities.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.