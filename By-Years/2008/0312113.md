* 0312113
* ITR:  Estimation, Approximation and Computation in Learning Theory
* CSE,CCF
* 09/01/2003,03/31/2004
* Yuesheng Xu, West Virginia University Research Corporation
* Standard Grant
* Sankar Basu
* 03/31/2004
* USD 225,000.00

ITR: Estimation, Approximation and Computation in Learning Theory&lt;br/&gt;
&lt;br/&gt;Learning theory, a rapidly growing area of multidisciplinary research
has recently attracted much attention from the mathematical community. There are
now numerous pressing issues coming from the statistical, engineering and
computer science communities resulting from their significant progress in
learning theory that provide a unique opportunity and vast need for
mathematicians to develop both theoretical concepts and computational tools to
assist in this area of research. We propose to study several fundamental
theoretical mathematical and computational problems crucial for the continued
rapid development of learning theory. They include a further study and
improvements of the F. Cucker and S. Smale theory of learning, the support
vector machine (SVM) of V. Vapnik, the regression theory of T. Poggio, the
deterministic approach of C. A. Micchelli for optimal estimation under
uncertainty and the relationship between these important ideas. Among other
things, we will be concerned with learning a function from other than function
values, learning vector valued functions, learning the optimal information for
learning a function and estimating the approximation error using notions of
nonlinear widths of function classes which is useful for obtaining deterministic
estimates that lead to statistical estimates for learning. We shall study
efficient numerical solutions of second kind integral equations in high
dimensions which come up in the study of the approximation error of Cucker and
Smale. We will also focus upon the minimal norm interpolation approach to
regression and SVM which is not emphasized much in the learning theory
literature and use duality theory as a bridge to compare all of them. We shall
also study the kernel density problem whose importance in learning theory has
been recently described by T. Poggio, investigate how to choose a kernel from
the data and consider probability density estimation problems which are useful
in pattern recognition and speech recognition. We are also interested in the
question of stability of learning algorithms and seek to construct kernels on
complex spaces suitable for applications.&lt;br/&gt;&lt;br/&gt;Our proposed
research addresses a multitude of practical problems arising from the handling
of massive amounts of data in high dimensional spaces. Therefore, in a time of
heightened concern for national security against terrorism, this research will
provide a new tool for dealing with the technological challenges that have
recently emerged and an opportunity for applied mathematicians to assist in
their solution. &lt;br/&gt; &lt;br/&gt;