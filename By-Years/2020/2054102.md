* 2054102
* EAGER: All-Optical Information Processing Device for Seeing Through Diffusers at the Speed of Light
* ENG,ECCS
* 11/15/2020,10/31/2021
* Aydogan Ozcan, University of California-Los Angeles
* Standard Grant
* Vikram Dalal
* 10/31/2021
* USD 150,000.00

Proposal Number: 2054102&lt;br/&gt;Principal Investigator: Aydogan Ozcan (PI)
and Mona Jarrahi (co-PI)&lt;br/&gt;Institution: University of California, Los
Angeles&lt;br/&gt;Title: EAGER: All-Optical Information Processing Device for
Seeing Through Diffusers at the Speed of Light&lt;br/&gt;Program Description:
EAGER: Electronics, Photonics, and Magnetic Devices&lt;br/&gt;&lt;br/&gt;Non-
Technical Abstract:&lt;br/&gt;&lt;br/&gt;Imaging through scattering and
diffusive media such as fog, clouds or human tissue has been an important
problem for many decades. Without an exception, all the previous methods are
based on, at their core, digital computers, such that the signals are first
detected by a device and then processed using digital computers to reconstruct
the diffuser-distorted images. There is an important and pressing need for a new
generation of optical devices that can see, detect and quantify target objects
through for example human tissues, walls, packages, clouds, fogs, etc., at the
speed of light and without using any power-hungry digital computation. This
unique capability, once fully demonstrated and developed, might open various new
applications in autonomous systems, biomedical imaging, astronomy, astrophysics,
atmospheric sciences, security, robotics, and many other
fields.&lt;br/&gt;&lt;br/&gt;Technical Abstract:&lt;br/&gt;&lt;br/&gt;In this
proposal, a computer-free, all-optical device that will see through unknown
diffusers at the speed of light, without the need for any digital computation
device will be developed. Unlike previous digital approaches that utilized
computers to reconstruct an image of the input object behind unknown diffusers,
a passive device will be created using a set of diffractive surfaces/layers to
all-optically reconstruct the image of an unknown object as the diffuser-
distorted input signals diffract through successive trained diffractive layers,
i.e., the image reconstruction will be processed at the speed of light through
this device. Each diffractive surface of a given device designed will have
thousands of diffractive features (termed as neurons), where the individual
phase values of these neurons will be adjusted in the training phase through
error back-propagation, by minimizing a customized loss function between the
ground truth image and the diffracted pattern at the output field-of-view. After
this deep learning-based design of these diffractive layers, the resulting
passive device will be fabricated to form a physical diffractive optical network
that is positioned between an unknown diffuser and the output/image plane. As
the input object light passes through an unknown diffuser, the scattered light
will be collected by the trained diffractive device to passively reconstruct the
distorted image. The success of this diffractive device will be demonstrated in
0.1-3 THz frequency band. Unlike other devices, the proposed diffractive image
reconstruction device operates at the speed of light and does not require any
power except for the illumination light. This all-optical image reconstruction
that will be achieved by passive diffractive layers will enable to see objects
through unknown diffusers and present an extremely low power device compared
with existing deep learning-based or iterative image reconstruction methods
implemented in computers.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.