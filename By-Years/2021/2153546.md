* 2153546
* CRII: III: Robust and Explainable AI Agents with Common Sense
* CSE,IIS
* 05/01/2022,04/30/2024
* Filip Ilievski, University of Southern California
* Standard Grant
* Sylvia Spengler
* 04/30/2024
* USD 175,000.00

This award is funded in whole or in part under the American Rescue Plan Act of
2021 (Public Law 117-2). &lt;br/&gt;&lt;br/&gt;This project will gain an
understanding of how to create Artificial Intelligence (AI) agents that provide
commonsense explanations about real-world narratives. Current AI agents lack
commonsense mechanisms to explain their judgment of everyday stories and they
cannot be applied to novel scenarios. This award will enable AI agents to reason
in novel situations and to explain their decisions. The project will focus on
two key aspects of stories: understanding situations and judging the adequacy of
actions in context. The project will test the ability of AI agents to complete
narratives and to provide commonsense explanations on the task of explainable
natural language inference. The explainability of AI agents can be expected to
improve public trust in AI technologies. Robust and explainable AI with common
sense is also critically missing in social AI assistants that aim to increase
the participation of children with Autism Spectrum Disorder and the elderly with
Alzheimer's dementia. The investigator will design a new set of lectures and a
full course on the topic of “AI assistants with common sense”, which will be
taught both at USC as well as internationally. Interdisciplinary research will
be facilitated via summer internships, and participation in the existing
University of Southern California (USC) Center for Knowledge-Powered
Interdisciplinary Data Science and NSF Research Experiences for Undergraduates
programs. The investigator will partner with USC's Center for Engineering
Diversity and Women in Science and Engineering, in order to recruit members of
historically underrepresented groups for research on this project. The
investigator will partner with USC's K-12 STEM Center to engage K-12 students
from historically underrepresented groups.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;This
award will create a paradigm shift in the development of AI agents, by combining
advances in neural language modeling with high-level explanations based on
logical axioms and commonsense knowledge. State-of-the-art technology is not
adequate for this goal: neural methods cannot infer causal links between events
and the motivations and goals of the agents directly from narratives, whereas
commonsense axioms and knowledge resources alone cannot handle the contextual
variations in human language. The team of researchers will build AI agents that
use common sense to explain their reasoning. To do so, the researchers will
leverage commonsense knowledge and axioms about agent psychology and event
causality in order to enrich story corpora. The enriched data will be used to
pre-train neuro-symbolic agents to complete open-world narratives and justify
their completion with commonsense explanations. The researchers will measure the
impact of representative techniques, axiomatic theories, and knowledge
dimensions on understanding narratives about situations and
actions.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.