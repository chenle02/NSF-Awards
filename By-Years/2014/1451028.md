* 1451028
* EAGER: Investigating the Neural Correlates of Musical Rhythms from Intracranial Recordings
* CSE,IIS
* 09/01/2014,08/31/2017
* Jerry Shih, Old Dominion University Research Foundation
* Standard Grant
* Ephraim Glinert
* 08/31/2017
* USD 149,940.00

The project will develop an offline and then a real-time brain computer
interface to detect rhythms that are imagined in people's heads, and translate
these rhythms into actual sound. The project builds upon research breakthroughs
in electrocorticographic (ECoG) recording technology to convert music that is
imagined into synthesized sound. The project researchers will recruit from a
specialized group of people for this project, specifically patients with
intractable epilepsy who are currently undergoing clinical evaluation of their
condition at the Mayo Clinic in Jacksonville, Florida, and are thus uniquely
prepared to use brain-computer interfaces based on ECoG recording techniques.
This is a highly multidisciplinary project that will make progress towards
developing a "brain music synthesizer" which could have a significant impact in
the neuroscience and musical domains, and lead to creative outlets and
alternative communication devices and thus life improvements for people with
severe disabilities.&lt;br/&gt;&lt;br/&gt;Most brain-computer interfaces (BCIs)
use surface-recorded electrophysiological measurements such as surface-recorded
electroencephalogram (EEG). However, while some useful signals can be extracted
from such surface techniques, it is nearly impossible to accurately decode from
such signals the intricate brain activity involved in activities such as
language with the detail needed to achieve a natural, transparent translation of
thought to device control. On the contrary, intracranial electrodes such as ECoG
are closer to the source of the desired brain activity, and can produce signals
that, compared to surface techniques, have superior spatial and spectral
characteristics and signal-to-noise ratios. Research has already shown that
intracranial signals can provide superior decoding capabilities for motor and
language signals, and for BCI control. Because complex language and auditory
signals (both perceived and imagined) have been decoded using intracranial
activity, it is conceivable to decode perceived and imagined musical content
from intracranial signals. This project will attempt to similarly use ECoG to
decode perceived and imagined musical content from intracranial signals as has
been done for language and auditory signals.