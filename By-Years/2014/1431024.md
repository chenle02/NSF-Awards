* 1431024
* SBIR Phase II: Emotionally Immersive Tele-Learning
* TIP,TI
* 08/15/2014,12/31/2017
* Ian Bennett, The Spirituality Network, Inc.
* Standard Grant
* Benaiah Schrag
* 12/31/2017
* USD 1,048,057.00

This SBIR Phase II project aims to incorporate novel machine vision and social
networking functionality into technologies used in online education and
webinars. Researchers have long identified engagement as the key ingredient for
success in any learning environment and particularly the online environment, but
current online teaching systems lack the means by which instructors can gauge
their students' level of engagement because these students are not visible.
Therefore in order to improve current online teaching modalities, it is
necessary to find ways to communicate to the instructor the level of engagement
of their unseen online students. The successful outcome of the project will
allow the lecturer to receive real-time feedback from facial expressions, gaze
and other body kinesics, which when averaged across the virtual classroom,
provides feedback related to the reception of information delivery. The project
supports NSF's mission in education, which seeks to answer questions about how
teachers can provide effective cognitive and motivational support for students.
This project aims to promote richer interactions between tutor and online
students through integrated cognitive and motivational scaffolding, leading to
higher levels of student success enabling them to compete more effectively as
skilled artisans in the 21st century workforce. This project contributes four
significant innovations: a machine-vision recognition system for gaze direction
and facial expressions of engagement, which aggregates data across participants
to improve signal to noise; a machine-vision recognition system for detecting
hand gestures and postural kinesics; enabling third party pedagogical
applications within a framework using ancillary hardware, and which can be sold
through an educational application store; and to integrate social network
functionality that replicates pre- and post-lecture socialization including pair
sharing, breakout groups, team teaching, and support for online teaching
assistance. The goals and scope of research required to support the above
innovations include: improving machine-vision classifier data and functionality;
optimization of user interface and integrated user calibration process;
extending the system's functionality to both synchronous and asynchronous
modalities; developing neuro-psychological and cognitive models of the online
pedagogical process; design and integration of content/media interoperability
and social networking capabilities; creation of open application programming
interfaces for third-party developers and application store functionality with
digital whiteboards and tablets; development of ancillary software modules to
help students manage data related to their educational efforts, diagnose study
and achievement patterns, and provide expert advice based on that data.