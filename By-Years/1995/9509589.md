* 9509589
* A Study of Long-Term Architectural Limits to Computing:     Galileo
* CSE,CCF
* 09/01/1995,08/31/1998
* James Goodman, University of Wisconsin-Madison
* Continuing Grant
* Anand R. Tripathi
* 08/31/1998
* USD 265,861.00

Galileo is an investigation into the implications of long range technology
advances across the computer field. While projections of narrow scope are
difficult and risky because of the rapid progress over a very broad range of
technology, it is possible to extrapolate current trends and make intelligent
guesses about future computer building blocks. Extrapolating current rates of
progress to as little as a decade hence suggesting that incredibly powerful
computer systems might not be only possible, but even affordable. Current
technology trends will undoubtedly be affected by new discoveries and by
limitations long before such performance levels are reached. It is the goal of
this research to identify those development directions that are likely to come
into conflict or otherwise be retarded, and to investigate the implications of
these effects. Future machines will undoubtedly much lower costs of all
operations, but some operations will become much cheaper than others. A major
goal is to identify the relative improvements on different kinds of operations,
and to understand how these changes will affect architecture, the programming
environment, and the algorithms used. The processor has long been the heart of a
computer system, and though much has been written about other limitations, the
CPU still plays a central role in today's architectures. Increasingly the
processor is becoming less effective, limited not by its peak processing power,
but by the ability of the system to provide work to keep it busy. While
processing power is rapidly becoming cheaper, the effective use of memory and
communication is becoming the critical challenge in achieving higher
performance. Memory costs have declined rapidly and steadily for more than
twenty years, and will continue to decline in cost per bit. Access time has not
improved dramatically, however, and high-bandwidth, low latency-memory will
always be relatively expensive. Limitations in memory access tile and bandwidth
are already posing difficult design challenges, and this will only be aggravated
by technology trends. This research is investigating how a system can get higher
performance form its memory system by applying cheap processing power wherever
it can be used effectively. In some sense, the system becomes a collection of
memory modules with processing power distributed in ways to maximize the
effective use of memory by minimizing communications between memory modules.
Memory access time and memory latency are intimately related. Both are critical
for a high-performance system, and either can be optimized at the expense of the
other. Today memory latency seems to be the more urgent problem, and much
current research is devoted to reducing or tolerating memory latency. Assuming
that some of these techniques are successful, the more fundamental problem of
memory bandwidth emerges. While it may be possible to build systems of
arbitrarily high bandwidth, it appears that one of the most important emerging
challenges is to make the most effective use of whatever bandwidth is available
between modules. By today's standards, future systems will have enormous
processing power, huge amounts of memory, and incredible communications
bandwidth. Computer systems will be limited by memory modules of insufficient
capacity and communication paths of limited bandwidth, with processor
distributed generously wherever needed to optimize the effectiveness of memory
and communication bandwidth. Galileo is investigating how the architecture of
such systems should differ from systems of today. Galileo is investigating how
the architecture of such systems should differ from systems of today, and how
such systems should be programmed.