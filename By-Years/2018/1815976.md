* 1815976
* CHS: Small: Enhancing Educational Virtual Reality with Headset-based Eye Tracking
* CSE,IIS
* 08/01/2018,07/31/2023
* Christoph Borst, University of Louisiana at Lafayette
* Standard Grant
* Dan Cosley
* 07/31/2023
* USD 531,813.00

Virtual reality (VR) can bring lab or field-trip-like experiences to students
who are unable to visit physical sites because of location, budget, or schedule.
Potential advantages of these experiences over traditional teaching tools
include increased student engagement and motivation, more direct viewing of size
and spatial relationships of modeled objects, and stronger memories of the
content. Emerging consumer VR devices are starting to provide sufficient quality
and affordability for home and school use, and this will eventually make
educational VR experiences broadly available. Future consumer VR headsets are
expected to include increased sensing, such as eye tracking cameras to determine
where users are looking and strain gauges to detect facial expressions. The
sensor data can be analyzed for insight into users' attention and emotional
affect. The project will investigate how such insight into student attention can
be used to improve educational VR through the design of personalized educational
environments that respond to individual students' attention. The project will
also develop techniques for using sensor data to give teachers enhanced real-
time insight into student activities and behavior patterns to help them provide
better teacher-guided VR experiences. This will involve development of new
approaches for educational VR technology and experiments that generate
fundamental knowledge and guidelines for applying such approaches. In addition
to the potential long-term benefit of improving education, the project will
provide a number of more immediate, direct educational benefits. The team will
incorporate the work into courses and undergraduate research experiences on
human-computer interaction and VR, as well as outreach activities and summer
programs aimed at high school students across Louisiana.
&lt;br/&gt;&lt;br/&gt;The team will design and assess methods including the
following: 1) educational content that responds to student eye gaze for more
responsive and engaging presentation; 2) visual effects or indicators, based on
detected eye behaviors, to encourage student attention to particular content in
a VR environment; and 3) visualizations of student eye gaze that use both raw
and processed gaze data to help teachers understand and guide students. To
understand the tradeoffs between approaches and to develop guidelines for wider
development and use of these techniques, effects will be studied in terms of
behavior, subjective experience, and learning. The most promising methods will
be applied to a case study of a networked VR interface that allows teachers to
monitor and guide students through an immersive educational VR environment. To
do this, the team will build on their existing educational VR framework that has
previously been deployed at regional high schools and to thousands of students
at outreach events. The project is expected to improve the effectiveness of such
VR systems and of teachers' ability to supervise and assist students. Resulting
methods and principles will provide a foundation for headset-based eye tracking
in educational VR and in other related applications such as simulation-based
training and accessibility.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.