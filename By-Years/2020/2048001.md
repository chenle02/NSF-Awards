* 2048001
* RI: CAREER : Understanding Opinions by Reasoning over Socially Grounded Language
* CSE,IIS
* 04/01/2021,03/31/2026
* Dan Goldwasser, Purdue University
* Continuing Grant
* Tatiana Korelsky
* 03/31/2026
* USD 316,693.00

Social media platforms have recently emerged as the primary space for public
conversations, providing a venue for people to share perspectives and for
policymakers to promote their decisions and inform the public about them. The
massive amount of available opinion data presents tantalizing opportunities to
study the perspectives expressed on these platforms. Insights derived from this
analysis can help gauge public opinion, inform public policy, and help support
human decision making. Realizing these opportunities requires models adapted to
the new social media settings, in which linguistic content and its social
context cannot be separated. This CAREER project develops novel modeling
techniques and learning algorithms for combining these two aspects under a
common innovative principle -- creating a socially grounded language
representation that views opinion understanding as part of a larger framework of
understanding real-world scenarios (such as the implementation of specific
policies or the response to an emergency situation) and their participants. This
research helps provide the relevant context needed for better understanding
social media content and result in highly nuanced analysis, capturing the
stances, attitudes and relationships between the different stakeholders of a
given real-world scenario.&lt;br/&gt;&lt;br/&gt;This project suggests a new way
to conceptualize opinionated text analysis, as part of a real-world scenario,
reflecting the attitudes-of and relationships-between stakeholders in the
scenario from which the text emerges. A major design goal is to avoid the
supervision bottleneck, and allow the system to easily adapt to new events and
policy issues by using the social information associated with users as a form of
indirect supervision over documents they author. This is done by representing
documents, authors, referenced entities, their connections and behaviors in a
shared neuro-symbolic framework enabling symbolic inference over latent entity
representations learned from data. The project addresses three main challenges:
(1) constructing a representation language for characterizing opinions, their
targets and motivation, and the stances they express, (2) grounding opinion text
in real world scenarios by infusing relevant real-world information into a
neural language model, and (3) exploiting social information by formulating a
unified view of social, behavioral, and textual information. These research
efforts help provide nuanced insights from social media content that lacks
specificity on its own, while building the computational foundations for jointly
processing textual and social information.&lt;br/&gt;&lt;br/&gt;This award
reflects NSF's statutory mission and has been deemed worthy of support through
evaluation using the Foundation's intellectual merit and broader impacts review
criteria.