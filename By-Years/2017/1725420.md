* 1725420
* SPX: Scalable In-Memory Processing Using Spintronics
* CSE,CCF
* 08/15/2017,07/31/2021
* Ulya Karpuzcu, University of Minnesota-Twin Cities
* Standard Grant
* Yuanyuan Yang
* 07/31/2021
* USD 800,000.00

The computational demands of modern workloads are influenced by a data-centric
view of computing. The traditional model of computing, which brought the data
into the compute engine for processing, is falling apart in the era of exploding
data volumes as the overheads of data transportation become forbidding. Instead,
it is more advantageous to take computing to the data. The objective of this
project is to explore the alternative paradigm of bringing computation to the
data by developing a novel scalable framework for processing-in-memory (PIM).
While traditional CMOS structures are unsuited to this tight integration,
emerging spintronic technologies show remarkable versatility in this regard. The
proposed approach will develop the notion of the computational RAM (CRAM) to
build PIM solutions to solve data-intensive computing problems using spintronics
technologies. The project seeks to provide a complete solution across the system
stack to the PIM problem under the CRAM platform.Â The project seeks to advance
the state of the art in electronics technology, and potentially has a large
impact in a pervasively-electronic society. Technically, its research results
are projected to significantly advance the state of the art in large scale
memory-centric computing using post-CMOS spintronic technologies, paving the way
for new ways to build energy-efficient, scalable integrated systems. A multi-
pronged outreach strategy will be pursued to take the results of this effort to
a set of core constituencies. Human resource development will be achieved by
training of undergraduate and graduate students in post-CMOS methods and novel
computing paradigms.&lt;br/&gt;&lt;br/&gt;The notion of bringing computation
nearer to memory has gained wide currency in the recent past. However, since the
regularity of large memory arrays is considered sacrosanct, the most viable
solutions proposed so far perform processing near-memory, performing computation
at the edge of a large memory array. The proposed CRAM-based approach avoids the
substantial overheads of such a method, in bringing data to and from the
periphery, and proposes a method for reconfiguring the memory to write the
output of a logic operation directly into a memory cell. This project realizes
the potential of the CRAM across the system stack by exploring the optimum over
a space of choices in technology, logic design, and memory architecture to
implement a diverse set of basic computational building blocks; by
quantitatively characterizing CRAM-specific multi-granular parallelism; by
investigating implications for the eco-system integration; by devising effective
methods for CRAM-specific spatio-temporal parallel task scheduling; and by
demonstrating how bioinformatics applications and applications featuring
irregular, i.e., amorphous parallelism can benefit from CRAM.