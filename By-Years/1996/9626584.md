* 9626584
* Understanding and Scaling-Up Machine Learning Algorithms
* CSE,IIS
* 07/15/1996,03/31/2001
* Thomas Dietterich, Oregon State University
* Continuing Grant
* Ephraim Glinert
* 03/31/2001
* USD 358,240.00

Dietterich Understanding and Scaling-Up Machine Learning Algorithms Several
machine learning algorithms have become very popular and widely used --
particularly the top-down partitioning algorithms for decision trees and the
backpropagation algorithm for feed-forward neural networks. This research seeks
to deepen our understanding of these algorithms, to explain why various boosting
and voting techniques improve their accuracy, and to determine the best
procedures for applying them in practice. A second goal of the research is to
find ways of scaling up these algorithms (and their associated boosting
techniques) to handle problems with billions of training examples and thousands
of output classes. Based on our experience with voting algorithms, we will
develop methods for reducing the cost of voting, scaling up the number of output
classes, handling continuous output values, and handling large numbers of
training examples. Existing learning algorithms have been designed for
conditions where data is very expensive and computer time is relatively cheap.
Emerging applications in data mining exhibit the opposite conditions: data is
voluminous and users want interactive speeds. This research will result in new
algorithms that are essential to supporting emerging applications in large-scale
data mining.