* 2213939
* PFI-TT: Virtual Reality Training for Active Pharmaceutical Ingredient Manufacturing Operations
* TIP,TI
* 07/15/2022,06/30/2024
* Magesh Chandramouli, Purdue University
* Standard Grant
* Jesus Soriano Molla
* 06/30/2024
* USD 247,979.00

The broader impact/commercial potential of this Partnerships for Innovation -
Technology Translation (PFI-TT) project, if successful, is to address the
shortage of skilled workforce in specialized areas of the pharmaceutical
manufacturing industry, such as production of active pharmaceutical ingredients
(API). The proposed technology consists of a user-friendly Virtual Reality and
Augmented Reality (VR/AR) training framework for API manufacturing processes.
Current training methods, including in-class and computer-based learning, do not
adequately address the critical skills that manufacturing operators need,
resulting in difficulties in operating and maintaining key process equipment.
Consequently, schedule disruptions and batch failures occur and cause
significant losses of time and money. The proposed VR/AR-based training is
expected to remedy the inadequacies of pharmaceutical training processes that
cause continued operator errors and delay drug availability as witnessed during
the COVID-19 pandemic. The proposed virtual simulation offers coordinated visual
spatial perception feedback cues to develop motor skills for procedural
knowledge and memory. The interactive training actively engages trainees to
explore the connections between actions and outcomes, build schemas, and develop
detailed, accurate mental models of API manufacturing operations. Optimal
training may provide affordable, precise, and quality drug delivery for generic
and personalized medicines to needy patients.&lt;br/&gt;&lt;br/&gt;The proposed
project will develop an interactive, photorealistic VR/AR framework for training
technicians in Active Pharmaceutical Ingredient (API) operations. Current
virtual modules are not scalable across multiple devices and are not built with
the end user customization in mind. This project advances multimodal (augmented
reality, mixed reality, and desktop VR) support, accommodating access via head
mounted displays, hand-held tablet devices, and/or desktop computers to
accommodate diverse learning styles. The project goals are to: 1) identify
VR/AR-specific visual, auditory, and haptic cues to enhance transfer of training
and retention in API operations, 2) judicious use of these features to design
and implement virtual training for multimodal access. The photorealistic modules
will include highly-detailed API operations, component assembly/dismantling
procedures, and alternative scenario visualization/simulation through
interactive parameter modification. Customizable interface functionalities allow
users to enable or disable guidance/query features, captions, and audio.
Following proper VR training, participant performance will be observed to
incorporate iterative enhancements. The intellectual merit involves the novel
design of customizable VR/AR interfaces reducing cognitive load and optimizing
integration of visual, auditory, and haptic stimuli for training-transfer and
retention. The metrics for success will focus on accuracy, schedule
optimization, and safety in order to demonstrate the efficiency of VR in
pharmaceutical training.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.