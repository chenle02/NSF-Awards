* 1728173
* Doctoral Dissertation Research:  Why adapt? Phonotactic learning as non-native language adaptation
* SBE,BCS
* 08/01/2017,07/31/2019
* Matthew Goldrick, Northwestern University
* Standard Grant
* Joan Maling
* 07/31/2019
* USD 10,112.00

In order to successfully communicate, listeners must continuously adapt to
systematic differences between speakers (e.g., changing expectations about what
you will hear based on a speaker's dialect). At the same time, listeners need to
ignore incidental variation (e.g., if a speaker happens to be talking with their
mouth full, you should not change how you expect they will speak after they have
finished eating; Kraljic, Brennan, &amp; Samuel, 2008). In this study, a series
of experiments examine the limits of adaptation to novel phonotactics, or
constraints on syllable structure (e.g. in English, but not Spanish, the
sequence /sk/ can begin syllables, such as in the word school). This project
tests the hypothesis that speakers use their past experience of phonotactic
variation to distinguish systematic from incidental variation. Speakers
naturally encounter variation in phonotactics between talkers of different
languages, but do not encounter such variation between talkers of the same
language; this predicts that speakers will only adapt to talker-specific
syllable structures when exposed to talkers who differ in their language
backgrounds (e.g., a native French talker and a native English talker).
&lt;br/&gt;&lt;br/&gt;This hypothesis is explored in three experiments. In study
1, listeners are exposed to two talkers, each with a different phonotactic
constraint, in a perception experiment. Adaptation to talker-specific
constraints is predicted only when talkers differ in language background. Study
2 explores the role of talker language background on adaptation to phonotactics
in speech production, using a tongue twister paradigm. Study 3 investigates the
structure and granularity of listeners' prior knowledge. Can listeners hold
models of only a native vs. non-native language, or can they maintain models for
two separate non-native languages?