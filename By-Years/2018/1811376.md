* 1811376
* A Non-Asymptotic Theory of Robustness
* MPS,DMS
* 07/01/2018,06/30/2022
* Wenxin Zhou, University of California-San Diego
* Continuing Grant
* Yong Zeng
* 06/30/2022
* USD 120,000.00

Modern data acquisitions have facilitated the collection of large-scale data
with complex structures, and meanwhile, have introduced a series of new
challenges to data analysis both statistically and computationally. The heavy-
tailed character of the distribution of empirical data has been repeatedly
observed in many fields of research, including microarray studies in genomics,
neuroimaging in medicine, and portfolio optimization and risk management in
finance. In functional MRI studies, the parametric statistical methods often
fail to produce valid cluster-wise inference, where the principal cause is that
the spatial autocorrelation functions do not follow the assumed Gaussian shape;
in finance, the power-law nature of the distribution of returns has been
validated as a stylized fact over the years. The least squares method, albeit
being most commonly used in practice due to its simplicity as a once-for-all
solution, is sensitive to the tails of sample distributions and is proven to be
suboptimal for heavy-tailed data from a non-asymptotic viewpoint. In this
project, the PI will develop robust statistical procedures for various problems,
ranging from mean estimation, linear regression, high-dimensional sparse
regression to large covariance matrix estimation. The main goals of this
research are to understand the finite-sample properties of robust learning, and
to develop computationally efficient procedures that advance the practical use
of robust methods.&lt;br/&gt;&lt;br/&gt;In this project, the PI will study
robust alternatives to the method of least squares for two fundamental problems:
linear regression and covariance estimation. To achieve robustness against
asymmetric and heavy-tailed data, the main idea is to use the adaptive Huber
loss and its extension on the matrix space. From a non-asymptotic viewpoint, the
accompanying scale parameter should adapt to the sample size, dimension and
noise level for optimal tradeoff between the gain in stability and cost in bias.
The work on the project aims to (i) develop new methods for robust estimation
and inference under linear models, and investigate their mathematical
underpinnings using techniques from concentration inequality in probability,
finite-sample theory for M-estimation in statistics and convex analysis in
optimization, and (ii) construct both general and structured large covariance
matrix estimators under minimal assumptions on the data. The originality of the
project resides in providing new perspectives on robustness, which not only
represent useful complements to classical robust statistics but also make
important contributions to modern statistical analysis, including high
dimensional estimation and large-scale inference. The philosophy of the project
echos John Tukey's principles for statistical practice by highlighting the
importance of having methods of statistical analysis that are robust to
violations of the assumptions underlying their use and allowing the possibility
of data's influencing the choice of method by which they are
analyzed.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.