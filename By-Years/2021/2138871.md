* 2138871
* ERI: Distributed Learning in Regulation of UAV Communication Networks with Dynamic UAV Lineup
* ENG,ECCS
* 07/01/2022,06/30/2024
* Ran Zhang, Miami University
* Standard Grant
* Anthony Kuh
* 06/30/2024
* USD 192,785.00

This award is funded in whole or in part under the American Rescue Plan Act of
2021 (Public Law 117-2).&lt;br/&gt;&lt;br/&gt;Unmanned aerial vehicles, or
drones, have been demonstrating impressive potentials in next generation
wireless communications. Compared to the terrestrial cellular base stations,
drones equipped with wireless transceivers can serve as mobile base stations,
and stand out in providing highly on-demand services with flexible 3D mobility,
better wireless connectivity with higher chance of Line-of-Sight links, and much
lower deployment cost with almost infrastructure-free network construction.
Promising as it is, drone based communication networks still face fundamental
regulation challenges: i) as drones are highly mobile, the dynamically changing
network topology may make it unpractical for a centralized control unit to
collect complete network information and make collective decisions; ii) the
environment in which drones operate may be dynamically changing or unexplored
without a priori knowledge of the environment modeling, making the conventional
optimization or rule-based methods hardly applicable; iii) the research is still
embryonic on how to optimally regulate the drone network when the lineup of the
serving drones dynamically change, which, however, will be a common event in
realistic implementation. To this end, this proposal is aimed to crack the nut
of the above identified issues, and develop an effective framework for
distributed network regulation solutions that are environment-model-free and
well adaptive to the dynamic drone lineup. The research outcomes are expected to
provide valuable inspirations and benchmarking to the distributed, scalable, and
artificial-intelligence powered management of aerial access communication
networks under a dynamic network setup. Such networks will be embraced as a key
component in the larger-scope Space-Air-Ground Integrated Networks for the
beyond-5G mobile telecommunications. The success of the project will potentially
contribute to the leadership and competence of the United States worldwide in
future generation mobile telecommunications as well as elevating national
communication welfare with more integrated and on-demand communication
infrastructure.&lt;br/&gt;&lt;br/&gt;In this project, multi-agent reinforcement
learning will be applied to establish a distributed and model-free network
regulation framework. The framework will feature strong capability in making
sequential decisions in complex time-varying environments. Under the developed
framework, the project aims to investigate how the drone communication networks
should responsively handle and further proactively control the dynamic change of
the drone lineup in a distributed yet coordinated manner. Specifically,
responsive strategies will be first designed for a general drone communication
network. The strategies will jointly optimize the radio resource management and
trajectory design for the drones when the drone lineup change dynamically. The
learning algorithm design will be investigated with different levels of inter-
drone information exchange. The learning exploration will be promoted by
adopting the structure of asynchronous parallel computing. The network will be
prototyped leveraging on programmable drone products and simple-yet-effective
communication protocols. To move one step further, proactive control strategies
will be derived for the solar-powered self-sustainable drone communication
network, which proactively control the quit and join-in of the drones by pre-
shaping their solar-charging plan. The strategies will consider dynamic user
spatial and traffic distributions by combining Fourier analysis, Long-Short Term
Memory and Gaussian process regression for distribution prediction, and enabling
predicting while learning to significantly reduce the reinforcement learning
complexity. The hybrid cooperative-compete relationship among individual drones
will be handled by exploiting Nash Q learning and correlated Q learning. The
anxiety on the high-dimension state-action space in learning will be relieved by
adopting problem decomposition techniques. The proposed project will advance the
research on autonomous regulation of drone communication networks by filling the
gaps of missing control strategy design to responsively handle and proactively
control the drone lineup change. In addition, the introduction of game theory
into the distributed framework makes the research more realistic with
diversified autonomy in individual drones. The prototyping plan will complement
the simulation evaluation on the time complexity and communication
overhead/latency in the real-world implementation.&lt;br/&gt;&lt;br/&gt;This
award reflects NSF's statutory mission and has been deemed worthy of support
through evaluation using the Foundation's intellectual merit and broader impacts
review criteria.