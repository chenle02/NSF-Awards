* 1524888
* CHS: Small: Using Virtual Reality for the Dynamic, Real-Time Optimization of Human Visual Perception
* CSE,IIS
* 12/01/2015,07/31/2019
* Edward Essock, Rutgers University Newark
* Standard Grant
* Ephraim Glinert
* 07/31/2019
* USD 599,297.00

Computational vision and vision science have traditionally looked to the
statistics of the natural world and each other for insights into visual
processing. Until recently, these approaches have been primarily static and
correlational: the natural world has been treated as a collection of images for
which processing should be optimized, and the averaged regularities in natural
scenes have been shown to be correlated with perceptual biases. Any dynamic
adjustment to recent experience influencing perception has often been minimized,
in large part because there have not been ways to disrupt the environment and
test the effects. But recent advances in computing and virtual reality hardware
have made possible the manipulation of visual input in near-real
time.&lt;br/&gt;&lt;br/&gt;This research combines mobile computing technology
with immersive augmented reality to explore how visual perception dynamically
adapts to encountered regularities in the environment. The PI will investigate
perception of orientation, a feature of the first cortical layer of human visual
processing, and thus a logical starting point. If stimuli are encoded under a
framework that uses recent environmental statistics to dynamically optimize
perception, then altering the typical environmental regularities should have
predictable effects on human visual performance. The PI argues that existing
computational models of human perception can be extended to predict which
changes in the input will improve (or inhibit) human perceptual performance.
This, in turn, will open up the possibility of training human perception to
optimize performance on real world tasks that previously required extensive
specialized training or costly, custom-built software. With the goal of creating
a more precise model of the flexibility of the human visual system by
quantifying the extent to which encoding biases can be altered or obliterated,
this project will include three interrelated thrusts. First, the PI will develop
a suite of software tools to process the visual environment in near real-time,
and will use these tools to systematically investigate changes in human
perception in response to experience with environments whose statistical content
is atypical. He will measure changes in human perceptual performance on a
variety of real-world tasks (e.g., object detection), in response to immersive
experience with atypical environmental input. And he will develop and test a
computational model of this human perceptual learning. Preliminary research
suggests that the combination of computer image-filtering and virtual reality
hardware can be used to change subsequent visual processing in ways that are
predictable based on the filtered input.