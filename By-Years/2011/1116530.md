* 1116530
* RI: Small: Robust Auditory Object Recognition with Spike Sequence Coding and the State-Dependent Dynamics of Cortical Networks
* CSE,IIS
* 09/01/2011,12/31/2014
* Dezhe Jin, Pennsylvania State Univ University Park
* Standard Grant
* Kenneth Whang
* 12/31/2014
* USD 296,470.00

Recognizing speech or other auditory objects in adverse environments -- e.g.
with noise, reverberation, and multiple speakers -- is essential for human and
animal communication. Current speech recognition technologies work well in high
signal-to-noise conditions, but perform orders of magnitude below human
performance in adverse conditions. Converging evidence from neuroscience
suggests that auditory information is encoded in sparse and precisely timed
spikes of sub-cortical neurons. However, the extent to which codes based on
spike timing might underlie the robustness of human auditory object recognition
has not yet been fully investigated. This project bridges this gap by devising a
biologically inspired computational model of auditory processing at the cortical
level and extracting computational principles that are essential for the model
to achieve robust auditory object recognition.&lt;br/&gt;&lt;br/&gt;The approach
is to transform sounds into the spike sequences generated by feature-detecting
thalamic auditory neurons, and to integrate these spikes spatially and
temporally using the state-dependent dynamics of cortical neurons with active
dendrites. In the proposed model, an auditory object first evokes sequential
spiking of thalamic neurons that have been trained to detect useful features.
Then, through feed-forward excitation and inhibition from the thalamus, and
lateral excitation and inhibition from the cortical neurons, the state of the
cortical network evolves, leading to temporal integration. Recognition of the
auditory object is signaled when the cortical neurons reach a specific network
state. The computational model is constrained by experimental results on the
properties of cortical neurons, the organization principles of cortical
networks, and the activity-dependent plasticity rules of the network structures.
The project aims both to design feature detectors that can robustly represent
auditory objects with spatiotemporal spike sequences, and to build a cortical
network model that can recognize specific auditory objects using state
transitions driven by the thalamic inputs, with neuron dynamics that can be
compared with those observed in the auditory cortex. The recognition performance
of the computational model will be evaluated and improved with auditory tasks
designed to compare different approaches to speech recognition.