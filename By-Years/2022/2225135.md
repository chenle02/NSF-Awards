* 2225135
* RUI: Improving motor learning and rehabilitation via experimental bidirectional dynamic human-virtual reality interaction system
* ENG,CMMI
* 09/01/2022,08/31/2025
* Stefanie Drew, The University Corporation, Northridge
* Standard Grant
* Alex Leonessa
* 08/31/2025
* USD 788,138.00

This grant supports research that generates new knowledge of how humans and
virtual reality systems interact to help learn motor skills for physical
rehabilitation. When humans put on a virtual reality headset, they are
transported into an immersive digital world that can be anything or anywhere.
Recent advancements of virtual reality systems make it so that these digital
worlds closely mimic the real-world -- opening up many possibilities to train
rehabilitative skills. However, in order for this potential to be fully
realized, a better understanding of the components of immersive virtual
environments that translate to real-world motor skill development is needed.
Correspondingly, this award supports the fundamental research of human movements
and experiences linked to learning in virtual reality environments that best fit
their learning needs. Findings from the current study will benefit the U.S.
economy and society as many schools and workplaces are using virtual reality
systems to provide people with scalable training of complex motor skills. To
properly examine the complexities of motor learning in virtual worlds, this
project involves researchers from several disciplines including mechanical
engineering, kinesiology, psychology, and vision science. Moreover, the multi-
disciplinary approach of this project helps broaden participation of
underrepresented groups, along with aids to bridge gaps between engineering and
social science research fields. &lt;br/&gt;&lt;br/&gt;The multidisciplinary
research team in this project will develop two dynamic human-virtual reality
interaction systems—one involving walking through a virtual world while avoiding
obstacles, and the other controlling a prosthetic arm and hand with a foot
controller. Each system includes a virtual reality headset with strategically
designed adaptive environments that scale to the skill level of the user, and
other subsystems to record vital user data such as gait, eye gaze behaviors, and
toe tapping events (while controlling the prosthesis). The developed systems
rely on various sensors, such as eye trackers, 3D motion capture systems, foot
controller insoles, that can fully capture the biomechanics of the users and
their strategies in performing the assigned tasks. Analyzing the collected data
will lead to clearer understanding of the bidirectional relationships between
humans and the virtual reality systems during motor learning or rehabilitation
tasks—humans enhancing their skills, and the VR system adapting to the user
needs. This research will fill a knowledge gap in the human-virtual reality
interaction research by demonstrating the potential of virtual reality to
improve learning and rehabilitation through the designed
systems.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.