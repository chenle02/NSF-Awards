* 1447549
* BIGDATA: F: DKM: DKA: Big Data Modeling and Analysis with Depth and Scale
* CSE,IIS
* 08/01/2014,07/31/2020
* Scott Smolka, SUNY at Stony Brook
* Standard Grant
* Sylvia Spengler
* 07/31/2020
* USD 1,500,000.00

An important step in understanding large volumes of data is the construction of
a model: a succinct but abstract representation of the phenomenon that produced
the data. In order to understand a phenomenon, a data analyst needs to be able
to propose a model, evaluate how the proposed model explains the data, and
refine the model as new data becomes available. Statistical models, which
specify relationships among random variables, have traditionally been used to
understand large volumes of noisy data. Logical models have been used widely in
databases and knowledge bases for organizing and reasoning with large and
complex data sets. This project is aimed at developing a programming language
and system for the creation, evaluation and refinement of combined statistical
and logical models for the express purpose of understanding very large and
complex data sets. Apart from its direct effect on model development for Big
Data problems, the semantic foundations and scalable computing infrastructure
resulting from this project is expected to directly impact the areas of system
development and verification, planning, and optimization, with broad application
in Science and Engineering. The tools developed in this project will facilitate
the training of a new generation of scientists capable of transforming data into
knowledge for use across disciplines. The project's education and outreach
component is designed to train select undergraduate students on Big Data
modeling and analysis via annual workshops and research mentorship; and graduate
students via curriculum modifications including a specialization in Data
Science.&lt;br/&gt;&lt;br/&gt;The project will develop Px, a language with well-
defined declarative semantics, to support high-level model construction and
analysis. Px will be capable of expressing generative and discriminative
probabilistic and relational models, and the Px system will support complex
queries over such models. The project will encompass three significant and
complementary research directions, aimed at developing: (1) semantic
foundations, including language constructs needed for succinct specification of
complex models with rich logical and statistical structure; (2) scalable
inference techniques combining exact and approximate methods, and query
optimizations over combined logic/statistical models; and (3) programming
extensions as well as static and dynamic analyses to support the creation and
refinement of complex models. The Px language and system will be evaluated using
two important and diverse application problems: (1) analysis and verification of
infinite-state probabilistic systems, including parameterized systems, and (2)
construction of phylogenetic trees from phenomic data, used in the Tree of Life
project, for mapping the evolutionary history of organisms. The project is
expected to make significant contributions towards creating a unifying framework
combining probabilistic inference, logical inference, and constraint processing,
with an emphasis on semantic clarity, efficiency, and scalability. The project
will also demonstrate the practical utility of the proposed integrated framework
by developing complex models from big data that take advantage of this
technology in fundamental ways.