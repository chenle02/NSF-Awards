* 1117062
* SHF: Small: Parallel Unified Linear algebra with Systolic ARrays (PULSAR)
* CSE,CCF
* 08/01/2011,07/31/2014
* Jakub Kurzak, University of Tennessee Knoxville
* Standard Grant
* Almadena Chtchelkanova
* 07/31/2014
* USD 499,996.00

More than seven years after traditional processor designs hit the edge of their
power envelope, the path of extreme scale Computational Science to a 100
petaflop (Pflop/s) system, which researchers had hoped to be using by the middle
of the coming decade, has never looked steeper. On current high performance
computing (HPC) systems, the 'application-architecture performance gap,' i.e.
the gap between theoretical peak performance and the performance realized by
full applications is already substantial. But with clock frequencies now capped
below 4 GHz and trending downward, latencies in key areas (e.g. memory access,
bus, system interconnect) expected to remain relatively stagnant, and software
parallelism required to increase by at least three orders of magnitude to make
effective use of the tens of thousands of processors and millions of cores that
100 Pflop/s systems are projected to contain, it is now reasonable to worry that
a widening application-architecture performance gap will make such systems
unproductive to use and therefore irrational to build. &lt;br/&gt;&lt;br/&gt;The
proposed research aims to provide the kind of coordinated math and computer
science research effort needed to solve the interrelated cluster of software
problems that threaten to cripple application performance on future large-scale
systems. Under the PULSAR project, the PIs use a variety of both classic and
novel dense linear algebra algorithms to explore the potential of well known,
but now little used systolic array design principles to exploit all the power
that future multi-core and heterogeneous systems, built to extreme scales. If a
software platform that virtualizes classic systolic array architecture, allowing
for suitable flexibility in the granularity of its application can be created,
then libraries and applications that use this data-driven execution model to
achieve outstanding performance and scalability on future massively parallel and
data-starved HPC systems can be produced.