* 2004364
* Collaborative Research : Elements : Extending the physics reach of LHCb by developing and deploying algorithms for a fully GPU-based  first trigger stage
* CSE,OAC
* 07/01/2020,06/30/2024
* Michael Sokoloff, University of Cincinnati Main Campus
* Standard Grant
* Rob Beverly
* 06/30/2024
* USD 289,603.00

The development of the Standard Model (SM) of particle physics is a major
intellectual achievement. The validity of this model was further confirmed by
the discovery of the Higgs boson at the Large Hadron Collider (LHC) at CERN.
However, the Standard Model leaves open many questions, including why matter
dominates over anti-matter in the Universe and the properties of dark matter.
Most explanations require new phenomena, which we call Beyond the Standard Model
Physics (BSM), and which the LHCb experiment at CERN has been designed to
explore. The LHC is the premier High Energy Physics particle accelerator in the
world and is currently operating at the CERN laboratory near Geneva Switzerland,
one of the foremost facilities for addressing these BSM questions. The LHCb
experiment is one of four large experiments at the LHC and is designed to study
in detail the decays of hadrons containing b or c quarks. The goal is to
identify the existence of new physics beyond the Standard Model by examining the
properties of hadrons containing these quarks. The new physics, or new forces,
can be manifest by particles, as yet to be discovered, whose presence would
modify decay rates and CP violating asymmetries of hadrons containing the b and
c quarks, allowing new phenomena to be observed indirectly - or via direct
observation of new force-carrying particles. The data sets collected by the LHC
experiments are some of the largest in the world. For example, the sensor arrays
of the LHCb experiment, in which both PIs participate, produce about 100 TB/s
and close to a zettabyte per year. Even after drastic data-reduction performed
by custom-built read-out electronics, the data volume is still about 10 exabytes
per year. Such large data sets cannot be stored indefinitely; therefore, all
high energy physics (HEP) experiments employ a second data-reduction scheme
executed in real time by a data-ingestion system - referred to as a trigger
system in HEP - to decide whether each event is to be persisted for future
analysis or permanently discarded. The primary goal of this project is
developing and deploying software that will maximize the performance of the LHCb
trigger system - running its first processing stage on GPUs - so that the full
physics discovery potential of LHCb is realized.&lt;br/&gt;&lt;br/&gt;The LHCb
detector is being upgraded for Run 3 (which will start to record data in 2022),
when the trigger system will need to process 25 exabytes per year. Currently,
only 0.3 of the 10 exabytes per year processed by the trigger is analyzed using
high-level computing algorithms; the rest is discarded prior to this stage using
simple algorithms executed on FPGAs. To significantly extend its physics reach
in Run 3, LHCb plans to process the entire 25 exabytes each year using high-
level computing algorithms. The PIs propose running the entire first trigger-
processing stage on GPUs, which has zero (likely negative) net cost, and frees
up all of the CPU resources for the second processing stage. The LHCb trigger
makes heavy use of machine learning (ML) algorithms, which will need to be
reoptimized both for Run 3 conditions but also for usage on GPUs. The specific
objectives of this proposal are developing: GPU-based versions of the primary
trigger-selection algorithms, which make heavy usage of ML; GPU-based
calorimeter-clustering and electron-identification algorithms, likely using ML;
and the infrastructure required to deploy ML algorithms within the GPU-based
trigger framework. These advances will make it possible to explore many
potential explanations for dark matter, e.g., dark photon decays, and the
matter/anti-matter asymmetry of our universe using data that would be otherwise
inaccessible due to trigger-system limitations.&lt;br/&gt;&lt;br/&gt;This award
reflects NSF's statutory mission and has been deemed worthy of support through
evaluation using the Foundation's intellectual merit and broader impacts review
criteria.