* 1744192
* I-Corps: Dexterous Robotic Prosthetic Control Using Deep Learning Pattern Prediction from Ultrasound Signal
* TIP,TI
* 07/01/2017,07/31/2018
* Gil Weinberg, Georgia Tech Research Corporation
* Standard Grant
* Anita La Salle
* 07/31/2018
* USD 50,000.00

The broader impact/commercial potential of this I-Corps project lies in the
development a novel system that would allow people with transradial and partial
hand amputations to gain unparalleled precise individuation of prosthetic digit
motion including continuous and simultaneous movement for individual digits
without requiring long and complicated training process. To allow for such
functionality a novel set of deep learning algorithms are designed to model
muscle movement patterns from ultrasound images. The network is pre-trained with
a large amount of data in an effort to minimize later individual training. In
addition to power prosthetics, the proposed technology can provide broad impacts
in other markets where easy-to-use and accurate gestural control of robotics
and/or digital environment are required. These include tele-robotics,
exoskeleton operation, virtual reality, gaming, glove boxes as well as work
related Personal Protective Equipment, and Performance Augmentation and
Amplification Devices.

This I-Corps project will develop and utilize a novel ultrasound sensor and
novel deep learning algorithms to recognize continuous muscle activity patterns
that can predict accurate and dexterous finger motion. Current myoelectric
powered prostheses use discrete classifiers that can only predict a limited
number of discrete gestures from noisy electromyography (EMG) signal. Feeding
deep learning architectures, such as Convolutional Neural Networks, with rich
and detailed ultrasound signal promises to allow for the modeling and prediction
of detailed continuous and simultaneous muscle movements patterns, which can be
mapped to control continuous and simultaneous movements of individual prosthetic
fingers. An additional intellectual of this project merit is the pre-training of
these deep neural network with a large amount of data, which would allow for
short fine tuning training for individual users, allowing for wide and easy
adoption of the technology. The proposed project could therefore allow amputees
and people with upper body disabilities to perform finger-by-finger movement
activities such as fine object manipulation, typing or playing a musical
instrument.