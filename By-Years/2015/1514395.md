* 1514395
* RI: Medium: Collaborative Research: Novel microLIDAR Design and Sensing Algorithms for Flapping-Wing Micro-Aerial Vehicles
* CSE,IIS
* 08/01/2015,07/31/2019
* Karthik Dantu, SUNY at Buffalo
* Continuing Grant
* David Miller
* 07/31/2019
* USD 372,655.00

This project makes it possible for a tiny robotic bee to sense its distance to
any nearby object. Such depth sensing for a small robot insect pushes the limits
of sensor and algorithm design in terms size, weight, computing, and power. The
key idea is joint design; every part of the robotic insect is optimized
together, from wing design and optics to intelligent algorithms and efficient
computation. This is possible by inter-disciplinary work across scientists and
engineers from diverse backgrounds. The lessons learned through this project can
be applied to transform other applications that involve small devices including
medical sensors and endoscope imaging, smart homes and the internet of things,
agricultural and industrial monitoring systems, and mobile vision for search and
rescue.

Lidar sensing has enabled large robotic cars to navigate complex environments.
This proposal introduces designs for "micro-lidar" that can be used on insect-
scale aerial robots. Making micro-lidar work on small platforms involves four
intertwined research thrusts. The first thrust uses MEMS mirrors and wide-angle
optics to sense and modulate the laser pulses. The second thrust is adapting
signal processing algorithms to estimate range data at this scale. The third
thrust is developing novel perception and navigation algorithms to map the
indoor environments using a micro-aerial vehicle. The fourth thrust is to
improve robotic insect flight to allow novel manipulations that require
knowledge of the surrounding range map. The utility of these sensors will be
demonstrated on the robobee for novel maneuvers and building topo-feature maps
of indoor environments.