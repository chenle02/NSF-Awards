* 8908612
* RIA:  Memory Architectures for Parallel Processing
* CSE,CCF
* 08/01/1989,07/31/1992
* David Harper,III, University of Texas at Dallas
* Standard Grant
* Yechezkel Zalcstein
* 07/31/1992
* USD 59,742.00

The primary objective of this investigation is to improve the performance of
computer architectures used for scientific and engineering computation. More
specifically, characteristics of scientific applications combined, with trends
in integrated circuit technology indicate that memory system performance will
soon be, if it is not already, the processing bottleneck in these architectures.
The research focuses on issues related to the improvement of memory system
performance. The first phase of the investigation studies characteristics of
data access in scientific codes. An understanding of vector and array usage in
applications is a prerequisite to designing efficient memory structures. The
second part of the investigation considers the benefits of uncovering the memory
architecture to system software. In particular, the recent work proposing the
use of dynamic storage schemes in main memory will be expanded upon. This
technique of using compile time and run time generated knowledge of program
behavior to dynamically optimize the memory architecture will be considered
experimentally, using simulation, and theoretically. Emphasis is placed on the
use of storage schemes to reduce contention for shared memory modules and the
processor-memory interconnection network. Concurrently, a set of tools to
provide interactive animation and simulation of main memory architectures will
be developed.