* 1551131
* EAGER: Collaborative Research: Models of Child Speech
* CSE,IIS
* 09/01/2015,02/28/2018
* Steven Lulich, Indiana University
* Standard Grant
* Tatiana Korelsky
* 02/28/2018
* USD 160,000.00

In contrast to the production, modeling, and machine recognition of adult
speech, which have been studied for decades, the production, acoustic modeling
and recognition of child speech have not received the same level of attention.
The lack of scholarly resources for dealing with children's speech is
problematic as new applications for child speech and language development become
increasingly important and commonplace. This is especially true for elementary
school children. As children grow, their articulators grow as well, resulting in
variations in their speech sounds. For example, the waveform of the word 'sunny'
spoken by a 6-year old can be quite different than that of the same child when
she is 9 years old. This is why current machine recognition of children's speech
does not perform well for young children and does not scale up as the child
grows. That is, these systems tend to be age dependent. Understanding and
modeling child speech as children grow is important not only to developing
better recognition systems but also for better understanding and diagnosis of
speech-language pathology (SLP). As the negative long-term ramifications of
deficits in early childhood development gain increasingly broad recognition, the
opportunities and the need for social and health services and technological
applications targeted toward young children are growing. In particular, it is
now understood that early deficits in language development and literacy persist
into adulthood, and the demand for SLP services in public schools is
significantly outpacing supply. As a result, it is no longer feasible for
clinicians and teachers to provide the most effective treatments or the
necessary attention to every child. Better speech recognition systems would
provide an opportunity for improved diagnosis and more intense computer-based
therapy. This Early Grant for Exploratory Research project aims to model how
speech and language develop during elementary school and how children with
speech disorders differ in their articulation of speech sounds. Models of child
speech will lead to the development of computer programs which can be used for
educational as well as therapeutic
purposes.&lt;br/&gt;&lt;br/&gt;Scientifically, the exploratory project will 1)
reveal processes of speech production development in 20-26 elementary school-
aged children through a unique combination of articulatory and acoustic
analyses, and 2) develop acoustic models and eventually automatic speech
recognition systems for children's speech which can be scalable with age (as
opposed to being age-dependent systems). This can only be achieved by
understanding how the articulation and corresponding acoustics develop with age.
The different aspects of the project are therefore synergistic: findings from
articulation and acoustic experiments will inform the development of algorithms
essential to automatic speech recognition. Production data will include real-
time 3D ultrasound recordings of the tongue, video recordings of the lips,
palate impressions, microphone recordings, and accelerometer recordings of neck
skin vibrations which have been shown to be beneficial in automatic speech and
speaker recognition applications. The causal relationship between articulatory
and acoustic variability will be explored, as will their relationship to
misrecognition of child speech. Articulatory features will be incorporated into
new automatic speech recognition systems along with acoustic features. The
exploratory project will contribute to knowledge of variability between
children, as well as variability over time as children grow and will provide,
for the first time, normative data and scientific models. These can lead to
robust child speech recognition systems as well as tools that will be useful for
a variety of applications such as educational games, training of speech-language
pathologists, automatic or semi-automatic transcription systems, and speech
articulation visualization systems. It will train undergraduate and graduate
students in important cross-disciplinary activities of technological and
scientific significance. We believe that the proposed project is transformative
in its advancement of the scientific and technological state of the art related
to child speech.