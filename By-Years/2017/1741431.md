* 1741431
* BIGDATA: IA: Distributed Semi-Supervised Training of Deep Models and Its Applications in Video Understanding
* CSE,IIS
* 09/01/2017,08/31/2020
* Mubarak Shah, The University of Central Florida Board of Trustees
* Standard Grant
* Hector Munoz-Avila
* 08/31/2020
* USD 662,431.00

This project investigates semi-supervised training of deep neural network models
using large-scale labeled and unlabeled data in a distributed fashion. Deep
neural networks have recently been widely deployed in artificial intelligence
and related scientific fields, largely attributing to well-labeled big datasets
and improved computing capabilities. However, the unlabeled data, which is often
bigger, is inherently ruled out by the prevailing supervised training of the
deep models. It is indeed highly challenging to model the unlabeled parts of
many recent and emerging datasets, which are often unstructured and distributed
over different nodes of a network (e.g., the videos captured by a camera
network). This project aims to explore how to effectively use the unlabeled and
distributed data to complement the discriminative cues of the labeled data, to
jointly learn accurate and robust deep models. The research seamlessly unifies
machine learning, computer vision, and parallel computing, and fosters unique
interdisciplinary research and education programs for the graduate and
undergraduate students.&lt;br/&gt;&lt;br/&gt;Despite the progress on semi-
supervised learning and deep learning, the confluence of these two is mostly
studied on a small scale in single-machine environment. However, many new
datasets easily grow beyond the computation or even storage capacity of a single
machine. Hence, it becomes a pressing need to investigate the semi-supervised
learning of deep models on parallel computing platforms. To better account for
this scenario, this project develops improved network architectures to
facilitate the parallel training, and the training procedure developed
adaptively switches between synchronized and asynchronized modes for optimal
efficiency. The main idea is to incorporate a parametric distribution to the
neural network and use covariate matching to coordinate the network behaviors
across different machines. The researchers also explore a novel application,
extreme-scale spatial-temporal action annotation of video sequences, to
benchmark the algorithms and frameworks in this project.