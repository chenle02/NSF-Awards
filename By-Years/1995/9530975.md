* 9530975
* A Computational Theory of Operant Conditioning with         Application to Trainable Robots
* CSE,IIS
* 06/01/1996,11/30/1999
* David Touretzky, Carnegie-Mellon University
* Continuing Grant
* Ephraim Glinert
* 11/30/1999
* USD 256,562.00

This award supports the development of a computationally explicit theory of
operant conditioning, in which animals determine the effects of their actions
and adjust their behavior to maximize reward. The Rescorla-Wagner model of
classical conditioning and its various descendants have yielded considerable
insight into how associations between sensory stimuli andreflex actions may be
acquired. But operant conditioning evokes more complex and deliberate behavior
patterns, for which there is no comparable computational model. The theory being
developed includes four types of learning: (i) on-line learning of reward
predictors based on observed reinforcement contingencies, (ii) acquiring
secondary reinforcers, such as the sound of a food dispenser being activated,
(iii) generating new actions by selecting and shaping innate behaviors, and (iv)
refining perception to focus on task-relevant signal discriminations. In
addition to testing the theory with computer simulations of classic animal
learning experiments such as the Delayed Match to Sample task, the theory is
being embodied in an RWI B21 mobile robot. This research promises a new class of
learning robots that can interact with people in much the same way that animals
interact with their human trainers