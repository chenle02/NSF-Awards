* 2237880
* CAREER: Human-Machine Supervision Cycle for Trustworthy Biometrics
* CSE,CNS
* 06/01/2023,05/31/2028
* Adam Czajka, University of Notre Dame
* Continuing Grant
* Anna Squicciarini
* 05/31/2028
* USD 107,988.00

Dominant approaches of biometric attack detection make strong assumptions about
the type of deviations from authentic information. This creates a critical gap
between reliability observed in laboratory settings and the performance expected
in the real world, where future attacks are unknown. This project fills this gap
and builds an effective symbiosis between Artificial Intelligence (AI) and
humans. The project novelties are new methods that (a) allow the AI to
effectively learn from humans how to increase detectability of unknown attacks
on biometric systems, and (b) support humans in their examination of fake
biometric inputs. The project's broader significance and importance are: (a)
trustworthy biometric systems that better recognize never-seen presentation
attacks, and thus better protect consumer devices, bank accounts and strengthen
the US border control processes; (b) a strong educational program that exposes
K-12, undergraduate and graduate students to both the security- and ethics-
related aspects of biometrics, and broadens their knowledge in a relevant topic
of national concern; (c) publicly available lectures prepared by the
investigator, which will broaden the awareness of responsible use of
biometrics.&lt;br/&gt;&lt;br/&gt;In this project, a holistic framework for
human-machine supervision cycle will be established to enable (a) human-guided
design of computer vision methods to make the biometric presentation attack
detection mechanisms generalize better to unknown attack instruments and (b)
creation of computer-aided methods of assisting human examiners in detecting of
fake inputs. Fundamental technical contributions of this project include (1)
broadening knowledge about mechanisms that govern human perception of fake
visual signals, (2) discovering the most effective human-interpretable
representations of information to support their decisions and speed up their
learning of new types of attacks, (3) developing quantitative metrics of trust
assessment and linking human and machine decisions into a trustworthy tandem
that makes better judgements on the authenticity of biometric inputs, and (4)
application of the framework to iris recognition of newborns, contributing to a
better linkage with mothers and/or guardians, resulting in improved chances to
benefit from healthcare systems, especially in developing
countries.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.