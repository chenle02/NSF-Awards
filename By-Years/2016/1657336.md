* 1657336
* CRII: SHF: Design and Analysis of Processing-Near-Memory Enabled GPU Architecture
* CSE,CCF
* 02/01/2017,01/31/2020
* Adwait Jog, College of William and Mary
* Standard Grant
* Yuanyuan Yang
* 01/31/2020
* USD 175,000.00

Graphics Processing Units (GPUs) are becoming an inevitable part of
every computing system because of their ability to enable orders of magnitude
faster and energy-efficient execution. However, the necessary and continuous
scaling of GPUs in terms of performance and energy efficiency will not be an
easy task. Prior works have shown that two biggest impediments towards this
scaling are the limited memory bandwidth and the excessive data movement across
different levels of the memory hierarchy. In order to alleviate these two
issues, die-stacking technology is gaining momentum in the realm of high-
performance energy-efficient GPU computing. This technology not only enables
very high memory bandwidth for better performance but also provides support for
processing-near-memory (PNM) to reduce data movement, access latencies, and
energy consumption. Although these technologies seem promising, the
architectural support and execution models for PNM-based GPUs and
their implications on the entire system design have largely been unexplored.
This project takes a fresh look at the design and execution model of a PNM-
enabled GPU, which consists of multiple memory stacks and each memory stack
incorporates a 3D-stacked logic layer that can consist of multiple PNM GPU cores
and other uncore components. Considering that GPUs are becoming an inevitable
part of every computing system ranging from warehouse-scale computers to
wearable devices, the insights resulting from this research can have a long-term
positive impact on the GPU-based computing. The findings of this research will
be incorporated to existing and new undergraduate and graduate courses, which
will directly help in educating and training students, including women and
students from diverse backgrounds and minority
groups.&lt;br/&gt;&lt;br/&gt;First, a detailed design space exploration will be
performed, which will involve the study of the impact and interactions of
different design choices related to PNM cores (e.g., register file, SIMD width,
pipeline components, warp occupancy), uncore components at the logic layer
(e.g., caches) and stacked memory (e.g., number of stacked memories). Second,
a computation distribution framework (CDF) will be developed that will answer:
a) when is it preferable to map computations to PNM cores, b) which PNM
cores and computations they should be?, and c) how can we effectively take
advantage of both PNM and regular GPU cores? The CDF will leverage different
static and runtime strategies to address many of such similar questions to push
the envelopes of energy efficiency and performance even further. The proposed
research components will be evaluated via a wide-range of GPGPU applications. 
If successful, the findings of this research would better equip PNM-enabled GPUs
to effectively alleviate the two major bottlenecks: memory bandwidth and energy.