
* 2113373
* A Transfer Learning Approach to Algorithmic Fairness
* DMS,STATISTICS
* 08/15/2021,08/02/2021
* Yuekai Sun,MI,Regents of the University of Michigan - Ann Arbor
* Standard Grant
* Yulia Gel
* 07/31/2024
* USD 150,000.00

In today's data-driven world, machine learning models are routinely used to make
high-stakes decisions in criminal justice, education, lending, medicine, and
many other areas. Although replacing humans with machine learning models appears
to eliminate human biases in decision-making processes, they may perpetuate or
even exacerbate biases in the training data. Such algorithmic biases are
especially objectionable when they adversely affect underprivileged groups. In
this project, we focus on detecting and mitigating algorithmic biases that are
caused by sampling biases in the training data. The project also provides
research training opportunities for graduate students.

There are three aims. First, the PIs identify gaps in the capabilities of
existing algorithmic fairness practices for overcoming sampling biases in the
training data. The PIs also study how current trends in the development of
machine learning (ML) models (for example, data augmentation and
overparameterization) can perpetuate and exacerbate algorithmic biases. Second,
the PIs cast the fair machine learning problem as a transfer learning problem
and leverage recent developments in transfer learning to detect and mitigate
algorithmic biases caused by sampling bias. Third, the PIs consider how to
collect training datasets that are more representative of the general population
and beget ML models that are free from algorithmic biases. The ultimate goal is
to broaden the appeal and adoption of algorithmic fairness practices among ML
practitioners. The PIs plan to demonstrate that the transfer learning approach
to algorithmic fairness avoids two barriers in the way of this ultimate goal:
(i) it aligns the goal of algorithmic fairness with the goals of (possibly non-
altruistic) ML practitioners by avoiding the apparent trade-off between accuracy
and fairness, and (ii) it addresses the lack of consensus on the choice of
algorithmic fairness practice in many ML tasks by providing an objective measure
of the efficacy of such practices.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.
