* 0308222
* Transductive Learning for Retrieving and Mining Visual Contents
* CSE,IIS
* 09/01/2003,05/31/2008
* Ying Wu, Northwestern University
* Continuing Grant
* Maria Zemankova
* 05/31/2008
* USD 281,702.00

Contemporary visual learning methods for visual content mining tasks are plagued
by several critical and fundamental challenges: (1) the unavailability of large
annotated datasets prevents effective supervised learning; (2) the variability
in different working environments challenges the generalization of inductive
learning approaches; and (3) the high-dimensionality of these tasks confronts
the efficiency of many existing learning techniques. The goal of this research
project is to overcome these challenges by exploring a novel transductive
learning approach.&lt;br/&gt;&lt;br/&gt;The approach provides a unified
framework accommodating four subtasks: (1) transduction that integrates
unlabelled and labeled data to alleviate the challenge of limited supervision
and to enable automatic annotation&lt;br/&gt; propagation; (2) model
transduction that automatically adapts a learned model to untrained environments
for&lt;br/&gt; efficient model reuse; (3) co-transduction that facilitates
transduction with multi-modalities to handle&lt;br/&gt; high-dimensionality in
visual data; and (4) co-inference that exploits the interactions among multiple
modalities to enable efficient model transduction.&lt;br/&gt;&lt;br/&gt;The
research is linked to educational activities including the development of an
integrated course of&lt;br/&gt; content-based visual data mining and the
development of innovative course projects to engage students
in&lt;br/&gt;research. The project disseminates research to other research
communities through organizing workshops and tutorials, and to the general
public, minority groups and woman students through creating Open House
events.&lt;br/&gt;&lt;br/&gt;The results of this project will lead to
significant improvement on the quality of content-based and object-level
multimedia retrieval, will greatly benefit visual recognition that requires
large datasets for training and evaluation, will significantly reduce the
efforts of training brand new models for un-trained scenarios, and will be very
useful in intelligent video surveillance applications thus having a great impact
on homeland security. A website, http://www.ece.nwu.edu/~yingwu, contains
research results, including demos, constructed benchmark datasets and software
can be accessed.&lt;br/&gt;&lt;br/&gt;