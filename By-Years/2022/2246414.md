* 2246414
* CAREER: Favorable Optimization under Distributional Distortions: Frameworks, Algorithms, and Applications
* ENG,CMMI
* 10/01/2022,09/30/2026
* Weijun Xie, Georgia Tech Research Corporation
* Standard Grant
* Georgia-Ann Klutke
* 09/30/2026
* USD 422,712.00

This Faculty Early Career Development Program (CAREER) award will support the
investigation of new methods to significantly enhance data-driven decision-
making under distributional distortions. Data-driven optimization is a commonly
used tool in many industries to support complex decision making, but the
resulting decisions are often susceptible to poor data quality. Stochastic
optimization methods, for example, may be unduly influenced by outliers, while
robust optimization methods may provide solutions that are overly cautious. This
research project investigates a new framework for data-driven optimization,
intended to specifically take into account the sensitivity of solutions to data
quality, and to develop methods to improve these decisions. In addition to new
undergraduate and graduate-level course modules on optimistic optimization, the
educational components of this project include a summer camp module for high
school girls interested in STEM, collaboration with a local science museum, and
an interactive optimization-based interdiction game.
&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;This project will establish theoretical and
algorithmic foundations for Distributionally Favorable Optimization (DFO) and
investigate its applications to the areas of operations engineering under
distributional distortions. Distributionally Favorable Optimization incorporates
methods to examine distributional assumption on the input data and select the
optimal decision under the most-favorable distribution. Specifically, this
research will (i) establish fundamental frameworks for DFO that can
substantially reduce the effects of outliers; (ii) investigate effective
decomposition-based solution schemes for solving large-scale DFO models that are
computationally efficient and have attractive convergent properties; (iii)
explore and exploit structures such as submodularity, clustering, and covering
of nonconvex DFO models, stimulating solution algorithms with theoretical
performance guarantees; and (iv) develop learning-and-optimization frameworks to
explore endogenous uncertainty in the DFO models. DFO can significantly reduce
the effects of outliers, potentially enabling more accurate and reliable
decisions.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.