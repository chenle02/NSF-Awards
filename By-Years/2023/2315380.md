* 2315380
* Doctoral Dissertation Research in Economics: Algorithmic Bias and Dynamics of Hate Speech on Social Media
* SBE,SES
* 07/15/2023,05/31/2024
* Aarushi Kalra, Brown University
* Standard Grant
* Kwabena Gyimah-Brempong
* 05/31/2024
* USD 20,496.00

This award supports research on social media algorithms that lead to hate speech
and polarization on these platforms. It is thought that the sharp increase in
hate speech around the world is partly caused by social media algorithms that
amplifies such hate speech. However, researchers have not been able to test
whether this is the case or not for lack of appropriate data. Working with one
of the largest social media platform in the world, the researchers will study
the effects of algorithmic recommendations on increased hate speech and the
cumulative effects of past exposure to hateful content prompted by algorithms on
current user engagement with such social media posts. The use of experimental
methods will allow the researchers to disentangle the effects of user
preferences for hate speech from the effects of algorithmic amplification of
hate speech. The results of this research will provide important inputs into
policies to reduce hateful speech on social media platforms and thus establish
the US as a global leader in reducing hate speech on social media.

Algorithmic recommendations are widely used to tailor content to usersâ€™
preferences on social media platforms leading to amplification of some messages,
yet little is known about the causal effect of these algorithms on hateful
speech. The algorithms expose different users to specific kinds of content based
on their innate preferences over social content. These preferences are not
observed by the researcher but are learned by the algorithm over time. This
project investigates the influence of algorithmic recommendation systems on the
amplification of engagement with hate speech. To accomplish this, the
researchers will conduct a large-scale RCT in collaboration with one of the
largest social media platforms in the world. In this experiment, content
recommendations will be switched off for a random set of users. As a result, a
large number of users will be exposed to content that is chosen randomly from
the entire corpus of posts. The researchers hypothesize that the effect of past
exposure on sharing of current content will cause algorithmic customization to
be more polarizing than it would be in the absence of such dynamic effects. The
results of this research will provide important inputs into policies to reduce
hateful speech on social media platforms and thus establish the US as a global
leader in reducing hate speech on social media.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.