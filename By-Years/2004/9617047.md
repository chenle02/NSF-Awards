* 9617047
* Visual Speech and Face Recognition: Common Information      Attributes
* SBE,BCS
* 04/15/1997,03/31/2001
* Lawrence Rosenblum, University of California-Riverside
* Continuing Grant
* Jasmine Young
* 03/31/2001
* USD 230,025.00

9617047 ROSENBLUM A series of experiments will test the relation between
speechreading (lipreading) and face recognition. Traditionally, the functions of
recognizing speech and recognizing the speaker have been thought to involve
separate processes and informational attributes. However, recent observations
with auditory speech suggest that these two functions might not be as separate
as once thought. The same question arises for the visual domain: How do
speechreading and face recognition functions interact? The first set of
experiments will test if facial familiarity facilitates speechreading. The
second series of experiments will explore if the relationship between
speechreading and face recognition could be based on the use of common visual
information for articulator movements. The experiments in this series will make
use of a point-light technique which involves placing small illuminated dots on
an otherwise darkened face. This technique serves to isolate articulator
movement information and can convey a great deal of speech information. The
third series of experiments will test whether face processing and speechreading
depend on the two cerebral hemispheres in the same or different ways. These
experiments will vary the amount of dynamic information available in the
stimulus by using static, moving, and point-light images. The results of these
experiments will be illuminating about theories of face and speech perception as
well as the general issue of the separability of perceptual processes. The
experiments should also help determine the salient information for speechreading
and face recognition. This research should ultimately be useful for designing
speech and face recognition devices as well as speechreading programs for the
hearing impaired. ***