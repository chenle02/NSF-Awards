* 2328856
* Collaborative Research: FuSe: Metaoptics-Enhanced Vertical Integration for Versatile In-Sensor Machine Vision
* CSE,CCF
* 10/01/2023,09/30/2026
* Yuhao Zhu, University of Rochester
* Continuing Grant
* Sankar Basu
* 09/30/2026
* USD 156,895.00

Vision is perhaps the most important human perception, as the majority of the
brain’s cognitive function is dedicated to processing visual information.
Despite recent advancements, today’s vision sensors remain quite primitive when
compared to the superior ability of human visual perception. Moreover, the rapid
development of deep learning and artificial intelligence (AI) has unleashed a
new wave of machine vision, where increasing amounts of image data are generated
and consumed, not by humans, but by edge devices to perform intelligent tasks
such as classification, recognition, and perception. Inspired by the biological
system and motivated by the huge demand of machine vision, this project
investigates an integrated and holistic approach to building versatile vision
systems that can be tailored for domain-specific tasks. It aims to create a
vertically-integrated design stack for vision sensors across optics, image
sensors, and vision processors. The project is expected to herald a new paradigm
of AI-driven vision systems and demonstrate technology to address pivotal
engineering challenges from real-time visual adaptivity in self-driving cars to
near-zero energy efficiency in persistent environmental monitoring. In addition,
the project’s education and workforce development activities foster an open-
source hardware community to boost accessibility and deepen collaboration beyond
the traditional discipline divides, as well as to build up the capacity of
domestic talents in vision sensor industry, critical to national security and
supply chain safety.

The research objective of this project is to create the scientific and
engineering foundations for a novel machine vision system that explores the
hybrid integration of nanophotonic metamaterials and complementary metal-oxide
semiconductor (CMOS) circuits and synergistically leverages the intrinsic
computing capability of computational metasurface and analog-domain encoder
embedded inside the image sensors. Our principled approach to abstracting design
knobs and modeling interactions and tradeoffs across the system layers and
physical domains will inform future “More than Moore” multi-physics
semiconductor device integration. We will delve into the key concept of
optimally distributing computation along the processing pipeline with
complementary intrinsic physical-domain operations. Our end-to-end design
framework is deliberately created to bridge the divide between
modeling/simulation infrastructure and design toolchains across multiple
heterogeneous physical domains. The core principles of embedding machine-
learning-enabled feature selection with optical/electrical vertical integration
could have a major impact on the design of sensor-rich intelligent physical
platforms where resource constraints coincide with strict latency requirements.
The technology developed in this project will turbocharge AI-enabled hardware to
satisfy the tremendous computational demand imposed by data proliferation,
broadly benefiting a range of burgeoning industries such as machine vision as a
service, smart IoT infrastructure, data-driven sensing and imaging.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.