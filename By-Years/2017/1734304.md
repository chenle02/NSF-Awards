* 1734304
* CompCog: Computational, distributed accounts of human memory: improving cognitive models
* SBE,BCS
* 08/01/2017,07/31/2022
* Prasenjit Mitra, Pennsylvania State Univ University Park
* Standard Grant
* Betty Tuller
* 07/31/2022
* USD 499,969.00

Memory is among the most impressive aspects of human cognition, allowing us to
learn new words or new ideas from just a few examples. However, the scientific
understanding of how this learning occurs is limited. This research project
focuses on how learning occurs in the context of memory for language. Within the
human mind, there is something like a dictionary that tells people what words
mean (semantics) and how words are combined to make grammatical sentences
(syntax). How does the mind learn this dictionary from experience with a
language? Computer simulations can help science better understand this learning
process. This scientific understanding can, in turn, help teach languages in the
classroom and aid in the early detection of language deficits, whether it be
developmental deficits in children, or age-related deficits in adults.
Furthermore, improving the ability of computers to simulate language learning
processes can also lead to the development of better technology such as machine
translation, web search, and virtual assistants. This project considers how a
better understanding of language learning can help us avoid common pitfalls of
memory connected to the use of language. For example, humans easily over-
generalize and judge a "book by its cover", associating certain occupations or
personality traits with a gender. If we know how people come up with
associations between words and concepts, we can also detect and prevent
prejudices in language to help ensure that artificial intelligence applications,
such as web search, do not produce prejudiced results. The project supports an
interdisciplinary and diverse team of researchers and students at Penn State,
attracting college students to engage with research in cognitive science and
artificial intelligence.&lt;br/&gt;&lt;br/&gt;In this project, the researchers
are designing a new model of human memory, the Hierarchical Holographic Model.
This computational model helps explain certain aspects of how words and
languages are learned. The model draws on the successes of artificial
intelligence and deep neural networks, and applies these insights to psychology.
With this model, the researchers investigate the question of whether human
memory has the ability to detect arbitrarily indirect associations between
concepts. The model uses a recursive learning process, building on previously
learned knowledge to acquire new knowledge, which allows the model to learn
arbitrarily indirect and abstract relationships between words. The researchers
consider evidence that sensitivity to abstract relations between words improves
the ability of the computer model to learn syntax, such as parts-of-speech, and
to use words appropriately to construct grammatical sentences. This work will be
assessed against human language data and competing computational models. The
success of the computational model should provide evidence that (1) language
acquisition depends on indirect associations, and (2) human memory must be able
to form indirect associations to facilitate it.