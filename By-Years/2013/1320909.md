* 1320909
* HCC: Small: Effective Augmented Reality Depth Representation Methods and Accuracy Evaluations Inspired by Medical Applications
* CSE,IIS
* 09/15/2013,08/31/2020
* J. Edward Swan II, Mississippi State University
* Continuing Grant
* Ephraim Glinert
* 08/31/2020
* USD 498,233.00

Augmented reality (AR) systems, which are computer systems that enhance the
viewing of physical objects in the world with computer data, are currently held
back from widespread use for many real-world applications because of the
unsolved human-computer interaction problem of how to accurately convey to a
person how far away from that person a computer-generated object is intended to
appear. People using AR systems routinely misjudge the depth of AR-presented
objects. This is especially true for AR objects that should appear to be located
behind opaque occluding surfaces; in this case AR should produce an "x-ray
vision" perceptual experience that makes the occluding surface appear to become
transparent. The perceptual phenomena that underlie this problem relate to (a)
conflicting depth cues that naturally arise with AR technology, especially
incorrect occlusion cues in optical "x-ray vision" AR, (b) conflicting findings
from techniques that have been developed to measure depth perception within
reaching distance, and (c) the role of practice and feedback in training to
correct these depth misjudgments.

This project will evaluate AR depth representation methods and explain the
underlying phenomena, with an emphasis on medical AR tasks and applications. The
project will develop and evaluate a head-worn haploscope to allow researchers to
study the depth cues of accommodation and vergence AR. The project will create
and evaluate vergence-based methods for rendering AR information in depth; that
is, techniques in which people can control the appearance of computer data
inside of a physical object by rotating their eyes as is needed to look at near
and far objects. The researchers on this project will collaborate with experts
on the use of AR for medical applications to develop new vergence-based
techniques for AR "x-ray vision" in the medical domain.

Broader Impacts: Vergence-based AR applications have the potential to improve
health outcomes for a broad array of medical procedures, and also to improve
human capabilities in task domains such as manufacturing and equipment
maintenance. This project will hasten the timeframe for successfully developing
and deploying such applications. Students working on this project will be
trained in an interdisciplinary context that rigorously studies the intimate
interplay between computer graphics and human perception. The interdisciplinary
and human-centered aspects of the project will help to recruit students who
might otherwise be less likely to gravitate to computer science.