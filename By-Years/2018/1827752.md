* 1827752
* Collaborative Research: Effector and Task Neural Representations of Hand-Object Interactions
* SBE,BCS
* 09/01/2018,08/31/2023
* Justin Fine, Arizona State University
* Standard Grant
* Betty Tuller
* 08/31/2023
* USD 466,383.00

This project focuses on understanding how people learn, plan, and execute hand
movements to grasp and use objects. For example, how does a person lift a cup of
coffee without spilling or a factory worker line up a Phillips-head screwdriver
with the grooves on a screw? Although we perform these tasks routinely without
giving them too much thought, dexterous manipulation is one of the most complex
and least understood human skills and one that still limits the utility of
robots in industry. Of particular interest is understanding the brain mechanisms
that allow people to learn to manipulate an object one way (e.g., to lift a mug
by the handle) and then apply that knowledge differently (e.g., to lift the same
mug by its sides). The investigators are working towards a comprehensive theory,
at both the neural and behavioral levels, of how people learn and generalize
these hand-object interactions. The results may inspire new robotic manipulators
that are more dexterous, with human-like ability to generalize a learned motor
behavior to novel contexts. The work may also influence development of more
dexterous neuroprosthetics. The project's other broader impacts include a public
lecture and discussion on the social and ethical implications of human-robot
systems and participation in the "Science Cafe" series hosted by the Arizona
Science Center.&lt;br/&gt;&lt;br/&gt;Previous work by the investigators has
provided evidence for two scenarios for learning how to manipulate objects. In
one scenario, people build a high-level (i.e., task-level) representation of
object manipulation, which allows them to generalize the learned manipulation to
a different context. For example, people successfully manipulate an object even
after a finger is removed from, or added to, the object's contact surface or
when the object is manipulated by the contralateral arm. In a second scenario,
people build an effector-level representation. In this case, they persist in
generating the same finger placement and forces despite a new context that
requires different solutions, as when an object with an asymmetric mass
distribution is rotated. What are the neural mechanisms involved with promoting
or interfering with generalization of learned hand-object interactions? Can
neural representations at the task level - enabling generalization - be built
following repeated exposure to a different manipulation context? These questions
represent a significant gap in our understanding of skilled object manipulation.
The overall goal of this collaborative research is to elucidate neural
mechanisms underlying task- and effector-level representations of hand-object
interactions. The studies will record finger position and forces utilized when
grasping objects in order to probe the influence of the context in which a given
hand-object interaction is learned. Electroencephalography (EEG) will be used to
determine the neural correlates of successful and unsuccessful generalizations
to new contexts. Quantification of these behavioral variables and the
corresponding brain mechanisms will provide insights into how objects are
mentally represented and how these representations underlie planning and
execution of dexterous manipulation.&lt;br/&gt;&lt;br/&gt;This award reflects
NSF's statutory mission and has been deemed worthy of support through evaluation
using the Foundation's intellectual merit and broader impacts review criteria.