* 2312930
* Collaborative Research: III: MEDIUM: Responsible Design and Validation of Algorithmic Rankers
* CSE,IIS
* 09/01/2023,08/31/2027
* Julia Stoyanovich, New York University
* Standard Grant
* Sylvia Spengler
* 08/31/2027
* USD 400,000.00

Data-driven systems employ algorithms to aid human judgment in critical domains
like hiring and employment, school and college admissions, credit and lending,
and college ranking. Because of their impacts on individuals, population groups,
institutions, and society at large, it is critical to incorporate fairness,
accountability, and transparency considerations into the design, validation, and
use of these systems. Current research in this area has mainly focused on
classification and prediction tasks. However, scoring and ranking are also used
widely, and raise many concerns that methods designed for classification cannot
handle because classification labels are applied one item at a time, whereas
ranking is explicitly designed to compare items. This project is focused on
algorithmic score-based rankers that sort a set of candidates based on a
“simple” scoring formula. Such rankers are widely used in critical domains
because of the premise that they are easier to design, understand, and justify
than complex learned models. Yet, even these seemingly simple and transparent
rankers may produce counter-intuitive results, unfairly demote candidates that
belong to disadvantaged groups, and be prone to manipulation due to sensitivity
to slight changes in the input data or in the scoring formula. Addressing these
issues is challenging due to the interplay between the data being ranked and the
ranker, the complex structure within the data, and the need to balance multiple
objectives.

This project considers the core technical challenges inherent in the
responsible design and validation of algorithmic rankers, and pursues three
synergistic aims. Aim 1 is to develop methods to quantify the impact of item
attributes, and of specific engineering choices regarding attribute
representation and pre-processing, on the ranked outcome (validation). This
information is then used to guide the data scientist in selecting a scoring
function that corresponds to their understanding of quality or appropriateness
(design). Aim 2 is to develop methods to quantify the impact of data
uncertainty, of slight changes in the scoring formula, or both, on the ranked
outcome (validation). This information is then used to guide the data scientist
in intervening on data acquisition and pre-processing to reduce uncertainty, and
in selecting a scoring function that is sufficiently stable (design). Aim 3 is
to develop methods to quantify lack of fairness in ranked outcomes, with respect
to candidates from under-represented or historically disadvantaged groups, in
view of multiple fairness objectives and potential intersectional discrimination
(validation). This information is then used to identify feasible trade-offs and
assist the data scientist in navigating these trade-offs to enact fairness-
enhancing interventions (design). Outcomes of this work will impact the practice
of scoring and ranking in critical domains like educational program admissions,
hiring, and college ranking. Insights from this work will enable technical
interventions when appropriate, and also identify cases where they are
insufficient, and where more data should be collected or an alternative
screening process should be used. This project will also include teaching and
mentoring, public education and outreach, and broadening participation of
members of under-represented groups in computing.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.