* 2245739
* CRII:SCH: Interactive Explainable Deep Survival Analysis
* CSE,IIS
* 06/01/2023,05/31/2025
* Lu Wang, Texas State University - San Marcos
* Standard Grant
* Christopher Yang
* 05/31/2025
* USD 174,964.00

Annually, the United States spends almost 20% of gross domestic product (GDP) in
healthcare with growth continued to be boosted by a greying population aging
into Medicare. Although the cost is huge, numerous patients fail to get timely
and effective medication cure. Accurate diagnosis is critical in clinical
decision making. However, “prevention is better than cure” as prevention and
early intervention will prevent the aging people from suffering more diseases
and/or more extensive treatments. Also, it is too late to build the prediction
model when a lot of patients have been observed in the late stage of a
progressive disease, which severely damages their health. Meanwhile, in order to
be usable by healthcare providers, the prediction model needs to be
interpretable and trustable. Also, efficient interaction between human
stakeholders (e.g., developers, domain experts and/or end-users) and clear model
interpretation not only improve the model performance but also enhance human
trust. The proposed research project aims at developing algorithms and methods
that support implementation of trustworthy and time-efficient data-driven
decision making for prevention and early intervention.&lt;br/&gt;&lt;br/&gt;The
main approach proposed in this project is interactive explainable deep survival
analysis. Survival analysis aims at predicting the time to event of interest,
which is extremely beneficial in healthcare for modeling disease progression,
identifying prognostic factors, assessing risk of health. This project will
build deep survival analysis models in healthy aging and precision medicine to
support clinical decision making, especially in the early stage of a progressive
disease before a lot of patients have been suffered from that disease. Deep
survival analysis is a kind of “black box” model that stakeholders cannot tell
how the model operates and how it comes to its decisions and hence limits its
usage in practice. This project will develop methods to achieve both
transparency and trustworthiness in deep survival analysis models with encoding
of domain knowledge and expert feedback to achieve better prediction
performance. More specifically, this project will propose a time-dependent
counterfactual gradient integration to interpret what makes the model output
differentiate from the counterfactual survival status at each time interval.
This project will also incorporate feature attribution priors into the training
process of deep survival analysis model to improve consistency of the
explanation as well as the performance and trustworthiness of the model.
Inspired by human-in-the-loop, this project will further investigate efficient
schemes to mathematically formulate physicians' qualitative feedback, and
interactively incorporate them in the learning process of the model with
powerful perceptual user interface to efficiently encode diverse types of
feedback from physicians.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.