* 1552924
* CAREER: Ubiquitous Sensing Using Computational Light
* CSE,CNS
* 03/01/2016,02/28/2022
* Xia Zhou, Dartmouth College
* Continuing Grant
* Alexander Sprintson
* 02/28/2022
* USD 542,403.00

The ability to sense and detect human movement is critical to the development of
data-driven mobile health systems. It can help detect disease and foster
behavioral changes to cultivate healthy lifestyles. Existing sensing
technologies either require users to constantly wear or carry on-body
potentially cumbersome devices, are vulnerable to electromagnetic interference,
or present severe privacy risks involving leaking of sensitive data and images.
This project takes a entirely different approach to addressing these issues. It
exploits the use of ubiquitous light as a low-cost, unobtrusive, and accurate
sensing medium capable of simultaneously sensing people and their surrounding
context. The proposed vision " LightSense " consists of off-the-shelf LED lights
on the ceiling and a few low-cost photodiode sensors sprinkled in the
environment. The photodiodes passively capture light blockage created by the
human body and reconstruct fine-grained user behaviors in real time. LightSense
leverages light to turn a space into a cognitive space, which recognizes our
presence, senses our behaviors such as postures and high-level activities while
monitoring our health status indicators such as levels of stress.
&lt;br/&gt;&lt;br/&gt;LightSense is empowered by Visible Light Communication
(VLC) that turns the visible light into computational light. It contains the
following novel systems and algorithmic designs: 1) a novel VLC network
architecture with LED panels and sparse photodiodes to ease system deployment;
2) algorithmic and systems designs to separate light rays from dense LEDs,
optimize the placement of photodiodes, and overcome the blockage of other
objects (e.g., furniture, other users); 3) a new VLC primitive that allows light
communication and sensing to be sustained even under extremely low light
conditions; and 4) learning algorithms to infer physical activities, derive
movement characteristics, and monitor psychological state. LightSense will be
evaluated using real-scale testbeds and user studies. Results from this project
will establish the foundational pieces to define a new research space (visible
light sensing), and will generate far-reaching impact on promoting innovative
interaction designs and enabling new types of precise health monitoring.