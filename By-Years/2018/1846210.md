* 1846210
* CAREER: Robust Policy Learning for Safe and Reliable Algorithmic Decision Making from Observational Data in Sensitive Applications
* CSE,IIS
* 06/01/2019,05/31/2024
* Nathan Kallus, Cornell University
* Continuing Grant
* Rebecca Hwa
* 05/31/2024
* USD 500,000.00

Some of the most impactful applications of machine learning are not just about
prediction but are rather about taking the right action directed at the right
target at the right time. Actions, unlike predictions, have consequences and so,
in seeking to take the right action, one must seek to understand its causal
effect. This project deals with the problem of extracting causal-effect-
maximizing personalized decision rules from observational data in sensitive
applications. Observational data, which have become plentiful in domains such as
medicine and civics, lack experimental manipulation so that isolated causal
effects are obscured by complex selection processes, a phenomenon known as
confounding, and such data are also otherwise messy, noisy, biased, and often
missing. Despite the promise of rich and plentiful observational data, current
approaches cannot handle the unique challenges it poses and can lead to
unreliable, unsafe, and unfair decision making unfit for sensitive applications.
The goal of this project is to create a comprehensive framework of rigorous
theory and robust methodology to address this gap and enable trustworthy
decision-making systems trained on observational data. The research and
education plans are integrated through student advising and curriculum
development and include targeted outreach efforts to broaden participation of
underrepresented groups.&lt;br/&gt;&lt;br/&gt;The research will proceed along
three primary directions. The first is to develop methods and theory for
algorithmic decision making in the presence of unobserved confounders. Whereas
existing approaches tenuously rely on various unverifiable assumptions that
ensure point-identification of causal effects, the project will develop robust
learning methods that produce policies with certificates of safety and/or
improvement backed by theoretical guarantees that do not rely on exact
identification. The second is to develop methods and theory for robust and
optimal weighting for policy learning to address issues of stability, limited
overlap, time-to-event data, and noisy and missing observations. The third is to
investigate algorithmic fairness of decision policies trained from observational
data. The project will develop characterizations of fairness in settings where
disparity metrics cannot be point-identified from data, whether due to biased
selection or missing attributes and labels, as well as methods that can audit
and enforce fairness in such settings. Through these thrusts, the project will
both advance knowledge at the intersection of machine learning, causal
inference, and optimization as well as broaden the scope of their integration
with new problem domains.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.