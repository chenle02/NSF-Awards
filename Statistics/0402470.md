
* 0402470
* Tree-Structured Methods for Prediction and Data Visualization
* DMS,STATISTICS
* 06/01/2004,05/03/2004
* Wei-Yin Loh,WI,University of Wisconsin-Madison
* Standard Grant
* Grace Yang
* 01/31/2008
* USD 240,490.00

Though many recursive partitioning algorithms exist in the literature, most are
unsuitable for model interpretation because they tend to select some types of
predictor variables more frequently than others. As a result, such tree
structures can yield misleading conclusions about the roles and relative
importance of the predictor variables. The main thrust of the proposed research
is to extend the investigator's GUIDE and QUEST strategies to regression and
classification, respectively. This approach effectively solves the problem of
selection bias and significantly reduces computation time. The computational
savings make it feasible to build tree-structured models that are hitherto
impractical to construct. A second objective is to use the methods to model
unreplicated and fractionally replicated data from designed experiments. The
hierarchical structure of tree-structured models and their variable selection
ability make them attractive alternatives to traditional methods. A third
objective is extension of the investigator's LOTUS algorithm to fit logistic
regression trees to data with multinomial response variables.

Statistical models constructed from high-dimensional data are often difficult or
unintuitive to interpret. This applies even to the simplest model, the multiple
linear regression model, where interpretation of the parameter estimates is
fraught with difficulties caused by nonlinearity, multicollinearity, and
interactions in the data. Graphical visualization is perhaps the most effective
way to interpret a model. But such techniques are inapplicable to more than two
or three dimensions. The proposed research enables the application of
visualization techniques to high-dimensional data by using a tree-structured
method to partition the data space such that at most one, two, or three
predictor variables are needed to model the data in each partition. The result
is a graphical model whose broad features are representable by a tree structure
and whose finer features are visualizable by two and three-dimensional graphical
displays.
