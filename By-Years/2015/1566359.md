* 1566359
* CRII: CSR: Multi-View Learning Solutions for Next-Generation Computationally-Autonomous Wearables
* CSE,CNS
* 05/01/2016,04/30/2018
* Hassan Zadeh, Washington State University
* Standard Grant
* Marilyn McClure
* 04/30/2018
* USD 191,000.00

Wearables have emerged as a revolutionary technology for many new applications
in healthcare, fitness, and human-centered Internet-of-Things (IoT).
Computational algorithms, including machine learning and signal processing
techniques, are often used to extract valuable information from wearable sensor
data continuously and in real-time. These algorithms, however, need to be
retrained upon any changes in configuration of the system, such as
addition/removal of a sensor to/from the network, sensor
displacement/misplacement, sensor upgrade, adoption of the system by new users,
and changes in physical and behavioral status of the user. Retraining of the
computational algorithms requires collecting sufficient amount of labeled
training data, a time consuming, labor-intensive, and expensive process that
limits scalability and sustainability of wearable technologies. The goal of this
research is to enable automatic reconfiguration of the computational algorithms
without need for collecting new labeled data. &lt;br/&gt;&lt;br/&gt;This
proposed research aims to design, develop and validate algorithms and tools for
self-configuration of wearables through two overarching research trusts. First,
this project investigates synchronous multi-view learning solutions for
scenarios where source and target views observe the phenomena of interest
simultaneously. In the synchronous learning, direct associations between
observations made by the source view and those of the target view are
established through context-sensitive learning processes that take the
properties of physiological monitoring and human body into account for transfer
learning purposes. Second, this research develops asynchronous multi-view
learning algorithms to allow for automatic knowledge transfer even in absence of
synchronous measurements in the source and target views. The asynchronous
learning research devises feature mapping, instance transformation, and data
labeling techniques to determine how data instances of the target view are
associated with those of the source view while taking into consideration
physical and contextual attributes of the user.&lt;br/&gt;&lt;br/&gt;This
project will potentially result in highly sustainable and scalable wearables
capable to self-monitor and self-configure in highly dynamic and uncontrolled
environments. The true realization of computationally autonomous wearables will
allow for conducting high-precision chronic disease management and contribute to
availability of new wearable-based consumer applications. This can lead to the
development of products and business around the concept of human-centered IoT
and their use in automation of health management and many applications that are
currently infeasible.