* 2150615
* Simulation-Based Inference for Differential Privacy
* SBE,SES
* 08/15/2022,07/31/2025
* Roberto Molinari, Purdue University
* Standard Grant
* Cheryl Eavey
* 07/31/2025
* USD 450,000.00

This research project will deliver tools to obtain accurate and broad
statistical conclusions from data that are subject to privacy constraints.
Differential Privacy is an increasingly adopted technique to protect data within
government and industry, such as in the US 2020 Decennial Census. However,
privacy protection comes at a cost in terms of accuracy of the analysis run on
these data, sometimes drastically affecting the decisions and conclusions that
entail. While employing and training graduate students from diverse backgrounds,
this project will use computer-simulation techniques to tackle a wide range of
statistical tasks under these privacy settings. The increased accuracy from
these new tools will allow for the wider adoption of Differential Privacy and
increase the possibility of sharing data with reduced risks of privacy
violations. This will guarantee broader access to essential and reliable
information for decision-making bodies as well as for researchers in the social
sciences and other fields of academic research. Results will be disseminated
through a series of publications in journals and conference proceedings in the
fields of statistics and computer science, as well as through presentations at
national and international scientific conferences and workshops. Open-source
software packages will be developed and made available to the broader
community.&lt;br/&gt;&lt;br/&gt;This research project will deliver both
theoretical and practical tools for the advancement of statistical approaches in
complex parametric settings such as those entailed by the added noise of
Differential Privacy mechanisms. Differential Privacy protects the private
information of individuals included in the data by introducing calibrated noise
(randomness) into the data. The idea behind this mechanism is that even a highly
informed attacker/hacker will not be able to detect whether changes in outputs
are due to a particular individual's response or are simply due to randomness.
However, these noise-addition techniques also introduce additional bias and
variance into the analyses made by researchers who will want to use these data
for the advancement of knowledge in government, industry, and academia. This
project will deliver more accurate analytical techniques by relying on
simulation-based statistical methods, such as co-sufficient sampling and
indirect inference. While preserving the same level of privacy, this approach
will take into account the noise mechanisms used to privatize the data. The
tools to be developed will improve estimation and statistical inference on noisy
privatized data by correcting bias of estimators and delivering reliable
confidence intervals and hypothesis tests for a wide range of statistical
methods. The project will establish some of the first links between statistical
privacy and simulation-based inference techniques and will expand the field of
robust statistics.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.