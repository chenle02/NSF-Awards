* 2301553
* Excellence in Research: Towards Secure Unmanned Aerial Vehicles-based Systems
* CSE,CNS
* 06/01/2023,05/31/2026
* Abdollah Homaifar, North Carolina Agricultural & Technical State University
* Standard Grant
* Subrata Acharya
* 05/31/2026
* USD 575,865.00

This project aims to enhance the resilience of deep learning-based Unmanned
Aerial Vehicles (UAV) navigation systems to novel attack vectors that attempt to
misguide the UAV by making small changes to the sensed data. Such systems are
vulnerable to different attacks, which can result in the misguidance or hacking
of the UAV, posing significant safety risks. Different types of adversarial
attacks will be considered. Additionally, the project will investigate defense
methods against these types of stealthy attacks using state-of-the-art methods
as well as experimentations. The performance of the models will be judged
according to their ability to resist attacks through simulations and real-world
experiments using a UAV testbed. The results of this research will have
significant implications for the development of safe and reliable UAV navigation
systems, with potential applications in various fields such as crop monitoring,
search and rescue, and infrastructure inspection. The project aligns with NSF's
mission to promote fundamental research, advance the national interest, and
contribute to the broader scientific community by sharing its findings through
publications and open-source software. The research will support technical
development and engagement of underrepresented graduate and undergraduate
students at North Carolina A&T State University. The funding will also enhance
development of undergraduate/graduate-level course modules and certificates in
autonomy.

The project will investigate attack scenarios that combine two triggers, namely
trojan and adversarial triggers, to create a malign behavior where the model
remains robust in the absence of a trojan under adversarial attacks but behaves
maliciously when the trojan is present. To address these attacks, a deep
learning-based detection model will be developed that learns features from both
adversarial perturbations and counterfactual attributions, to detect and
mitigate these attacks. Secure deployment will also be investigated, including
remote controller and secure hardware.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.