* 2006618
* RI: Small: Speech-Centered Robust and Generalizable Measurements of "In the Wild" Behavior for Mental Health Symptom Severity Tracking
* CSE,IIS
* 10/01/2020,09/30/2023
* Emily Provost, Regents of the University of Michigan - Ann Arbor
* Standard Grant
* Tatiana Korelsky
* 09/30/2023
* USD 450,000.00

Bipolar disorder is a common and chronic illness characterized by pathological
swings from euthymia (healthy) to mania (heightened energy) and depression
(lowered energy). Mood transitions are associated with profound consequences to
one's personal, social, vocational, and financial well-being. Current management
is clinic-based and dependent on provider-patient interactions. Yet, increased
demand for services has surpassed capacity, calling for radical changes in the
delivery of care. This project will create new algorithms that can process
speech data naturally collected from smartphone use to measure behavior and
changes in behaviors and to associate these measurements with the severity of
the symptoms of bipolar disorder. This will lead to the creation of new early
warning signs, indications that clinical intervention is needed.
&lt;br/&gt;&lt;br/&gt;Natural behavior provides a wealth of information about
the health an individual. However, when assessing health, clinicians typically
access cross-sectional medical data at point-of-care that is based on
traditional medical methods (exams, labs, and surveys). Next generation
'precision health' depends on an inclusive and holistic approach that captures
changes in health as people live their lives. This is highly relevant as 130
million Americans live with chronic disease and need efficient monitoring
strategies. Speech is a promising medium for monitoring mood. Clinicians
subjectively assess both form and content of speech when evaluating human
disease, as speech is altered by changes in mood and health states. Yet, while
speech is easy to record, speech-centered mobile monitoring solutions are not
currently publicly available. The technology is neither sufficiently accurate
nor robust. The central challenge is the signal itself: speech is inherently
variable and complex. Existing techniques are insufficient to handle this
complexity, limiting the accuracy and robustness of speech-centered mood
monitoring technologies. This project will create novel and robust approaches to
extracting mood symptom severity measures from speech. Mood is clinically
quantified via the Hamilton Depression Rating Scale (HamD) and the Young Mania
Rating Scale (YMRS). The technology focuses on the creation of methods that
accurately extract symptom-focused measures, whose variation lies between that
of speech and mood severity, and that are robust to conditions, both
environmental and social, in which the data were recorded. The methods will be
validated on an existing natural speech dataset at the University of Michigan.
The unification will provide critical steps towards speech-centered mHealth
solutions.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.