* 1718550
* RI: Small: CompCog: Leveraging Deep Neural Networks for Understanding Human Cognition
* CSE,IIS
* 08/15/2017,07/31/2019
* Thomas Griffiths, University of California-Berkeley
* Standard Grant
* Kenneth Whang
* 07/31/2019
* USD 448,284.00

The last few years have seen significant breakthroughs in artificial
intelligence and machine learning, resulting in systems that approach or even
exceed human performance in interpreting pictures and words. This project
explores the implications of these breakthroughs for understanding how the human
mind works. Focusing on artificial neural networks, a key technology behind many
recent breakthroughs that is capable of discovering novel representations for
complex stimuli, the project has two goals. First, assessing the degree of
correspondence between human and machine learning by examining whether the
pictures or words that are similar in the representations discovered by neural
network models are also judged to be similar by people. Second, developing
methods for increasing this correspondence, with the goal of being able to use
neural network representations to generate good predictions about how people
learn and form categories using real images or text.

This research project will answer basic scientific questions about how the
representations discovered by contemporary neural networks relate to human
cognition. It will then explore what architectures and training regimes produce
representations with these properties. In addition, the project will address the
methodological question of how one can modify these representations to produce
better alignment with human cognition. Answering this question will lead to
powerful new tools for making models of human behavior in naturalistic contexts,
leveraging the latest results in machine learning to broaden the scope of
experimental research in cognitive science. By building stronger links between
human and machine learning, this project will have implications for both fields.
Even if current neural network systems turn out to differ significantly from
human learning, they provide state-of-the-art representations for images and
text that can be used as a starting point for developing better accounts of
human representations. By discovering the ways in which the representations
learned by artificial neural networks differ from those of humans, one can
identify new algorithms and training methods that will result in a closer
alignment. Since human beings remain the best examples available of systems that
can solve certain problems, such an alignment offers a path toward expanding the
capacities of current artificial intelligence systems and making them more
interpretable by people, which is critical in settings that require human-
machine interaction.