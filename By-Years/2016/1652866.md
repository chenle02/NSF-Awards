* 1652866
* CAREER: Designing Ultra-Energy-Efficient Intelligent Hardware with On-Chip Learning, Attention, and Inference
* CSE,CCF
* 03/15/2017,02/29/2024
* Jae-sun Seo, Arizona State University
* Continuing Grant
* Sankar Basu
* 02/29/2024
* USD 472,195.00

Building intelligent computers that can perform cognitive tasks (e.g., learning,
recognition) as well as humans do has been a long-standing goal of computing
research. State-of-the-art deep learning and neuromorphic algorithms have
recently advanced the software performance for cognitive applications. However,
such algorithms are computation-memory-communication intensive, which makes the
hardware design challenging to perform low-power real-time training and
classification on portable platforms. Furthermore, to optimize system-level
power, efficient power delivery and supply voltage regulation of such large-
scale hardware systems also becomes a critical concern. This project will
address these challenges across multiple disciplines of hardware and software
design, towards the overarching goal of building brain-inspired intelligent
computing systems that are ultra-energy-efficient for various cognitive tasks in
computer vision, speech, robotics and biomedical applications. The success of
this research is likely to impact many user-centric computing systems in society
and industry, including wearable, mobile, and edge computing. This project also
entails integrative education and outreach plans through a new interdisciplinary
coursework development, undergraduate/graduate student training, and a summer
outreach program for high school students.&lt;br/&gt;&lt;br/&gt;In this project,
energy-efficient circuits, architectures and algorithms will be designed to
incorporate learning, attention and inference computations in area-/power-
constrained mobile/wearable hardware platforms. The particular technologies that
will be developed to achieve large improvement in energy-efficiency include: (1)
computation redundancy minimization of state-of-the-art deep learning algorithms
with bio-inspired attention models, (2) novel memory compression schemes that
apply to both software and hardware implementation, (3) real-time on-chip
learning methods that consume low power on mobile/wearable devices, (4)
efficient on-chip voltage regulators that can adapt to abrupt changes in
cognitive workloads, and (5) cross-layer optimization of circuit, architecture
and algorithm. The outcomes of this research will feature new very-large-scale
integration (VLSI) systems that can learn and perform cognitive tasks in real-
time with superior power efficiency, opening up possibilities for ubiquitous
intelligence in small-form-factor devices.