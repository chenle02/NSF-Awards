* 9626187
* Multivariate Nonparametric Methodology Studies
* NONE,NONE
* 06/15/1996,08/31/1999
* David Scott, William Marsh Rice University
* Continuing grant
* Joseph M. Rosenblatt
* 08/31/1999
* USD 219,081.00

DSM9616187 Scott Nonparametric methodology is widely used in one and two
dimensions, but not in high dimensions. This research focuses on the mid-range
dimensions and provides a deeper understanding of the implications of the curse
of dimensionality and related problems associated with massive data sets.
Particular emphasis has been given to multivariate regression and density
estimation problems, and closely related applications such as clustering and
ridges. Anecdotal evidence has suggested a gap between the apparent successes of
nonparametric methodology in practice and the poor performance predicted by
theory. We have examined new points of view, especially related to locally
adaptive estimation. Higher quality estimation has often required use of
negative kernels, but our results have shown that equivalent gains are possible
in regions where the Hessian is indefinite, often in the tails which dominate in
higher dimensions. In addition, we have developed a class of locally adaptive
but not higher order algorithms that work better in practical problems and avoid
problems of negativity. We have addressed problems arising from high
dimensionality in several ways. We have created algorithms for finding
interesting subspaces from the density estimation point of view. Such subspaces
are defined by maximal bias content, sequentially peeling off low bias
subspaces. We have examined semiparametric models for density estimation that
can work better than ordinary nonparametric algorithms, extending feasibility by
several extra dimensions. Visualization is especially important when dealing
with medium dimensional data and the growing body of massive data sets. One
example of a new visualization tool is provided by the density grand tour, which
performs an ordinary grand tour but displays a real-time view of a derived
density estimate, the averaged shifted histogram. We have found that traversing
ridges and contours is useful to control or constrain viewing. We h ave extended
our density visualization capabilities to regression surfaces and related
problems in visual clustering and visual discrimination applications.
Visualization is also important for organizing complicated multiple testing
problems is clustering, such as our results in mode estimation and testing based
on the mode tree. We have investigated a local testing algorithm for collapsing
modes as the basis for an improved clustering algorithm. A natural extension has
been demonstrated for multiprocessor and parallel architectures for massive data
sets. A great challenge in mathematical sciences is provided by massive data
sets. At a recent National Research Council workshop, numerous scientists
identified critical statistical needs in their work: alternatives to principal
components, specialized visualization tools for exploring massive data, better
clustering algorithms, and techniques for handling nonstationary data. Results
from our research directly impact three of these four critical opportunities.
This program represents a comprehensive and long-term attack on a host of
important data analytic problems in multivariate estimation. %%% Statistical
techniques that do not require formulae to be written down explicitly are called
nonparametric methods and include the well-known histogram as a simple example.
Such techniques are widely used with data in one and two dimensions, but not in
higher dimensions where most of the grand challenge problems are to be found.
This research focuses on the mid-range dimensions where many serious
theoreticians have expressed concern that nonparametric methods may not work.
However, it is well-known that many practicing scientists and engineers have
been successfully using nonparametric methods with data from signal processing,
image understanding, data mining, among a wide array of real problems. This
research is providing a deeper understanding of the implications of the so-
called curse of dimensionality and particular p roblems associated with massive
data sets. Particular emphasis is given to problems in multivariate regression
and density estimation, as well as closely related applications such as
clustering and ridges. We have obtained a new understanding of how locally
adaptive estimation should work in overcoming the usual limitations of
nonparametric methodology in several dimensions. For higher dimensional data, we
have developed algorithms for finding maximally interesting subspaces from the
density estimation point of view. Such subspaces are defined by maximal bias
content and are constructed sequentially, peeling off low bias subspaces. Beyond
two dimensions, visualization is a critical task, especially as related to the
growing body of massive data sets. One example of a success is provided by our
new density grand tour, which provides a new way of looking at high dimensional
data in real-time. We have extended our density estimation visualization
capabilities to regression surfaces. Visualization is also very useful for
examining data to detect the presence of clusters. Such clusters are critical
for determining the usefulness of data collected for proposes such as character
recognition, remote sensing crop identification, ground water pollution, as well
as many more specialized engineering and scientific applications. Multiprocessor
and parallel architectures versions of these algorithms are particularly
relevant in the massive data set situation. A great challenge in mathematical
sciences is provided by handling massive data sets. At a recent National
Research Council workshop, numerous scientists identified critical statistical
needs in their work: alternatives to principal components, specialized
visualization tools for exploring massive data, better clustering algorithms,
and techniques for handling nonstationary data. Results from our research
directly impact three of these four critical opportunities. This program
represents a comprehensive and long-term attack on a host of important data
analytic problems in multivariate estimation. Nonparametric methodology seems to
work well in the hands of experts, and this research is designed to not only aid
the expert but to facilitate the use of the methodology by a wider audience. ***