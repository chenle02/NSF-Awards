* 0219885
* ITR: Learning and Measuring Perceptual Similarity
* CSE,IIS
* 08/15/2002,07/31/2005
* Edward Chang, University of California-Santa Barbara
* Continuing Grant
* Maria Zemankova
* 07/31/2005
* USD 161,080.00

Image retrieval has been an active research area for many years, but two
fundamental problems remain largely unsolved: 1) How best to learn users'
subjective query concepts, and 2) How to measure perceptual similarity with
significant accuracy. The first problem concerns the completeness of formulating
a query concept, e.g., how to formulate a query such as ``animals,''
``cathedrals,'' or ``aircraft.'' The second problem concerns search accuracy,
i.e., given a learned query concept, how to find all images that match that
concept.

To tackle these two fundamental problems and to ensure that our solutions are
scalable, this project has four specific targets. First, we plan to develop
novel active learning algorithms that quickly learn users' subjective query
concepts (thoughts and intents) despite time and sample constraints. Second, we
will design semi-automatic image annotation and annotation refinement methods
for assigning semantic labels to images in order to support multimodality query-
concept learning and information retrieval. Third, we will devise perceptual
distance functions for improving accuracy of visual searches. For instance, once
a query concept such as ``enemy vessels'' is learned, we want to find every
matching object in the surveillance database, not missing any. Finally, we plan
to conduct validation studies} on developed learning algorithms, using
experimental data provided by colleagues at various institutions (including IBM
research centers and Fine Arts Museums of San Francisco).



