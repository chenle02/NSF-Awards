
* 2145167
* CAREER: Exploiting Low-Dimensional Structures in Data Science: Manifold Learning, Partial Differential Equation Identification, and Neural Networks
* DMS,OFFICE OF MULTIDISCIPLINARY AC
* 03/01/2022,01/12/2022
* Wenjing Liao,GA,Georgia Tech Research Corporation
* Continuing Grant
* Stacey Levine
* 02/28/2027
* USD 332,336.00

This award is funded in whole or in part under the American Rescue Plan Act of
2021 (Public Law 117-2).

In general, scientific and engineering data can be high-dimensional, but in many
practical applications, data exhibit low-dimensional features due to local
regularities, global symmetries, or repetitive patterns. This project aims to
develop new theoretical and computational tools to exploit low-dimensional
structures in data science. The overall goal is to develop improved
computational algorithms for machine learning with high-dimensional datasets
that have additional structure. Machine learning research will also be
integrated with data science education, including a bridge program that aims to
help prepare undergraduate students with diverse backgrounds for careers in both
industry and academia.

This project aims to make fundamental mathematical, statistical, and
computational advances in analysis of high-dimensional data with structures.
Research directions include manifold learning, identification of partial
differential equations, and a nonparametric estimation theory for neural
networks. This work focuses on three sets of related but distinct questions. The
first set is about efficient approximation of functions supported on and near a
low-dimensional manifold. Efficient algorithms will be developed to build local
linear approximations of the manifold and polynomial approximations of the
function. A theoretical goal is to prove that the function estimation error
converges to zero as the sample size grows with a fast rate depending on the
intrinsic dimension of the manifold. The second set is on robust PDE
identification from noisy data. The PI will combine tools in machine learning
and numerical PDEs to explore noisy data and robustly identify the underlying
PDE and dynamics. This project will address denoising, recovery of spatially
varying parameters, and kernel identification in nonlocal equations. The third
set of questions concerns nonparametric estimation theory for neural networks
for learning operators between infinite dimensional function spaces. The work
aims to provide an upper bound for the error in estimation of Lipschitz
operators.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.
