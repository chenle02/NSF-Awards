
* 0706805
* Theory and algorithms for semi-supervised learning
* DMS,STATISTICS
* 09/01/2007,08/10/2007
* Tong Zhang,NJ,Rutgers University New Brunswick
* Standard Grant
* Gabor Szekely
* 08/31/2010
* USD 150,001.00

The investigator studies semi-supervised learning from a decision theoretical
point of view. The research shows that in the Bayesian framework, unlabeled data
should be used to construct a prior for the purpose of improving predictive
learning. More generally, the investigator considers the problem of constructing
priors and learning predictive structures on hypothesis spaces from unlabeled
data. Under this unified framework, the investigator systematically studies
theoretical and algorithmic consequences of semi-supervised learning.

Statistical machine learning is concerned with building computer systems that
can predict unobserved information (labels) based on observed information
(data). For example, to predict whether a patient has cancer (label) based on
blood test (data). Traditionally, a statistical machine learning algorithm
builds prediction rules from a set of labeled data. One of the most important
issues in practical applications of statistical machine learning is whether one
can improve the performance of a learning algorithm by using unlabeled data.
This is because unlabeled data are generally abundant while their labels are
very costly to obtain. Methods that use both labeled and unlabeled data are
generally referred to as semi-supervised learning. This research attempts to
establish a general statistical theory for semi-supervised learning, and applies
the theory to improve state of the art machine learning algorithms.
