* 0933430
* Robust optimization of nanoparticle synthesis in a supercritical CO2 process for energy applications
* ENG,CBET
* 09/01/2009,08/31/2013
* Jye-Chyi Lu, Georgia Tech Research Corporation
* Standard Grant
* Maria Burka
* 08/31/2013
* USD 415,011.00

0933430 Grover

Systematic methods are needed to quantify uncertainty in nanomanufacturing
processes, and subsequently to design processes that are robust to these
uncertainties. Nanoscale phenomena present a new challenge for manufacturing,
due to the inherent stochastic dynamics, in addition to sensitivities to
macroscopic process inputs like temperature and pressure. However, processes are
currently being developed to take advantage of the new discoveries and
advancements in nanoscience, and cost-effective engineering approaches and tools
are needed to more efficiently explore the design space to develop
nanotechnology-enabled products. In this work the PIs focus on the synthesis of
metal nanoparticles, which are used in a wide range of applications from energy
to medicine. For example, nanoparticles of controlled size and size distribution
are needed to create high performance catalysts for NOx treatment in diesel
engines, which produce lower CO2 emissions relative to gasoline engines.
However, developing a high-throughput manufacturing process to create durable
supported catalysts in a cost-effective manner has been elusive, in part due to
design tradeoffs like higher performance but lower durability at smaller
nanoparticle size. Moreover, significant variability exists both within a single
batch of nanoparticles, due to the inherent distribution of particle nucleation
times, and also between batches, due to drift in operating conditions and noise
variables.

This project is a comprehensive methodology for robust optimization of a batch
process, using various sources of information integrated by a rigorous Bayesian
method. First, mechanistic models of mean process behaviors, as is common in the
engineering disciplines, will be developed. Since models of nanoscale phenomena
are typically not accurate within manufacturing tolerances, mechanistic models
will be supplemented with stochastic components linking within- and between-
batch variations to controllable process parameters and noise variables for
robust process design. Expert opinions help model trends and expected variance
for upgrading the models into a stochastic-mechanistic simulation tool. The
simulated data generated will be used to build a statistical-mechanistic model,
which is less complex than the simulation model, suitable for efficient
exploration of process recipes. Then, physical data will be collected based on
optimal experimental design plans developed to validate and improve the
statistical-mechanistic model. Finally, the refined model will be used to cost-
effectively search for the optimized process recipe, to achieve the desired
nanoparticle size with a narrow size distribution while minimizing batch-to-
batch variation.

Intellectual merit. The current disconnect between the fields of robust design
in statistics and mechanistic modeling in engineering will be bridged by this
methodology. Incorporating all sources of information on mean behavior and
variance requires domain-specific knowledge and mechanistic understanding. This
modeling approach for mean and variance of process variables is required to
derive the recipe for a robust optimal process.

Broader impact. The PI team is uniquely equipped to develop this new methodology
for robust process optimization. They combine expertise in experiments,
mechanistic modeling, process control, and experimental design, along with our
close collaborations with industry. The diverse team of faculty and students
(graduate, undergraduate, and high school) who will participate in the project
will gain experience and insight that will allow them to work in
interdisciplinary nanomanufacturing environments.