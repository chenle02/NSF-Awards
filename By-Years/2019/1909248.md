* 1909248
* CHS: Small: Collaborative Research: Improving Mobile Device Input for Users who are Blind or Low Vision
* CSE,IIS
* 10/01/2019,09/30/2023
* Keith Vertanen, Michigan Technological University
* Standard Grant
* Ephraim Glinert
* 09/30/2023
* USD 225,663.00

Smartphones are an essential part of everyday life. But for people with visual
impairments, basic tasks like composing text messages or browsing the web can be
prohibitively slow and difficult. The goal of this project is to develop
accessible text entry methods that will enable people with visual impairments to
enter text at rates comparable to sighted people. This project will design new
algorithms and feedback methods for today's standard text entry approaches of
tapping on individual keys, gesturing across keys, or dictating via speech. The
project aims to help users avoid errors by enabling more accurate input via
audio and tactile feedback, help users find errors by providing audio and visual
annotation of uncertain portions of the text, and help users correct errors by
combining the probabilistic information from the original input, the correction,
and approximate information about an error's location. Improving text entry
methods for people who are blind or have low vision will enable them to use
their mobile devices more effectively for work and leisure. Thus, this project
represents an important step to achieving equity for people with visual
impairments. &lt;br/&gt;&lt;br/&gt;This project will contribute novel interface
designs to the accessibility and human-computer interaction literature. It will
advance the state-of-the-art in mobile device accessibility by, first, studying
text entry accessibility for low vision in addition to blind people. Next, the
researchers will study and develop accessible gesture typing input methods.
Finally, the project will develop accessible speech input methods. This project
will produce design guidelines, feedback methods, input techniques, recognition
algorithms, user study results, and software prototypes that will guide
improvements to research and commercial input systems for users who are blind or
low-vision. Further, the project's work on the error correction and revision
process will improve the usability and performance of touchscreen and speech
input methods for everyone.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.