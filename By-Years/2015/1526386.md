* 1526386
* SHF: Small: Techniques and Frameworks for Exploiting Recent SIMD Architectural Advances
* CSE,CCF
* 07/01/2015,06/30/2020
* Gagan Agrawal, Ohio State University
* Standard Grant
* Almadena Chtchelkanova
* 06/30/2020
* USD 449,999.00

Single Instruction Multiple Data (SIMD) parallelism has been available in common
processors for several decades now, and has been widely exploited for dense
matrix and other regular problems. Recent architectural trends, such as
increasing width of SIMD lanes coupled with instruction sets, provide
significantly enhanced functionality. There is a need to effectively use the new
architectural features for dynamic or irregular applications, which have not
been easy to perform on parallel on SIMD processors in the past.
&lt;br/&gt;&lt;br/&gt;The PI proposes comprehensive research program on mapping
various classes of unstructured and/or irregular applications to modern SIMD
novel architectural features and developing optimized compiler transformations
from programs written in CUDA and OpenCL. This research proposal proposes to
address the challenge of developing and executing unstructured and/or irregular
applications using novel SIMD processors' instructions such as scatter and
gather. The PI plans to design compiler transformation methods from CUDA and
OpenCL programs to increase the number of contiguous accesses and decrease the
number of cache lines from which data needs to be accessed. These novel
transformation methods are targeting applications such as unstructured grid
kernels, sparse matrix computations, and graph and tree traversals. The PI plans
to continue development of an Operator Overloading based library.