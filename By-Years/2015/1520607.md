* 1520607
* SBIR Phase I:  Authoring tools for rapid high quality complex assessments for Next Generation Science Standards
* TIP,TI
* 07/01/2015,12/31/2015
* Rajesh Jha, SimInsights Inc
* Standard Grant
* Glenn H. Larsen
* 12/31/2015
* USD 0.00

This SBIR Phase 1 project will research the feasibility of novel tools for
authoring; distributing and scoring high quality game based complex performance
assessments for Next Generation Science Standards, ultimately targeting the
entire K-12 science segment of nearly 54 million students in the US. US science
education is facing critical challenges in terms of global competitiveness.
Designed to meet these challenges, Next Generation Science Standards call for
major changes in assessments. Historically, the development life cycle of
assessments, particularly for measuring complex learning, has required
significant amount of time and resources. In addition, the design, development,
and validation of complex measures of content and cognition can be expensive and
take many months. Similarly, creation of simulations and games is also very
expensive. Software systems that enable the authoring of large numbers of high
quality game based assessments will accelerate assessment development and
innovation, reduce costs, enhance teacher proficiency and buy-in, and also
positively impact instruction and curriculum by providing valuable feedback on
student learning progression. Highly engaging assessments will potentially help
students realize where they need to focus their efforts without the pressure of
typical tests, thereby increasing learning and self-efficacy outcomes and
significantly increasing the number of students who decide to pursue science and
engineering degrees and careers.&lt;br/&gt;&lt;br/&gt;This SBIR proposal seeks
to simultaneously satisfy several important assessment requirements including
quality, development cost, student engagement, easy authoring and teacher buy-in
by creating a novel game based assessment authoring system. The proposed
approach will investigate a middle path between two alternatives. The
traditional approach involves assessment item development by professionals.
While the resulting items are of high quality, they are also expensive and lack
teacher buy-in and student engagement. In contrast, another approach calls for
teachers to develop and test new items without much expert guidance. These
items, while authentic and low-cost, can have quality problems. The proposed
research will investigate authoring tools that offer teachers the freedom to
exercise their creativity in authoring authentic assessments, while also
providing expert guidance to significantly increase the probability that the
assessments are of high quality and generate trustworthy formative feedback. The
proposed system will also automatically measure and score students' performances
using techniques from psychometrics and educational data mining to rapidly
produce actionable insights to guide the next best instructional steps. The
proposed authoring tools and resulting assessments will be validated with
usability, classroom and crowdsourcing studies.