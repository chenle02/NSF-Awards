* 2122961
* Grounding computational models of vision with infant brain data
* SBE,BCS
* 09/01/2022,08/31/2025
* Laurie Bayet, American University
* Standard Grant
* Jonathan Fritz
* 08/31/2025
* USD 577,409.00

How do children learn to recognize visual objects? They soon learn to recognize
a cat or a cup or the faces of their family very quickly, often with no apparent
effort. Human vision is one of the most complex systems in our body. Almost half
of our brains are devoted to the visual system. Neuroscientists have a deep
interest in understanding visual perception as an important sensory window to
the world and as a key domain of human intelligence. Computer scientists are
also interested in understanding human vision to gain insights that may help
develop better computer vision systems. Artificial neural networks (ANNs) - a
form of artificial intelligence - can be trained to recognize visual objects as
well. Thus, while understanding human vision may have implications for computer
vision, the converse is also possible and hence ANNs have been proposed as a
model to understand human vision. However, ANN models do not yet fully match or
explain human vision. For example, ANN models are trained in fundamentally
different ways from how humans learn from infancy and beyond. One way to train a
computer to recognize visual objects, such as cats, is to give it millions of
images of cats that have been labeled. However, children can learn to recognize
cats after only a few short encounters. Thus, to better model human vision, we
need to know how vision develops in human infants. The goal of the research in
this project will be to study how the infant brain represents visual objects.
Data and tools developed as part of the project will be shared with other
scientists to stimulate further research in this field. The project will also
involve undergraduate and graduate students as well as outreach to K-12
students, STEM teachers, and local families.&lt;br/&gt;&lt;br/&gt;This project
aims to jointly inform artificial models of human vision, enhance computer
vision and advance our understanding of the infant brain. Researchers will use
the safe and non-invasive technique of EEG (electro-encephalography) to measure
brain activity in infants (12-15 months old). The first aim of the research will
be to compare how infants and ANNs represent visual objects. The EEG data will
be analyzed using multivariate pattern analysis (MVPA) and representational
similarity analysis (RSA) in relation to predictions from different artificial
neural network (ANN) models. A second aim will be to explore how infants
represent visual objects in the context of partly hidden objects. A related aim
is to discover how spoken words, and linguistic representation, can influence
object recognition. Infants will be presented with whole or partially occluded
images of objects, after hearing a congruent spoken cue or an incongruent cue.
Congruent words are predicted to enhance visual processing for partial images,
an indication of recurrent or top-down processing. This will test the hypothesis
that top-down factors shape how the infant brain represents visual objects.
Findings from this research may ultimately contribute to the design of more
human-like artificial intelligence in the domain of visual perception. The
studies in this project will also build bridges between computational and
developmental neuroscience and machine learning and computer vision. For
developmental researchers, the proposed methods (MVPA) provide a new and
promising tool for the analysis of infant EEG data and results will offer a
fresh angle for understanding infantsâ€™ visual processing. For researchers in
computational neuroscience, results from the project offer an exciting
opportunity to align a wide-spread goal, developing neural networks that learn
like the human brain learns, to actual data from the learning infant
brain.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has
been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.