* 2330862
* HCC: Medium: A novel neural interface for user-driven control of rehabilitation of finger individuation
* CSE,IIS
* 10/01/2022,11/30/2025
* Xiaogang Hu, Pennsylvania State Univ University Park
* Standard Grant
* Ephraim Glinert
* 11/30/2025
* USD 749,709.00

Following a stroke incident, a majority of stroke survivors lose the ability to
use their hand to perform a variety of tasks despite months of therapy. In an
effort to restore hand dexterity, advanced assistive devices (e.g.,
exoskeletons) have been developed. Unfortunately, only few of these novel
devices have been used effectively by stroke survivors. One critical factor
limiting user acceptance is the lack of reliable method that allows stroke
survivors to intuitively control the device. The overarching objective of the
project is to combine novel decoding of neurological signals that drive the
muscles with a personalized musculoskeletal model of the upper limb to provide
intuitive control of an assistive hand exoskeleton. The control strategy will be
robust in handling different arm postures and movements. This personalized
approach will improve hand functional performance in stroke survivors, with the
overall goal of improving their ability to live independently. The computational
approaches employed here will also produce a research tool to study human-robot
interactions. The researchers will make the computational model available over
online repository system, SimTK.org, as a simulation platform for other
researcher working on hand function and control of rehabilitative devices. The
project will provide educational and training opportunities. The research
concepts will be integrated into existing courses. Summer projects incorporating
the techniques will be offered to undergraduate and high school students and
local school and community college instructors. Outreach programs will be
developed to disseminate the proposed research outcomes to underrepresented
students.

The goal of this project is to develop a personalized hybrid (neural data-based
and model-based) interface that combines the decoded neural command with a
musculoskeletal model. The developed interface will be used to control a soft-
hard hybrid exoskeleton to enable dexterous finger movements in stroke
survivors. The research team will first develop a real-time neural decoding
algorithm based on populational firing probability of the motoneurons, extracted
from motor unit decomposition of high-density electromyographic (HD-EMG)
signals. Through incorporation of binary neuron discharge events, the decoded
neural drive signals will be robust to changes in muscle activity features,
background noise, and motion artifact. The research team will then employ a
personalized musculoskeletal model of the limb, which will be calibrated to the
unique musculoskeletal structure and activation parameters of stroke survivors.
The model-based controller will be able to compensate for limb posture, movement
dynamics, and subject-specific impairments that could otherwise disturb the
mapping between user input and desired output. Finally, the research team will
evaluate the developed interface for control of an advanced hand exoskeleton,
allowing users to control flexion or extension assistance independently for each
digit. The assistive forces will reinforce beneficial muscle activation while
compensating for abnormal activation patterns. Collectively, the outcomes will
restore hand dexterity in stroke survivors, thereby enabling them to perform
daily activities and live independently.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.