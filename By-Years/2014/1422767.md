* 1422767
* RI: Small: Using Prediction to Build a Compact Visual Memex Memory for Rapid Analysis and Understanding of Egocentric Video Data
* CSE,IIS
* 09/01/2014,08/31/2018
* Kayvon Fatahalian, Carnegie-Mellon University
* Continuing Grant
* Maria Zemankova
* 08/31/2018
* USD 450,000.00

This project develops new data-driven techniques for egocentric (first-person)
video stream analysis that exploit the structure and redundancy in streams
captured over days, months, and even years, to significantly reduce the size of
these datasets without losing the most useful visual information.
Simultaneously, the research team is developing parallel programming frameworks
that simplify expression and acceleration of these video analysis algorithms at
scale. While the focus of this research is the design of core algorithms and
systems, success stands to enable the development of new classes of applications
(in domains such as navigation, personal assistance, health/behavior monitoring)
that use the extensive visual history of a camera to intelligently interpret
continuous visual data sources and immediately respond to the observed input. A
further output of this research is the collection and organization of a large
egocentric video database from the life of a single
individual.&lt;br/&gt;&lt;br/&gt;The core idea of this research is to identify
and exploit redundancy in everyday life. While it is not tractable to maintain
an easily analyzable representation of all video ever seen by a camera, it is
likely possible to identify and provide future applications fast access to the
most important visual information. The challenge is to determine what visual
data is the most important. This work explores the use of video stream
predictability as a notion of importance. Specifically, the vast visual history
of the camera (e.g., life experiences captured by a head-mounted camera) is used
to make predictions about what the camera will see next, and the accuracy of
these predictions dictates what data is retained. (Highly predictable
occurrences are judged to be less valuable to retain in the database.) In
addition, this research is characterizing the structure of always-on egocentric
video streams (What is the "working set" of a person's day? How much novel
information is collected from day to day?), leveraging this structure to inform
the design of new algorithms for video corpus analysis (data compression,
accelerated retrieval), and exploring the design of specialized programming
abstractions for authoring visual data understanding applications at
scale.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;URL:
http://graphics.cs.cmu.edu/projects/egocentricPrediction