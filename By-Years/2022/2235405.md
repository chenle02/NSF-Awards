* 2235405
* NSF Convergence Accelerator Track H: AI-based Tools to Enhance Access and Opportunities for the Deaf
* TIP,ITE
* 12/15/2022,11/30/2023
* Dimitris Metaxas, Rutgers University New Brunswick
* Standard Grant
* Pradeep Fulay
* 11/30/2023
* USD 750,000.00

We propose to develop sustainable, robust AI methods to overcome obstacles to
digital communication and information access faced by Deaf and Hard-of-Hearing
(DHH) individuals, empowering them personally and professionally. Users of
American Sign Language (ASL), which has no standard written form, lack parity
with hearing users in the digital arena. The proposed tools for privacy
protection for ASL video communication and video search-by-example for access to
multimedia digital resources build on prior NSF-funded AI research on
linguistically-informed computer-based analysis and recognition of ASL from
videos.&lt;br/&gt;PROBLEM #1. ASL signers cannot communicate anonymously about
sensitive topics through videos in their native language; this is perceived by
the Deaf community to be a serious problem.&lt;br/&gt;PROBLEM #2. There is no
good way to look up a sign in a dictionary. Many ASL dictionaries enable sign
look-up based on English translations, but what if the user does not understand
the sign, or does not know its English translation? Others allow for search
based on properties of ASL signs (e.g., handshape, location, movement type), but
this is cumbersome, and a user must often look through hundreds of pictures of
signs to find a target sign (if it is present at all in that
dictionary).&lt;br/&gt;&lt;br/&gt;The tools to be developed will enable signers
to anonymize ASL videos while preserving essential linguistic information
conveyed by hands, arms, facial expressions, and head movements; and enable
searching for a sign based on ASL input from a webcam or a video
clip.&lt;br/&gt;&lt;br/&gt;Participants include DHH individuals, Deaf-owned
companies, and members of other underrepresented minorities. The products will
serve the &gt;500,000 US signers and could be extended to other sign languages.
The proposed application development brings together state-of-the-art research
on: (1) video anonymization (using an asymmetric encoder-decoder structured
image generator to generate high-resolution target frames driven by the original
signing from the low-resolution source frames for anonymization, based on
optical flow and confidence maps); (2) computer-based sign recognition from
video (bidirectional skeleton-based isolated sign recognition using Graph
Convolution Networks); and (3) HCI, including DHH user studies to assess
desiderata for user interfaces for the proposed
applications.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission
and has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.