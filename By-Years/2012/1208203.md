* 1208203
* CRCNS: Cortical representation of phonetic, syntactic and semantic information during speech perception and language comprehension
* CSE,IIS
* 10/01/2012,09/30/2017
* Frederic Theunissen, University of California-Berkeley
* Continuing Grant
* Kenneth Whang
* 09/30/2017
* USD 888,774.00

The overarching goal of this project is to discover how language-related
information is represented and processed in the human brain. To address this
issue we propose to use a novel computational modeling approach, voxel-wise
modeling. Voxel-wise modeling draws from the principles of nonlinear system
identification, and it provides an efficient method for using complex data sets
collected under naturalistic conditions to test multiple hypotheses about
language representation. The specific research plan is divided into three aims,
each targeted at a different form of language-related information. Aim 1 will
reveal how low-level features of speech, such as spectral power, spectral
modulation and phonemic structure, are represented across human cortex. Subjects
will passively listen to human speech while hemodynamic brain activity is
recorded by functional MRI. Voxel-wise modeling will then be used to determine
how each point in the brain (i.e., each voxel, or volumetric pixel) is tuned for
these various features. Using analogous methods, Aim 2 will reveal how syntactic
and semantic features are represented across cortex. Finally, Aim 3 will reveal
how language-related information is represented when it is delivered by auditory
versus visual modalities. In this case speech and video stimuli will be used.
Separate models will be estimated for data recorded during auditory and visual
stimulation, and voxel-wise tuning will be compared across modalities. The
voxel-wise computational models developed under this proposal will reveal how
these various types of language-related information are represented across the
cortical surface. These models will also provide clear predictions about how the
brain will respond to novel speech stimuli. The results of the proposed research
will have broad impacts on clinical problems related to speech perception and
production, and they could form the basis of powerful brain decoding device that
would enable neurological patients to communicate by thought alone.