* 2318926
* ATD:Understanding Adversarial Examples in Neural Network: Theory and Algorithms
* MPS,DMS
* 09/01/2023,08/31/2026
* Teng Zhang, The University of Central Florida Board of Trustees
* Standard Grant
* Tomek Bartoszynski
* 08/31/2026
* USD 240,000.00

While neural network-based models have shown exceptional power and versatility,
their robustness against adversarial examples, which are inputs deliberately
designed to mislead the model, has become a major area of concern. Adversarial
training is currently the most widely used method to improve the robustness of
neural networks against adversarial perturbations, but this approach has been
found to have limitations, such as overfitting. In addition, the understanding
of both attacks and adversarial training is still limited. In light of these
challenges, this research aims to develop a theoretical analysis that sheds
light on the robustness of neural network-based methods and the properties of
adversarial training. This understanding is essential to the design of effective
attack strategies and defense mechanisms for various machine learning models.
This research has the potential to have a significant impact on a wide range of
fields, such as cybersecurity, computer vision, natural language processing,
healthcare, and financial services, where machine learning models play a crucial
role. The proposed project aims to contribute to the development of robust
neural network-based models and algorithms through novel theoretical studies.
Unlike existing works that primarily focus on the generalization error of the
neural network algorithms, this project will focus on the robustness and
stability. The research will leverage a range of mathematical and computational
techniques, including statistical learning theory, random matrix theory,
reproducing kernel Hilbert space, and optimization. The investigation of
robustness will lead to the development of novel algorithms that are less
vulnerable to adversarial attacks and can be implemented with greater security
and stability

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.