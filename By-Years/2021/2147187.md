* 2147187
* FAI: A Normative Economic Approach to Fairness in AI
* CSE,IIS
* 03/01/2022,02/28/2025
* Ariel Procaccia, Harvard University
* Standard Grant
* Todd Leen
* 02/28/2025
* USD 560,345.00

A vast body of work in algorithmic fairness is devoted to preventing artificial
intelligence (AI) from exacerbating societal biases. The predominant viewpoints
in this literature equates fairness with lack of bias or seeks to achieve some
form of statistical parity between demographic groups. By contrast, this project
pursues alternative approaches rooted in normative economics, the field that
evaluates policies and programs by asking "what should be". The work is driven
by two observations. First, fairness to individuals and groups can be realized
according to people’s preferences represented in the form of utility functions.
Second, traditional notions of algorithmic fairness may be at odds with welfare
(the overall utility of groups), including the welfare of those groups the
fairness criteria intend to protect. The goal of this project is to establish
normative economic approaches as a central tool in the study of fairness in AI.
Towards this end the team pursues two research questions. First, can the
perspective of normative economics be reconciled with existing approaches to
fairness in AI? Second, how can normative economics be drawn upon to rethink
what fairness in AI should be? The project will integrate theoretical and
algorithmic advances into real systems used to inform refugee resettlement
decisions. The system will be examined from a fairness viewpoint, with the goal
of ultimately ensuring fairness guarantees and welfare.&lt;br/&gt;&lt;br/&gt;The
research plan includes two main directions based on previous work has shown that
classifiers incorporating parity-based fairness criteria can be Pareto
inefficient. That is, the welfare of all groups—including the protected
group—would be higher under a classifier that is less fair. In the first
direction, the project extends this observation to non-convex problems and then
from in-processing to post-processing bias mitigation. The planned research will
also study the interaction between multiple policy makers and its impact on
social goals such as fairness and welfare. In the second direction, the project
develops a new conceptualization in which classifiers are viewed as public
resources or goods. This work then draws on ideas from fair division, a long-
established branch of normative economics that defines and applies rigorous
notions of fairness, and on the specific notion of the core. To put this idea
into practice, there are several challenges that must be addressed: conditions
for the existence of classifiers in the core, algorithms for their computation,
and generalization from a training set.&lt;br/&gt;&lt;br/&gt;This award reflects
NSF's statutory mission and has been deemed worthy of support through evaluation
using the Foundation's intellectual merit and broader impacts review criteria.