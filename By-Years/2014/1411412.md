* 1411412
* Studies in Adaptive and Optimal Control of Stochastic Systems
* MPS,DMS
* 09/01/2014,08/31/2020
* Tyrone Duncan, University of Kansas Center for Research Inc
* Standard Grant
* Victor Roytburd
* 08/31/2020
* USD 310,000.00

A large number of processes and physical phenomena in science and engineering
have to contend with uncertainties in the measurements of the data or the forces
that drive the system. Such situations are described by stochastic systems,
where suitable assumptions are made about the stochastic nature of the unknown
parameters and forcing in the system. Frequently, one is interested in
controlling the system through control parameters or forcing with the goal of
optimizing a given "cost" functional. For example, in the context of finance,
the net worth is described by an stochastic differential equation, the controls
are the shares placed in the various assets, and the goal is to optimize a
functional of the net worth. The goal of this research is the study of optimal
control and adaptive control of stochastic systems. The solutions of such
problems require algorithms for parameter identification and the determination
of explicit optimal controls. The noise processes used in this project are
empirically determined and belong to a class of fractional Brownian motions. In
addition to the investigation of problems of stochastic optimal and adaptive
control some problems of two-person zero-sum stochastic differential games will
be studied. These games can model many situations of two competing players or
interest groups so they often arise. These stochastic problems in control and
differential games will be studied for both continuous and discrete time
systems. The proposal will also engage undergraduate and graduate students, as
well as high school students, in research on stochastic problems.

Stochastic optimal control problems for a variety of systems, cost functionals,
and noise processes will be studied with the particular emphasis on obtaining
explicit optimal controls. The proposers have developed a method that does not
require solving Hamilton-Jacobi-Bellman equations or using a stochastic maximum
principle and can be applied to systems with general noise processes that are
not Markov or semimartingales. The systems include both discrete and continuous
time and linear and nonlinear systems. Two person zero sum stochastic
differential games will also be investigated for both linear and nonlinear
equations to determine explicit optimal control strategies for the two players
by a direct method. Since stochastic systems often contain unknown parameters,
the problems of adaptive control, which connote the simultaneous identification
of parameters and the control of the system will be investigated for linear
systems with ergodic (long run average) quadratic and exponential quadratic cost
functionals and noise processes that are fractional Brownian motions or other
processes with stationary increments. The stochastic systems for control to be
studied are both finite dimensional and infinite dimensional. The infinite
dimensional systems that evolve in Hilbert spaces can model both parabolic and
hyperbolic stochastic partial differential equations with fractional Brownian
motion noise. The control and the noise can be restricted to the boundary of the
domain or to discrete points in the domain.