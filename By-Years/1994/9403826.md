* 9403826
* Mathematical Sciences:  Computer-Intensive Methods for the  Statistical Analysis of Time Series and Random Fields
* MPS,DMS
* 09/01/1994,10/31/1997
* Joseph Romano, Stanford University
* Continuing Grant
* James E. Gentle
* 10/31/1997
* USD 75,000.00

The statistical analysis of time series and random fields is vital in many
diverse scientific disciplines. The general goal of this project is to develop
methods of inference for the analysis of time series and random fields that do
not rely on unrealistic or unverifiable model assumptions. Typical inferential
methods in the data-dependent setting rest upon strong assumptions. In contrast,
bootstrap resampling or computer-intensive methods offer viable approaches to
obtaining valid distributional approximations while assuming very little about
the stochastic mechanism generating the data. Many important questions need to
be addressed in order for these modern approaches to be applied safely in
practice. The main issues we wish to tackle include the following: finding
general conditions for asymptotic validity of computer-intensive methods,
especially subsampling, in the presence of nonstationarity; higher-order
comparison of block-resampling and subsampling; developing computationally
efficient and accurate estimates of standard error, and the corresponding
improvement on confidence regions for parameters of interest; optimal choice of
design parameters, such as block size, as well as practical guidelines for
implementation; assessing goodness of fit in time series settings; and finally
interval estimation with lattice or non-lattice random field data. Addressing
these general problems fruitfully will have many practical applications.
Applications of statistical methods for time series and spatial data are well-
known and numerous, especially in the fields of physics, engineering, acoustics,
geostatistics, medicine, econometrics, ecology, forestry, seismology and others.
The general purpose of this research proposal is to develop inferential methods
for dependent data that does not rely on strong model assumptions. These methods
are computer-intensive, very generally applicable, flexible, and offer solutions
to problems when there are no alternatives; how ever, further mathematical study
of these procedures is needed in order to fully under their potential and
limitations.