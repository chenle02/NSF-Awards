* 2120506
* Sensorimotor adaptation as a window to speech movement planning
* SBE,BCS
* 09/01/2021,08/31/2024
* Benjamin Parrell, University of Wisconsin-Madison
* Continuing Grant
* Betty Tuller
* 08/31/2024
* USD 596,698.00

Speaking is normally thought of as a two-part process. First, a language
planning system transforms ideas, concepts, and/or words into a series of
smaller units, such as syllables or speech sounds. These basic linguistic units
are then thought to be “read out” into articulatory movements by a separate
motor planning system. However, this divided planning process cannot explain
speech production in the real world, because it is possible to learn changes to
speech movements that are dependent on language context. For example, if you
move from California to Wisconsin, you may learn a new accent: you may
unconsciously start saying “bag” with the vowel sound in “say” instead of the
vowel sound in “sat”. If the same change occurred in all words with this sound
(“snag”, “dragon”, “agriculture”), it would suggest you learned a change to the
smaller unit (“ag”). However, you might change the way you say “bag” while
keeping your old pronunciation of “bagpipe”, suggesting learning that is
dependent on word context. The purpose of this research is to understand when
linguistic context influences learning and when it does not and to use those
results to determine the span of speech motor planning in different contexts. A
more accurate characterization of speech motor planning is critical for
understanding how we typically speak and how this process breaks down in
neurological disorders that impair the way we plan speech movements, such as
aphasia and apraxia of speech. The investigators are involved with Frontiers for
Young Minds, a journal that aims to engage the next generation of scientists
(kids ages 8-15) by involving them in the peer review process. They will host
live demonstrations at the yearly Wisconsin Science Festival, and will provide
hands-on science experiences as a part of summer and afterschool programming for
Madison-area kids. &lt;br/&gt;&lt;br/&gt;To investigate how speech movements are
planned, the investigators will use a speech learning task that causes an
unconscious change to pronunciation. Participants will talk into a microphone
while hearing playback of their voice with certain frequencies shifted, making
one vowel sound like another (for example, “bed” could be shifted to sound like
“bad”). Over time, this causes participants to unknowingly shift their vowel
pronunciation in the opposite direction. Importantly, participants can
simultaneously learn to shift a single vowel sound in different ways based on
the word in which it appears (for example, pronouncing “bed” and “head”
differently, even though they share the same vowel sound). This shows that the
word context can differentiate planning of this vowel sound. The investigators
will test other linguistic contexts that might allow participants to learn
different pronunciations for the “same” speech sound, contexts such as word
meaning, phrase structure, pitch or intonation, and gesturing while speaking
(for example, pointing). If this learning is possible, it suggests that these
contexts are part of the movement plans for speaking, together forming a
cohesive unit that can scaffold learning. The work will establish how speech
motor planning integrates linguistic representation and other communicative
movements such as pitch and gesture.&lt;br/&gt;&lt;br/&gt;This award reflects
NSF's statutory mission and has been deemed worthy of support through evaluation
using the Foundation's intellectual merit and broader impacts review criteria.