* 2239879
* CAREER: Social Response-Powered Misinformation Detection, Robustness, and Correction
* CSE,CNS
* 05/15/2023,04/30/2028
* Srijan Kumar, Georgia Tech Research Corporation
* Continuing Grant
* Dan Cosley
* 04/30/2028
* USD 120,008.00

This project will invent methods to detect and correct misinformation on online
platforms. Online misinformation poses an alarming threat to public health,
democracy, science, and society. Addressing misinformation at scale remains a
pressing challenge as current solutions rely on the limited resources of
professional fact-checkers or moderators, which neither scales to newly emerging
information issues nor directly addresses how to respond to misinformation in
situ. This project will address these challenges through developing robust
detection models that leverage user-generated responses to social media posts to
identify potentially non-credible information. The team will also design a
counter-response generation tool that can help everyday users effectively
respond to misinformation, leveraging the models developed along with existing
fact-checking resources and best practices in communication to suggest possible
responses to incorrect posts that will help readers assess them. Together, the
proposed work will boost information literacy in society and reduce the number
of people exposed to misinformation. The team will also develop
interdisciplinary coursework and research opportunities that will broaden both
studentsâ€™ toolkits for addressing misinformation in social media systems and the
range of students who engage in it.&lt;br/&gt;&lt;br/&gt;This project will
advance scientific knowledge in misinformation, graph neural networks,
adversarial learning, and social network analysis. The general approach is to
leverage the social responses that ordinary users make on online posts, such as
supporting, questioning, disbelieving, or countering claims, to robustly detect
misinformation and suggest corrective responses. Around detection, the project
will develop novel signed dynamic graph neural network models and network
augmentation methods to address network sparsity issues. Around robustness, the
project will create detection models that are robust to adversarial
manipulation, by better modeling adversarial attacks carried out by groups of
attackers, then creating defenses that optimize against fake response injections
into social media comments. Around correction, the project seeks to empower
social media users to correct misinformation by developing text generation
methods to suggest effective counter-responses to posts estimated to contain
information; these methods will be trained on data collected from professional
fact-checking organizations and assessed in a series of studies. The project
will also result in new models, datasets, benchmarks, and tools around
misinformation that will promote future research on these
topics.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has
been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.