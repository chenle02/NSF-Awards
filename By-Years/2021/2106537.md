* 2106537
* Collaborative Research: HCC: Medium: Design guidelines for dynamic visualizations
* CSE,IIS
* 10/01/2021,09/30/2024
* Camillia Matuk, New York University
* Standard Grant
* Dan Cosley
* 09/30/2024
* USD 267,421.00

People rely on visualizations to understand and communicate patterns in data,
processes in diagrams, or routes within maps, in domains including journalism,
education, business, and security. These visualizations are increasingly
dynamic, using moving objects or animated patterns to show trends and
interactions in the data. In many cases these dynamic displays can help people
understand these relationships, but in some cases these dynamic elements can
overwhelm people or lead them to incorrect conclusions. Across all of these
domains, even expert designers have trouble predicting which displays will work.
Through psychology-based experiments and interviews with expert visualization
designers, this project will explore the power and limits of dynamic
visualization. It will result in a set of guidelines that will enable designers
from diverse backgrounds and levels of experience to create more effective
displays that lead to better understanding, education, and
decisions.&lt;br/&gt;&lt;br/&gt;To understand how people process and interpret
these dynamic displays, the investigators will catalog an abstracted set of
intended uses for animation across data displays (e.g., track a value across an
axis change in a graph) by interviewing designers of data displays and
validating how well their designs meet their stated goals. In collaboration with
these designers, the research team will conduct a series of empirical tests of
the power and limits of the human visual system to process the intended
patterns, with an initial set of experiments that will test the ability of
dynamic visualizations to support viewers in seeing statistics, making
comparisons, tracking objects, and drawing attention. The investigators will use
these findings to generate a practitioner’s guide for designing effective
displays for common goals. In ongoing consultations with our team of designers
and advisors, the investigators will incorporate their feedback about (a)
whether our abstracted displays, tasks, and measures remain relevant to their
in-context case studies, and (b) whether our practitioner’s guide is consistent
with their expectations and captures rules that should generalize across most
case-study contexts.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.