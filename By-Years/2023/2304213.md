* 2304213
* III: Small: RUI: A Fairness Auditing Framework for Predictive Mobility Models
* CSE,IIS
* 09/01/2023,08/31/2025
* Afra Mashhadi, University of Washington
* Standard Grant
* Sylvia Spengler
* 08/31/2025
* USD 553,536.00

Recent years have seen an increase in the use of location data collected from
devices with GPS as well as location-based social media. This type of location
data can be used for various decision-making purposes in the context of urban
computing and city planning. For instance, in the context of traffic management
and crowd flow, location data has been shown to provide immense opportunities
for understanding and predicting visitation and congestion patterns, thus
helping managers to plan resources accordingly. For a long time, privacy
concerns about location data have received attention from the research
community. Decades of research have been examining how to strip sensitive
information from location data to block the re-identification of individuals.
The success of these efforts has led to new opportunities for integrating
predictive and generative models that are based on historical location data into
decision-making tasks. However, a critical concern that arises is the extent to
which such models and analyses are representative of everyone, fair, and
equitable. Ultimately, the goal of this research is to ensure that such models
and underlying data are both private and fair.

This project aims to define a set of methods and approaches for auditing
location predictive and generative models in terms of fairness from the
perspectives of individual and collective level (i.e., crowd flow) location
data. At its core, this project will advocate a novel framework for auditing the
fairness of mobility traces and models in both centralized and distributed
systems by offering a set of domain-specific fairness metrics related to
mobility. The technical aim of this project is in two research thrusts. The
first thrust focuses on building infrastructure, knowledge, and methods for the
creation of spatial-temporal data through fair-aware generative AI models that
are inclusive and can lead to fair and equitable policy planning. The second
thrust focuses on building infrastructure, knowledge, and methods for increasing
and evaluating the fairness of Location Privacy Preserving Methods (LPPMs) by
offering a set of novel fair-aware algorithms that will satisfy the objectives
of prediction accuracy, privacy, and fairness.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.