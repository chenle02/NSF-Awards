* 1844723
* Doctoral Dissertation Research: Extending and testing theories of language production by investigating speaker choice in a classifier language
* SBE,BCS
* 03/01/2019,02/28/2021
* Roger Levy, Massachusetts Institute of Technology
* Standard Grant
* Tyler Kendall
* 02/28/2021
* USD 18,414.00

Natural language often gives speakers multiple ways to convey the same meaning.
Meanwhile, linguistic communication takes place in the face of environmental and
cognitive constraints. When multiple options are available to express more or
less the same meaning, what general principles govern speaker choice? Advancing
our understanding of this question can potentially enhance a broad array of
human language technologies, such as providing more human-like language
generation with better understanding of speaker choice, more accurate machine
translation, better resources for language learning and teaching, as well as
insights to improve treatment for language disorders.

Within this broader research program, this project focuses on the influence of
contextual predictability on the encoding of linguistic content manifested by
speaker choice in a classifier language. In English, a numeral modifies a noun
directly (e.g., three tables). In classifier languages such as Mandarin Chinese,
it is obligatory to use a classifier (CL) with the numeral and the noun (e.g.,
three CL.flat table, three CL.general table). While different nouns are
compatible with different specific classifiers, there is a general classifier
'ge' (CL.general) that can be used with most nouns. This study focuses on the
alternating options between using the general classifier versus a specific
classifier with the same noun where the options are nearly semantically
invariant. The use of a more specific classifier would reduce surprisal at the
noun, but the use of that more specific classifier may be dispreferred from a
production standpoint if accessing the general classifier requires less effort.
This project combines corpus analyses, psycholinguistic behavioral experiments
and computational modeling using techniques from statistics, natural language
processing, and experimental psychology, examining how language users allocate
resources to prepare them to produce and comprehend language, shedding lights on
why language is structured in the way it is.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.