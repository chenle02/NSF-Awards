* 1528029
* CSR: Small: Cross-Layer Design of Power Delivery and Load Balancing for Green Data Centers
* CSE,CNS
* 09/01/2015,07/31/2018
* Yi Lu, University of Illinois at Urbana-Champaign
* Standard Grant
* Marilyn McClure
* 07/31/2018
* USD 514,687.00

As ever more computing is moved to the cloud, the energy consumption of data
centers becomes increasingly important, both from an environmental and cost
viewpoint. As a result, there is an increasing trend towards reducing the energy
and carbon foot- print of data centers. While there has been considerable
efforts to reduce the energy consumption, relatively little attention has been
paid towards the power delivery in data centers. The objective of this work is
to reduce the high voltage conversion losses (currently contributing 10-15%
power loss) to almost zero by designing a joint software and hardware power
delivery architecture specifically for a multi-server environment. This
research, which could lead to drastic reduction of power conversion losses in
data centers, has far-reaching impact on the design of sustainable and green
data centers. Participation of underrepresented groups is encouraged, and
portions of the research is incorporated into cloud computing courses, as
hardware projects into a laboratory power electronics course, and as a case
study of data center power delivery in an advanced graduate level power
electronics course. An interactive online power usage portal, that visualizes in
real-time the power usage of each individual server in the test-cluster provides
opportunities for public interaction with the research. These open-source
software and hardware demonstrations enable practitioners from around the world
to learn more about sustainable computing. &lt;br/&gt;&lt;br/&gt;This research
explores a cross-layer design approach to data centers, where the power delivery
architecture and software load balancing algorithms work together to achieve the
highest possible power delivery efficiency. The research explores electrically
series-connected racks of servers, to minimize overall power conversion and
attendant losses. A key challenge in series voltage stacking is the variation in
input voltage of each server due to imbalance of computational load in a series-
stack. In this research, the challenge is addressed both in hardware and
software. In software, scalable load balancing algorithms that ensure uniform
power consumption in each server in the rack are developed. The load balancing
algorithms simultaneously optimize for response time and power loss. Moreover,
hardware power converters and distributed energy storage (e.g., capacitors,
batteries) provide filtering and power balance in cases when software alone does
not suffice. A key question being addressed is the suitable size of energy
storage, and the required control bandwidth of the power converters to ensure
proper operation for realistic workloads. In addition, high speed sensing and
communication of electrical measurements of voltage and currents are employed in
combination with operation of servers at asymmetric input voltages for static
power consumption mismatch mitigation. The load balancing algorithms is tested
with two types of workloads: (1) Interactive web workloads with short turnaround
time and homogeneous servers; and (2) Map-reduce type workloads with long
turnaround time and servers with data locality constraint.