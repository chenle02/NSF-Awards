* 1955162
* III: Medium: Collaborative Research: Evaluating and Maximizing Fairness in Information Flow on Networks
* CSE,IIS
* 10/01/2020,09/30/2025
* Carlos Scheidegger, University of Arizona
* Continuing Grant
* Sylvia Spengler
* 09/30/2025
* USD 80,415.00

Social networks (whom you know and whom you can reach) help determine access to
hiring opportunities, education, and health information. They encode social
capital based on network position, and in an era where access to information is
crucial for advancement, this social capital can be immensely valuable. In this
project, we study interventions on social networks that mitigate access
inequality, that is, differences in access to information that emerge from where
you are in the network. This project will develop novel mathematical and
computational models to characterize how differences in position in a social
network can amplify inequalities of access, and techniques to change the
structure of the network that both increase the flow of information and reduce
the overall inequities. Finally, the project will develop experimental
methodology to assess the behavior of human agents in such online social
networks to assess the validity of the designed interventions. The project will
support the mentoring and training of underrepresented populations of
undergraduate and graduate students, as well as the dissemination of the work
through open-source software repositories and event organization at the top
research venues in the field. &lt;br/&gt;&lt;br/&gt;We will develop mathematical
and computational tools for the analysis of fairness in information access on
networks. From there, we will characterize the algorithmic difficulty of
mitigating information access gaps, develop efficient estimators to predict such
gaps, and design intervention strategies to reduce these gaps. We will also
consider how to characterize clusters of people who share similar access to
information. More generally, we seek to connect the research on influence
maximization to recent work on algorithmic fairness: the study of how automated
procedures can perpetuate or exacerbate existing structural disadvantages of
marginalized groups. The algorithms and results developed through these efforts
will be evaluated using a combination of theoretical models, network
repositories maintained by the PIs, real-world social network datasets, and
experiments with volunteer participants.&lt;br/&gt;&lt;br/&gt;This award
reflects NSF's statutory mission and has been deemed worthy of support through
evaluation using the Foundation's intellectual merit and broader impacts review
criteria.