* 0901100
* Collaborative Research:   Methods for Analyzing Large Dimensional Data
* SBE,SES
* 08/15/2008,05/31/2010
* Serena Ng, Columbia University
* Continuing Grant
* Nancy Lutz
* 05/31/2010
* USD 51,612.00

Economists are fortunate to have access to lots of data, but the econometric
tools that can be used to digest all the information remain rather limited. The
standard assumption underlying asymptotic analysis that treats N (number of
cross-section units) as fixed and let T (the number of time series observations)
to tend to infinity is no longer appropriate for analyzing large data panels.
The theme of the PIs research is efficient use of information in a large panel
of data, say, X. The PI's work will be organized around three projects. Project
A continues the PIs previous work in using factor models to reduce the dimension
of X. With N large, there is a need to carefully downweigh noisy data. The more
difficult problem is to deal with the cross-section correlation in idiosyncratic
errors that are not pervasive enough to be called common factors, but are strong
enough to adversely affect the precision of the estimated common factors. In
this grant, the PI's seek to develop more efficient principal component
estimators to deal with both problems. Project B continues to exploit the
relevant information in X, but now the goal is to predict some series, y, and
the PI's step outside of the factor framework. The problem here is to pick out a
set of reasonably strong predictors for y, but that the predictors are not very
highly correlated with each other, or else there will be too much information
overlap. The PI's will use penalized regressions to study optimal shrinkage. The
goal is to establish data dependent rules for the penalty parameters in a time
series setting. For example, stationary and non-stationary predictors will be
penalized at different rates. Both in and out-of-sample predictions will be
considered. Project C aims to develop an efficient estimator for panel
cointegration in the presence of cross- section common shocks, which drive the
comovement of economic variables. The framework allows for cross-sectionally
correlated errors and encompasses the fixed effects model as a special case.
Broader Impact and Intellectual Merit Standard principal component estimates are
now used in many forecasting exercises and in policy analysis. Improved factor
estimates will inevitably impact these work. Project A should lead directly to
better estimates for the number of factors, which has a natural role in asset
pricing models and in demand analysis. In addition to providing results of
immediate use to forecasters, Project B also impacts macroe- conomic analysis,
as many economic models involve expectational variables. Economic hypotheses
cannot be fairly tested when the forecasts/conditional expectations are not
properly modelled. Fur- thermore, instead of predicting y, a researcher might
just want to predict if y is higher, lower, or stays the same. The many
predictors framework is potentially useful in broader contexts. When working
with economic data, the assumption that the errors are iid across units is un-
appealing. Project C tackles efficient estimation when the errors are cross-
sectionally correlated. The results will be useful for economic analysis
involving data for countries/industries/firms.