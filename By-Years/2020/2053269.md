* 2053269
* CRII: RI: Learning with Low-Quality Visual Data: Handling Both Passive and Active Degradations
* CSE,IIS
* 08/01/2020,07/31/2021
* Zhangyang Wang, University of Texas at Austin
* Standard Grant
* Jie Yang
* 07/31/2021
* USD 77,253.00

This project is focused on effectively and robustly exploiting low-quality (LQ)
visual data for computer vision tasks. While most current computer vision
systems are designed for high-quality visual data, collected from "clear"
environments where subjects are well observable without significant attenuation
or alteration, a dependable vision system must reckon with the entire spectrum
of degradations from unconstrained environments. With various degradations
arising from the visual data acquisition and processing pipeline, the ubiquitous
LQ visual data can dramatically deteriorate the model performance in practice.
The project outcome can broadly benefit a variety of real-world applications,
such as video surveillance, autonomous/assisted driving, robotics and medical
image analysis, where LQ visual data has constituted major performance and
reliability bottlenecks. &lt;br/&gt;&lt;br/&gt;This research categorizes common
degradations into the two types: "passive degradations" that are caused by
uncontrollable environment factors (such as bad weather and low light); and
"active degradations" that are intentionally introduced in a controllable way to
meet certain budget requirements (such as lossy compression). The project will
mainly addresses two important technical questions: i) how to overcome passive
degradations and achieve more robust high-level task performance on LQ video
data, using end-to-end deep learning models; and ii) how to properly introduce
and control active degradations to generate the desired form of LQ data, that
both satisfies certain budget requirements and maintains the target task
utility, using deep adversarial learning models. The resulting new techniques
are to be verified on application examples such as video recognition, video
annotation, video compression, and de-identified video data sharing for
recognition purpose.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.