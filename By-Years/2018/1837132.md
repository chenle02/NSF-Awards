* 1837132
* FMitF: Collaborative Research: Formal Methods for Machine Learning System Design
* CSE,CCF
* 10/01/2018,09/30/2023
* Sanjit Seshia, University of California-Berkeley
* Standard Grant
* Pavithra Prabhakar
* 09/30/2023
* USD 294,000.00

Machine learning (ML) algorithms, fueled by massive amounts of data, are
increasingly being utilized in several critical domains, including health care,
finance, and transportation. Models produced by ML algorithms, for example deep
neural networks, are being deployed in these domains where trustworthiness is a
big concern. It has become clear that, for such domains, a high degree of
assurance is required regarding the safe and correct operation of ML-based
systems. This project seeks to provide a systematic framework for the design of
ML systems based on formal methods. The project seeks to review and improve
almost every aspect of the design flow of ML systems, including data-set design,
learning algorithm selection, training of ML models, analysis and verification,
and deployment. The theory and ideas generated during the project will be
implemented in a new software toolkit for the design of ML systems in the
context of cyber-physical systems.&lt;br/&gt;&lt;br/&gt;The project focuses on
cyber-physical systems (CPS), which is a rich domain to apply formal methods
principles. Moreover, the research ideas from this project can be readily
applied to other contexts. A key aspect of this research is the use of a
semantic approach to the design and analysis of ML systems, where the semantics
of the target application and a formal specification for the full system,
comprising the ML component and other components, are cornerstones of the design
methodology. The project employs a range of formal methods, including
satisfiability solvers, simulation-based verification, model checking,
specification analysis, and synthesis to improve all stages of the ML design
flow. Formal techniques are also used for the tuning of hyper-parameters and
other aspects of the training process, to aid in debugging misclassifications
produced by ML models, and to monitor ML systems at run time and ensure that
outputs from ML models are used in a manner that ensures safe operation at all
times.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has
been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.