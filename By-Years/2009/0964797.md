* 0964797
* EAGR:  Perceptually Optimized Semantic Media Adaptation for Mobile Device Access
* CSE,IIS
* 04/01/2010,03/31/2011
* Chang Wen Chen, SUNY at Buffalo
* Standard Grant
* Jie Yang
* 03/31/2011
* USD 59,999.00

This project develops a semantic media adaptation scheme for mobile access of
information that is perceptually optimized for users to enjoy semantically
relevant media content using small display mobile devices. The research team
explores seamless integration of multidisciplinary technologies from computer
vision, media coding and transmission, wireless networking, mobile device, and
human visual perception to tackle the challenges in closing the gap between rich
content in high resolution and size limited mobile device access.

The intellectual merit of this project lies in the exploration and development
of several relevant techniques in (1) Limited user interface media semantic
extraction; (2) Capacity and resource constrained media content adaptation; (3)
Perceptually optimized delivery and display of adapted media to small sized
mobile devices. The research team addresses these issues by seamless integration
of technologies from different research fields that traditionally have less
interaction.

The project bridges both semantic gap and user intention gap in mobile
multimedia search and access. First, the innovative scheme of semantic
adaptation can be extended for any media search application based on
semantically relevant characteristics. Second, the adaptation of high resolution
media content for small sized mobile device plays a key role in media gateway
for wireless mobile access. Finally, the investigation of perceptual optimized
display on mobile devices shall open up a new research avenue to understand how
mobile users perceive rich media content with small displays.