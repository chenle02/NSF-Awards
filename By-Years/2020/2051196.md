* 2051196
* Evaluating the Impacts of Machine Learning Algorithms on Human Decisions
* SBE,SES
* 07/01/2021,06/30/2024
* Kosuke Imai, Harvard University
* Standard Grant
* Cheryl Eavey
* 06/30/2024
* USD 330,000.00

This research project will develop a methodological framework and set of tools
for experimentally evaluating the impacts of machine learning algorithms on
human decisions. In today's data-driven society, decisions often are based at
least in part on algorithmic recommendations. Whenever choosing movies to watch
or shopping for clothes to wear, online sites are constantly feeding consumers
with such information. The project will develop methodologies to evaluate
whether algorithmic recommendations help human decision makers achieve their
goals and how they affect the fairness of such decisions. The new methodologies
will help researchers empirically evaluate the efficacy of algorithm-assisted
human decision making in a wide range of settings. These settings include
individual decisions such as online shopping as well as decisions in medicine,
finance, and judicial systems that have the potential to affect the lives of
many in society. The investigators will apply the new methods to a randomized
evaluation of pretrial risk assessment instruments on judicial decisions. An
open-source software package will be developed, and the databases used in this
research will be made publicly available.&lt;br/&gt;&lt;br/&gt;This project will
develop tools for experimentally evaluating whether algorithmic recommendations
help human decision makers achieve their goals and how such recommendations
affect the fairness of such decisions. On the methodological front, the project
will show how to evaluate the impacts of machine learning algorithms on the
accuracy and fairness of human decisions. Although there exists a growing
literature on algorithmic fairness, existing research almost exclusively focuses
on the evaluation of accuracy and fairness of the algorithms themselves.
Machines and humans have their own biases, however, and these biases may
interact in unexpected ways to influence ultimate decisions. Also, the existing
definitions of fairness do not account for the fact that decisions may influence
individuals. The methodological framework to be developed will address these
open problems. On the substantive front, the project will analyze data on
original, real-world randomized controlled trials (RCTs) in collaboration with
several jurisdictions in the United States. The project will analyze these RCTs
to evaluate the impacts of pretrial risk assessment instruments (PRAIs) on
judicial decisions. There has been a growing concern in the academic and public-
policy communities about the potential racial bias of these PRAIs. This research
will develop and implement rigorous evaluation methodologies to answer policy-
relevant questions so that direct contributions can be made to this important
public policy debate.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.