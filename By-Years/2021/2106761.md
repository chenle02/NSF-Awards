* 2106761
* Collaborative Research: CNS Core: Medium: Towards Federated Learning over 5G Mobile Devices: High Efficiency, Low Latency, and Good Privacy
* CSE,CNS
* 10/01/2021,09/30/2025
* Yuanxiong Guo, University of Texas at San Antonio
* Continuing Grant
* Alhussein Abouzeid
* 09/30/2025
* USD 203,500.00

Recent emerging federated learning (FL) allows distributed data sources to
collaboratively train a global model without sharing their privacy sensitive raw
data. However, due to the huge size of the deep learning model, the model
downloads and updates generate significant amount of network traffic which
exerts tremendous burden to existing telecommunication infrastructure. This
project takes FL over 5G mobile devices as a workable application scenario to
address this dilemma, which will significantly improve the design, analysis and
implementation of FL over 5G mobile devices. The research outcomes will
substantially enrich the knowledge of machine learning technologies and 5G
systems and beyond. Moreover, this project is multidisciplinary, involving
machine learning/deep learning/federated learning, edge computing, wireless
communications and networking, security and privacy, computer architectural
design, etc., which will serve as a fruitful training ground for both graduate
and undergraduate students to equip them with multidisciplinary skills for
future work force to boost the national economy. Furthermore, outreach
activities to high school students will increase the participation of female and
minority students in science and engineering.&lt;br/&gt;&lt;br/&gt;Specifically,
by observing that iterative model updates tend to show high sparsity, the
investigators leverage model update sparsity to design model pruning and
quantization schemes to optimize local training and privacy-preserving model
updating in order to lower both energy consumption and model update traffic.
They achieve this design goal by conducting the four research tasks: (1)
designing software-hardware co-designed model pruning schemes and adaptive
quantization techniques in FL within a single 5G mobile device according to the
local data and model sparsity property to reduce the local computation and
memory access; (2) making sound trade-off between "working" (i.e., local
computing) and "talking" (i.e., 5G wireless transmissions) to boost the overall
energy/communications efficiency for FL over 5G mobile devices; (3) developing
novel differentially private compression schemes based on sparsification
property and quantization adaptability to rigorously protect data privacy while
maintaining high model accuracy and communication efficiency in FL; and (4)
building a testbed to thoroughly evaluate the proposed
designs.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.