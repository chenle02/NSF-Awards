* 9309564
* Properties of Transsaccadic Memory
* SBE,BCS
* 10/15/1993,09/30/1997
* David Irwin, University of Illinois at Urbana-Champaign
* Continuing Grant
* Jasmine Young
* 09/30/1997
* USD 194,587.00

9309564 IRWIN Our eyes move from object to object in the world several times
each second. We scan the world by means of saccades--fast eye movements that are
separated by brief fixations during which the eyes are relatively still. Each
eye movement causes visual stimulation to be swept across the retinas, producing
a blur or smear that is not ordinarily perceived because vision is suppressed
during saccades. Because of this suppression, we acquire visual information from
the world only during fixations, when the eyes are still. For this reason, our
visual information about the world is registered in isolated glimpses that are
separated in time. Furthermore, the contents of these isolated glimpses are not
identical, because different regions of the world fall on different parts of the
retina when the eyes change position. Despite this rapidly changing and
discontinuous visual input, we ordinarily perceive the world as unified, stable,
and continuous. How the perceptual system accomplishes this has puzzled
psychologists and vision researchers for over a century. One frequent hypothesis
is that the contents of individual eye fixations are combined in memory across
eye movements to produce a coherent mental representation of the visual
environment. This research will investigate the characteristics of this
hypothetical process. In particular, the research will determine how much
information is remembered from one eye fixation to the next, whether some kinds
of information are remembered better than others, and how this information is
stored and combined across eye movements. The experimental procedure will
involve having individual observers view visual displays on a computer terminal
screen while their eye movements are monitored by an eyetracking device. During
selected eye movements, the visual display will disappear and the observer's
memory for that display will be assessed. For example, the observer may indicate
whether a second display is identi cal to or different from the first display,
attempt to report some particular information that was present in the first
display, or name an indicated object in a new display as rapidly as possible.
These responses will reveal what aspects of the original display are stored in
memory, maintained across an eye movement, and used to relate successive eye
fixations to each other. The question of how people perceive a continuous visual
world across eye movements is a classic problem in perception. The research will
advance the solution to this problem. In addition, the research will lead to the
development of more sophisticated theories of spatial representation and spatial
cognition in general. From a practical standpoint, the research will help human
factors engineers design visual displays, and tasks that require multiple eye
fixations on a display, to take best advantage of an operator's ability or
inability to combine different kinds of visual information across eye movements.
***