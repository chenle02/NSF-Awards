* 1136944
* NSF/FDA SIR:  System Solutions for Improved Image Quality of Context-aware Mobile Displays
* ENG,CBET
* 09/01/2011,08/31/2014
* Lin Zhong, William Marsh Rice University
* Standard Grant
* Leon Esterowitz
* 08/31/2014
* USD 105,000.00

1136944 Zhong

Unlike PCs, mobile devices such as smart-phones and tablets are likely to be
used under various viewing conditions. Many contextual factors including viewing
angle, ambient light, and a shaking hand will introduce significant distortion
in the perceived image quality, challenging the use of mobile devices to view
medical images. On February 4, 2011, the US FDA cleared the first diagnostic
radiology application that allows the physicians to view CT, MR, and PET images
on the iPhone and iPad mobile devices when there is no access to a workstation.
While this ruling enables physicians to view images and make diagnoses under
recommended lighting conditions, it mandates that the cleared application
include labeling and safety features to mitigate the risk of adverse viewing
conditions. The challenge from the contextual factors remains unaddressed: the
physicians are responsible to operate a mobile display in a proper viewing
environment.

The goal of this research project is to address the challenge to mobile image
quality from contextual factors with a computational and sensing approach. The
key point is that efficient sensing and computational power of mobile devices
can be leveraged to extract information about the viewing context to compensate
for image distortions in mobile display. The proposed research will heavily draw
upon the modern understanding of the human visual system. It will not only offer
solutions that are applicable to all kinds of mobile displays but also will
provide technology-specific solutions for existing and emerging mobile display
technologies, from liquid-crystal display (LCD) to organic light-emitting diode
(OLED) to auto-stereoscopic three-dimensional (3D) technologies.