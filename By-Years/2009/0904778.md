* 0904778
* III: Medium:  A Machine Learning Approach to Computational Understanding of Skill Criteria in Surgical Training
* CSE,IIS
* 07/15/2009,09/30/2013
* Huan Liu, Arizona State University
* Standard Grant
* Sylvia Spengler
* 09/30/2013
* USD 874,484.00

This award is funded under the American Recovery and Reinvestment Act of 2009
(Public Law 111-5).&lt;br/&gt;&lt;br/&gt;A recent study by the Agency for
Healthcare Research and Quality (AHRQ) documented over 32,000 mostly surgery-
related deaths, costing nine billion dollars and accounting for 2.4 million
extra days in hospital in 2000. At the same time, economic pressures influence
medical schools to reduce the cost in training surgeons. The success of
simulation-based surgical education and training will not only shorten the time
involving a faculty surgeon in various stages of training (hence reducing cost),
but also will improve the quality of training. Reviewing the state-of-the-art
research, there are two research challenges: (1) to automatically rate the
proficiency of a resident surgeon in simulation-based training, and (2) to
associate skill ratings with correction procedures. This award will explore a
machine-learning-based approach to computational understanding of surgical
skills based on temporal inference of visual and motion-capture data from
surgical simulation. The approach employs latent space analysis that exploits
intrinsic correlations among multiple data sources of a surgical action. This
learning approach is enabled by the simulation and data acquisition design that
ensures clinical meaningfulness of the acquired data.
&lt;br/&gt;&lt;br/&gt;Intellectual Merit: &lt;br/&gt;The intellectual merit of
the proposed work lies in the exploration of the answers to two key research
questions: (1) how to develop a computational understanding of surgical-skill-
defining criteria (high-level knowledge) from low-level, raw sensory
observations; and (2) how to efficiently perform temporal inference from
correlated data sources of disparate nature with unknown structures. Expertise
related to motion is a well-observed phenomenon but the task of inferring motion
expertise patterns from captured data especially video is largely unexplored.
This award presents a controlled methodology to extract expertise patterns from
raw sensory data. This interdisciplinary team with collaboration from medical
professionals is well positioned to address these fundamental research
issues.&lt;br/&gt;&lt;br/&gt;Broad Impact: &lt;br/&gt;The broad impact of the
proposed work is threefold. First, the ability of the proposed system to create
descriptive, mathematical models from recorded video and other data in surgical
training opens up the possibility of new paradigms that can significantly
improve current practice in surgeon education and training. Second, the proposed
approaches may enable development of lower-cost surgical training systems.
Third, the novel formulation of and solution to the fundamental problem of
expertise inference from disparate temporal measurements with intrinsic
correlation can find many other applications such as sports (e.g., baseball and
golf training), rehabilitation, and surveillance. The impact of the
interdisciplinary project on education manifests in its direct contribution to
better training and education of surgeons and to nurturing a new generation of
students who possesses strong interdisciplinary background and skills.
&lt;br/&gt;&lt;br/&gt;Key Words: Surgical Simulation, Surgical Education and
Training, Complementary Feature Selection, Visual and Temporal Inference,
Learning in Latent Space.