* 2040800
* FAI: Fairness in Machine Learning with Human in the Loop
* CSE,IIS
* 02/01/2021,01/31/2024
* Mingyan Liu, University of California-Santa Cruz
* Standard Grant
* Todd Leen
* 01/31/2024
* USD 625,000.00

Despite early successes and significant potential, algorithmic decision-making
systems often inherit and encode biases that exist in the training data and/or
the training process. It is thus important to understand the consequences of
deploying and using machine learning models and provide algorithmic treatments
to ensure that such techniques will ultimately serve the social good. While
recent works have looked into the fairness issues in AI concerning the “short-
term” measures, the long-term consequences and impacts of automated decision
making remain unclear. The understanding of the long-term impact of a fair
decision provides guidelines to policy-makers when deploying an algorithmic
model in a dynamic environment and is critical to its trustworthiness and
adoption. It will also drive the design of algorithms with an eye toward the
welfare of both the makers and the users of these algorithms, with an ultimate
goal of achieving more equitable outcomes. &lt;br/&gt; &lt;br/&gt;This project
aims to understand the long-term impact of fair decisions made by automated
machine learning algorithms via establishing an analytical, algorithmic, and
experimental framework that captures the sequential learning and decision
process, the actions and dynamics of the underlying user population, and its
welfare. This knowledge will help design the right fairness criteria and
intervention mechanisms throughout the life cycle of the decision-action loop to
ensure long-term equitable outcomes. Central to this project’s intellectual
inquiry is the focus on human in the loop, i.e., an AI-human feedback loop with
automated decision-making that involves human participation. Our focus on the
long-term impacts of fair algorithmic decision-making while explicitly modeling
and incorporating human agents in the loop provides a theoretically rigorous
framework to understand how an algorithmic decision-maker fares in the
foreseeable future.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.