* 1910940
* CHS: Small: Audio-Visual Reconstruction for Immersive Virtualized Reality
* CSE,IIS
* 10/01/2019,09/30/2023
* Roberta Klatzky, University of Maryland, College Park
* Standard Grant
* Ephraim Glinert
* 09/30/2023
* USD 499,999.00

Maintaining the sense of presence is a major challenge in immersive virtual
environments. An important aspect of immersion is the feeling of cohesiveness
between different senses, including the visual and auditory; for example, an
object that looks like wood should also sound like wood. Sound synthesis can
improve a user's sensory cohesion when interacting with objects, but it requires
accurate real-world material parameters. While much prior work in computer
vision has focused on acquiring the geometric shape and visual characteristic of
objects, the resulting point-clouds and images can assist in more accurate
recovery of audio parameters for sound synthesis, along with acoustic scattering
and absorption properties for sound rendering and propagation. A hypothesis of
this research is that, conversely, auditory metrics can also assist in
determining an object's geometry, including holes and occlusions, in a manner
analogous to sonar detection (but of course 3D geometry reconstruction is far
more challenging than object detection). The audio-visual reconstruction enabled
by this project will have broad impact across many domains, including assistive
technology for persons who are visually impaired, multimodal human-centric
interfaces, immersive teleconferencing, rapid prototyping of acoustic spaces for
urban planning, structural design, and noise control, to name just a few.
Project outcomes including scientific advances and software systems will be
disseminated through websites, publications, workshops, community outreach, and
other professional events.&lt;br/&gt;&lt;br/&gt;This project explores a novel
paradigm of audio-visual reconstruction of real-world scenes, where audio cues
are used to guide the classification of objects and materials for 3D geometry
reconstruction. At the same time, the visual information can be used to
initialize and accelerate the identification of acoustic material parameters.
Some of the major research challenges that will be addressed include audio-
guided 3D model reconstruction, design of audio-visual neural networks for
material and object identification, learning-based acoustic material
classification of a large physical or virtual space, and optimization-based
acoustic material refinement using geometric and wave-based methods.
Perceptually-grounded evaluation and validation of the new methods and
applications will be performed.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.