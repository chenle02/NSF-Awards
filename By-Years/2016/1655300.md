* 1655300
* Discovering Hierarchical Representations for Action Understanding
* SBE,BCS
* 08/01/2017,07/31/2022
* Hongjing Lu, University of California-Los Angeles
* Standard Grant
* Betty Tuller
* 07/31/2022
* USD 555,792.00

A major issue in the psychological sciences is understanding how people can
infer the intentions of others. Humans are remarkably adept at predicting the
actions of other people and making inferences about their intention and goals.
The present investigation examines how humans make such inferences from the
physical movements of others. The work is guided by a computational theory of
biological motion understanding that quantifies what aspects of actions allow
observers to make inferences about the meaning of actions and what might come
next. The larger goal is to explain how perception and reasoning operate
synergistically to infer hidden goals and intentions. These findings will guide
development of the next generation of intelligent machine-vision systems, useful
in forensic sciences as well as many other real-world applications. Such systems
will need to perform challenging tasks that currently are difficult and time-
consuming for humans (for example, automated interpretation of human actions
recorded in low-resolution surveillance video). The project will also help to
identify individual differences in action understanding, potentially revealing
the nature of the impairments in action understanding observed in people with
autism disorder. In addition, the project will provide a unique training
opportunity for students who are interested in interdisciplinary research at the
interface between cognitive science and artificial intelligence and will provide
an in-depth international research experience for a graduate student and
postdoctoral fellow.&lt;br/&gt;&lt;br/&gt;The research will integrate advanced
psychophysical methods with sophisticated computational approaches. A key aim is
to develop a unified theory based on a hierarchical non-parametric Bayesian
framework, specifying the fundamental computational mechanisms involved in
perception of human actions and reasoning about them. More generally, the
project will use human body movements as an underutilized approach to
understanding general problems in learning: how to construct, use and transform
hierarchical representations to support human perception and cognition. Three
aims are particularly noteworthy. First, the project will integrate
computational modeling approaches with behavioral experiments to investigate the
critical connection between perceptual and cognitive systems. Second, the
project uses action stimuli derived from motion capture data in the real world
as the visual input (CCTV images collected in the UK and secured at the
University of Glasgow). By avoiding the limitations of studies that use
restricted examples and constrained environments, the investigators maximize the
likelihood that the findings will generalize to real-world situations. Third,
the project will develop significant extensions of Bayesian approaches in order
to study complex visual processes by combining generative models with
probabilistic constraints. This award is co-funded by the Perception, Action,
and Cognition Program and the Office of International Science and Engineering.