* 2245968
* CRII: SaTC: Towards Data-effective and Cost-efficient Security Attack Detections
* CSE,CNS
* 03/15/2023,02/28/2025
* Lingwei Chen, Wright State University
* Standard Grant
* Xiaogang (Cliff)  Wang
* 02/28/2025
* USD 174,943.00

Increased connectivity of devices and people to the Internet has created an
ever-expanding security attack surface. Machine learning (ML) techniques have
been used to help detect attacks and may offer a more scalable way to deal with
an increasingly large attack surface. However, acquiring a large volume of high-
quality labelled attack samples is both costly and time consuming. Further, the
acquired data set quite often do not fully represent the true data distribution.
Given the challenge of labeled data scarcity and imbalance in representation,
this project's novelties are to explore new ways to build data driven cyber-
attack detection systems that can learn effectively from limited or biased cyber
data set in a cost-efficient manner. The project's broader significance and
importance are 1) enhancing the data-driven security attack detection
infrastructure that leads to more secure and trustworthy cyberspace; 2) bridging
the gap between research and practice by creating open-source systems that
encourage real security productions, 3) providing research opportunities to both
undergraduate and graduate students in the area of AI/ML enabled cyber
defense.&lt;br/&gt;&lt;br/&gt;This project unveils an insight on how limited
and/or imbalanced attack samples can be used as effective training data to
facilitate data-driven model construction and enable high-performance security
attack detection with low cost in practice. Towards this insight, this project
contains three technical approaches: (1) cross-modal adversarial reprogramming
that repurposes prior trained transformer models by inserting patch-level
perturbations to inputs, reducing the number of parameters needed yet still
maintaining its capability for data-limited learning; (2) scalable semi-
supervised learning through consistency and contrastive regularization to boost
model generalization for performing pseudo-labeling tasks and to help reduce
label bias; (3) leveraging labeled and unlabeled objects to extend these two
learning pipelines for more effective attack
detection.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.