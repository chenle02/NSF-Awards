* 0905228
* HCC: Medium: Collaborative Research: Development of Trust Models and Metrics for Human-Robot Interaction
* CSE,IIS
* 09/01/2009,08/31/2014
* Holly Yanco, University of Massachusetts Lowell
* Standard Grant
* Ephraim Glinert
* 08/31/2014
* USD 560,000.00

It is often assumed that the use of robots to help people execute tasks will
result in better performance than if the person or robot were operating alone.
However, research in automated systems suggests that the performance of a human-
machine system depends on the extent to which the person trusts the machine and
the extent to which this trust (or distrust) is justified. As robots are being
developed to aid people with complex tasks, it is critical not only that we
build systems which people can trust, but that these systems also foster an
appropriate level of trust based on the capabilities of the systems. A user who
does not have an appropriate level of trust in the robot may misuse or abuse the
robot's autonomous capabilities or expose people to danger. This project
proposes to develop quantitative metrics to measure a user's trust in a robot as
well as a model to estimate the user's level of trust in real time. Using this
information, the robot will be able to adjust its interaction accordingly.
&lt;br/&gt;&lt;br/&gt;Promoting appropriate levels of trust will be particularly
beneficial in safety-critical domains such as urban search and rescue and
assistive robotics, in which users risk harm to themselves, the robot, or the
environment if users do not trust the robot enough to rely on its autonomous
capabilities. The research has the potential for a large impact on the field of
human-robot interaction as few studies have explicitly examined issues involving
trust of robots. Being able to model trust and foster appropriate levels of
trust will result in more effective use of robotic automation, safer
interactions, and better task performance.