* 1208497
* NRI-Small: Collaborative Research: Multiple Task Learning from Unstructured Demonstrations
* CSE,IIS
* 10/01/2012,09/30/2016
* Andrew Barto, University of Massachusetts Amherst
* Standard Grant
* Reid Simmons
* 09/30/2016
* USD 499,199.00

This project develops techniques for the efficient, incremental learning of
complex robotic tasks by breaking unstructured demonstrations into reusable
component skills. A Bayesian model segments task demonstrations into simpler
components and recognizes instances of repeated skills across demonstrations.
Established methods from control engineering and reinforcement learning are
leveraged and extended to allow for skill improvement from practice, in addition
to learning from demonstration. The project aims to unify existing research on
each of these ideas into a principled, integrated approach that addresses all of
these problems jointly, with the goal of creating a deployment-ready, open-
source system that transforms the way experts and novices alike interact with
robots.

A simple interface that allows end-users to intuitively program robots is a key
step to getting robots out of the laboratory and into human-cooperative settings
in the home and workplace. Although it is often possible for an expert to
program a robot to perform complex tasks, this programming is often very time-
consuming and requires a great deal of knowledge. In response to this, much
recent research is focusing on robot learning-from-demonstration, where non-
expert users can teach a robot how to perform a task by example. Unfortunately,
much of this work is limited to the artificially-structured demonstration of a
single task with a well-defined beginning and end. By contrast, human-
cooperative robots will be required to efficiently and incrementally learn many
different, but often related, tasks from complex, unstructured demonstrations
that are easy for non-experts to produce.