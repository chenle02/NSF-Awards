* 1717877
* SHF:Small: Optimization of Parallel and Shared Cache Memory using the Footprint Theory
* CSE,CCF
* 08/15/2017,07/31/2021
* Chen Ding, University of Rochester
* Standard Grant
* Almadena Chtchelkanova
* 07/31/2021
* USD 544,262.00

Multicore processors bring a tremendous increase in computing power to personal,
scientific, and business computing platforms. Most on-chip memory in these
processors is devoted to shared cache, making it a major factor in performance.
A common practice is to improve cache performance by building a path of
improvements through testing. However, testing may take too many steps, it may
not converge to a stable solution, and most importantly for large scale parallel
programs, the solution is far from optimal since testing covers only a minuscule
fraction of all possibilities. &lt;br/&gt;Instead of testing, this research
provides software developers and hardware engineers new tools based on modeling.
The research builds on the past NSF supported research which has developed the
footprint theory for sequential applications. This work solves the new problems
of data sharing and extends the locality theory to optimize the parallel code.
Parallel systems require complex models, and this complexity is addressed by
composable models to solve large scale problems with large scale modeling. The
new tools include statistical models of both program and machine
characteristics. Program models include profiling analysis that derive the data
and cache sharing in all thread combinations and data placements, in cache of
all sizes. Cache models analyze the effect of many hardware designs including
associativity, exclusivity, coherence, cache-way partitioning, and transient
loads/stores. Combined use of these models enables parallel program optimization
and improves thread and data placement.