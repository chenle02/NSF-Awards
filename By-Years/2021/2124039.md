* 2124039
* FMitF: Track I: Scalable and Quantitative Verification for Neural Network Analysis and Design
* CSE,CCF
* 10/01/2021,09/30/2025
* Yufei Ding, University of California-Santa Barbara
* Standard Grant
* Wei Ding
* 09/30/2025
* USD 749,248.00

Neural Networks (NNs) have been successful in many areas including computer
vision, speech recognition, and natural language processing. However, due to the
increasing adoption of NNs in safety-critical and socially sensitive domains
such as self-driving cars, robotics, computer security, criminal justice, and
medical diagnosis, there is a pressing need for developing verification
techniques that can provide guarantees about dependability and safety of NN
applications. Formal-verification techniques can provide guarantees of
correctness; however, existing approaches are not effective in analyzing real-
world NNs with large numbers of neurons and complicated model structures. This
project sets a comprehensive research agenda focusing on a holistic formal-
verification framework for NNs that will provide a systematic and principled
approach for developing dependable and safe NNs. It is intended to benefit major
machine-learning applications such as autonomous driving and contribute to the
leadership of the United States in software engineering and artificial
intelligence. The research findings are being widely disseminated through open-
source software packages, publications in premier conferences and journals,
tutorials at teaching workshops, as well as specialized K-12 programs for
exposing the young generation to the frontiers of software verification and
machine-learning research. &lt;br/&gt;&lt;br/&gt;The team of researchers working
on this project are integrating methods from the classical computing fields such
as software engineering, automated verification, and formal methods to address
the unique research challenges in the dependability and safety of NN
applications. Specific research directions include 1) novel symbolic
quantitative analysis techniques that provide sound results for establishing
dependability and safety of the state-of-the-art NN models; 2) a set of
effective system-level optimizations for computation/memory efficient NN
verification with sufficient cross-framework portability and high verification
efficiency; 3) advanced neural architecture design and training support for
exploring and developing neural network models with verifiable robustness. The
success of this research agenda is intended to enable a more complete and
efficient software stack for improving the scalability of NN verification
techniques and the robustness of NN applications.&lt;br/&gt;&lt;br/&gt;This
award reflects NSF's statutory mission and has been deemed worthy of support
through evaluation using the Foundation's intellectual merit and broader impacts
review criteria.