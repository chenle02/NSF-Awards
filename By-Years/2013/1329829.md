* 1329829
* CPS: Synergy: A Novel Biomechatronic Interface Based on Wearable Dynamic Imaging Sensors
* CSE,CNS
* 02/01/2014,01/31/2019
* Jana Kosecka, George Mason University
* Standard Grant
* Sylvia Spengler
* 01/31/2019
* USD 995,055.00

The problem of controlling biomechatronic systems, such as multiarticulating
prosthetic hands, involves unique challenges in the science and engineering of
Cyber Physical Systems (CPS), requiring integration between computational
systems for recognizing human functional activity and intent and controlling
prosthetic devices to interact with the physical world. Research on this problem
has been limited by the difficulties in noninvasively acquiring robust
biosignals that allow intuitive and reliable control of multiple degrees of
freedom (DoF). The objective of this research is to investigate a new sensing
paradigm based on ultrasonic imaging of dynamic muscle activity. The synergistic
research plan will integrate novel imaging technologies, new computational
methods for activity recognition and learning, and high-performance embedded
computing to enable robust and intuitive control of dexterous prosthetic hands
with multiple DoF. The interdisciplinary research team involves collaboration
between biomedical engineers, electrical engineers and computer scientists. The
specific aims are to: (1) research and develop spatio-temporal image analysis
and pattern recognition algorithms to learn and predict different dexterous
tasks based on sonographic patterns of muscle activity (2) develop a wearable
image-based biosignal sensing system by integrating multiple ultrasound imaging
sensors with a low-power heterogeneous multicore embedded processor and (3)
perform experiments to evaluate the real-time control of a prosthetic
hand.&lt;br/&gt;The proposed research methods are broadly applicable to
assistive technologies where physical systems, computational frameworks and low-
power embedded computing serve to augment human activities or to replace lost
functionality. The research will advance CPS science and engineering through
integration of portable sensors for image-based sensing of complex adaptive
physical phenomena such as dynamic neuromuscular activity, and real-time
sophisticated image understanding algorithms to interpret such phenomena running
on low-power high performance embedded systems. The technological advances would
enable practical wearable image-based biosensing, with applications in
healthcare, and the computational methods would be broadly applicable to
problems involving activity recognition from spatiotemporal image data, such as
surveillance.&lt;br/&gt;&lt;br/&gt;This research will have societal impacts as
well as train students in interdisciplinary methods relevant to CPS. About 1.6
million Americans live with amputations that significantly affect activities of
daily living. The proposed project has the long-term potential to significantly
improve functionality of upper extremity prostheses, improve quality of life of
amputees, and increase the acceptance of prosthetic limbs. This research could
also facilitate intelligent assistive devices for more targeted
neurorehabilitation of stroke victims. This project will provide immersive
interdisciplinary CPS-relevant training for graduate and undergraduate students
to integrate computational methods with imaging, processor architectures, human
functional activity and artificial devices for solving challenging public health
problems. A strong emphasis will be placed on involving undergraduate students
in research as part of structured programs at our institution. The research team
will involve students with disabilities in research activities by leveraging an
ongoing NSF-funded project. Bioengineering training activities will be part of a
newly developed undergraduate curriculum and a graduate curriculum under
development.&lt;br/&gt;&lt;br/&gt;The synergistic research plan has been
designed to advance CPS science and engineering through the development of new
computational methods for dynamic activity recognition and learning from image
sequences, development of novel wearable imaging technologies including high-
performance embedded computing, and real-time control of a physical system. The
specific aims are to: &lt;br/&gt;(1) Research and develop spatio-temporal image
analysis and pattern recognition algorithms to learn and predict different
dexterous tasks based on sonographic patterns of muscle activity. The first aim
has three subtasks designed to collect, analyze and understand image sequences
associated with functional tasks. (2) Develop a wearable image-based biosignal
sensing system by integrating multiple ultrasound imaging sensors with a low-
power heterogeneous multicore embedded processor. The second aim has two
subtasks designed to integrate wearable imaging sensors with a real-time
computational platform. (3) Perform experiments to evaluate the real-time
control of a prosthetic hand. The third aim will integrate the wearable image
acquisition system developed in Aim 2, and the image understanding algorithms
developed in Aim 1, for real-time evaluation of the control of a prosthetic hand
interacting with a virtual reality environment.&lt;br/&gt;&lt;br/&gt;Successful
completion of these aims will result in a real-time system that acquires image
data from complex neuromuscular activity, decodes activity intent from
spatiotemporal image data using computational algorithms, and controls a
prosthetic limb in a virtual reality environment in real time. Once developed
and validated, this system can be the starting point for developing a new class
of sophisticated control algorithms for intuitive control of advanced prosthetic
limbs, new assistive technologies for neurorehabilitation, and wearable real-
time imaging systems for smart health applications.