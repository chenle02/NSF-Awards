* 2018926
* CC* Compute: Private Campus Cloud for Data Analytics and Machine Learning
* CSE,OAC
* 07/01/2020,01/31/2023
* Thomas Hacker, Purdue University
* Standard Grant
* Kevin Thompson
* 01/31/2023
* USD 408,205.00

New usage patterns of computing for research have emerged that rely on the
availability of flexible, elastic, and highly specialized services. Uniform
batch computing pools traditionally provided by high performance or high
throughput computing environments have difficulty adapting to meet these
requirements. A new approach that updates and evolves the research computing
ecosystem is needed to respond to these needs. This new model, a “Community
Cloud”, provides a cost effective, highly responsive, sustainable, and
customizable cloud and container computing solutions for specific applications
and domain science communities.&lt;br/&gt;&lt;br/&gt;This project, through the
acquisition of a new compute cluster, knits together central and lab-scale data,
instrument, and compute resources into a cloud ecosystem for researchers who
need capabilities beyond batch computing, and extends the research computing
ecosystem to include cloud capabilities at the campus level. The Community Cloud
is designed to: 1) Devise a new approach to establish a community cloud service
using virtualization, containers, and infrastructure-as-code (IAC) techniques to
create running infrastructure as an artifact; 2) Support diverse science domains
via an effective infrastructure that enables new kinds of discovery that cannot
be well met through the use of traditional batch computing systems; 3) Develop a
reference business model for the evolution of campus “condo” cluster programs to
sustainably operate a production community cloud; and 4) Enable scalable and
sustainable instructional use of the proposed community cloud for courses, real-
world training, and workforce development for the campus and national research
computing communities. The new compute cluster includes 8 application nodes
(1024 cores), 2 GPU nodes (8 gpus), 6 storage nodes (288 TB), and one bastion
node, all interconnected through a 100Gb network, and managed using
Kubernetes.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.