* 2144927
* CAREER:  Foundations of Privacy-Preserving Collaborative Learning
* CSE,CCF
* 03/01/2022,02/28/2027
* Basak Guler, University of California-Riverside
* Continuing Grant
* Phillip Regalia
* 02/28/2027
* USD 214,055.00

Collaborative machine-learning techniques allow multiple data owners to
collaborate to train better machine-learning models by increasing the volume and
diversity of data. In many real-world scenarios, however, the data is privacy-
sensitive, as is the case for healthcare records, financial transactions, or
geolocation data. Privacy-preserving machine-learning techniques can facilitate
machine-learning applications while protecting the privacy of sensitive data.
This project aims to develop an efficient, secure, and trustworthy collaborative
learning paradigm to address several critical challenges in the real-world
application of privacy-preserving collaborative learning. The outcomes of the
project will allow multiple data owners to collaborate to train machine-learning
models without revealing any sensitive data, which will improve the performance
of machine-learning applications by increasing the volume and diversity of data.
It will also facilitate novel applications in fields where data is scarce and
collaboration has traditionally been limited due to privacy challenges, such as
better drug and vaccine discovery in healthcare. The research will be strongly
integrated with education, through mentoring of undergraduate students,
development of new undergraduate and graduate courses, and machine-learning
workshops for K-12 students and teachers, with the goal of building a diverse
and inclusive machine learning workforce. &lt;br/&gt;&lt;br/&gt;Privacy-
preserving machine learning is expected to revolutionize the future of data-
driven collaborative applications, by allowing large-scale machine-learning
applications without revealing any sensitive data, but its real-world adoption
has been limited by several major barriers, including the communication
bottleneck, security, and trustworthiness. The research will address these
fundamental challenges by introducing a new approach rooted in information and
coding theory. The research is organized in three main thrusts: 1) develop the
foundations of communication-efficient privacy-preserving collaborative
learning; 2) realize a privacy-preserving machine-learning paradigm with
provable security and fairness guarantees; and 3) enable privacy-preserving
machine learning in arbitrary network topologies, including centralized,
decentralized, and dynamic topologies, and networks with heterogeneous computing
and communication resources. The research is rooted in coding and information
theory, and incorporates stochastic optimization, distributed computing, and
cryptography. The insights gained from the research will enable privacy-aware
machine learning applications that are: 1) accessible by users with bandwidth
and computational limitations, such as consumer devices in mobile edge networks;
2) secure, by preventing adversaries from injecting unwanted behavior into the
decision process; and 3) fair in its decisions towards all communities in
society, without revealing any sensitive data and personal
information.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission
and has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.