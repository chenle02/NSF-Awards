* 2028894
* Collaborative Research: PPoSS: Planning: Hardware-accelerated Trustworthy Deep Neural Network
* CSE,CCF
* 10/01/2020,09/30/2022
* Xiaonan Guo, Indiana University
* Standard Grant
* Danella Zhao
* 09/30/2022
* USD 59,957.00

Deep-learning approaches have recently achieved much higher accuracy than
traditional machine-learning approaches in various applications (e.g., computer
vision, virtual/augmented reality, and natural language processing). Existing
research has shown that large-scale data from various sources with high-
resolution sensing or large-volume data-collection capabilities can
significantly improve the performance of deep-learning approaches. However,
state-of-the-art hardware and software cannot provide sufficient computing
capabilities and resources to ensure accurate deep-learning performance in a
timely manner when using extremely large-scale data. This project develops a
scalable and robust heterogeneous system that includes a new low-cost, secure,
deep-learning hardware-accelerator architecture and a suite of large-data-
compatible deep-learning algorithms. It allows deep learning to fully benefit
from extremely large-scale data and facilitates efficient, low-latency
applications in connected vehicles, real-time mobile applications, and timely
precision health. The new technologies resulting from this project can enable
more research opportunities to design new hardware accelerators for deep
learning and obtain further optimization in computational complexity and
reduction in power consumption. Moreover, by integrating the research results
with the undergraduate and graduate curricula and outreach activities, this
project has great impacts on education and training of researchers and engineers
for computer architecture, security, theory and algorithms, and
systems.&lt;br/&gt;&lt;br/&gt;This project designs trustworthy hardware
accelerators optimized for large-scale deep-learning computations and models the
complicated structure of large-scale datasets. More specifically, this project
develops a novel hardware accelerator for deep learning that can achieve low
power consumption. In addition, this project designs innovative in-memory
encryption schemes to secure the neural models in deep-learning accelerators.
Furthermore, data-modeling and statistical-learning algorithms are developed in
this project to further reduce the computing cost of deep learning when
processing extremely large-scale datasets. Finally, this project builds and
evaluates a prototype of the proposed heterogeneous deep-learning system in
terms of efficiency, scalability, and security in multiple application domains
including mobile applications, connected vehicles and precision
health.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has
been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.