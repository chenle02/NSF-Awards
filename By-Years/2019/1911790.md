* 1911790
* Inferring Implicit Comparison Classes in Natural Language Understanding
* SBE,SMA
* 09/01/2019,08/31/2021
* Michael Tessler, Tessler                 Michael        H
* Fellowship Award
* Josie Welkom Miranda
* 08/31/2021
* USD 138,000.00

This award was provided as part of NSF's Social, Behavioral and Economic
Sciences (SBE) Postdoctoral Research Fellowships (SPRF) program and SBE's
Perception, Action, and Cognition program. The goal of the SPRF program is to
prepare promising, early career doctoral-level scientists for scientific careers
in academia, industry or private sector, and government. SPRF awards involve two
years of training under the sponsorship of established scientists and encourage
Postdoctoral Fellows to perform independent research. NSF seeks to promote the
participation of scientists from all segments of the scientific community,
including those from underrepresented groups, in its research programs and
activities; the postdoctoral period is considered to be an important level of
professional development in attaining this goal. Each Postdoctoral Fellow must
address important scientific questions that advance their respective
disciplinary fields. Under the sponsorship of Dr. Roger Levy at MIT, this
postdoctoral fellowship award supports an early career scientist investigating
children's understanding of context-sensitive language. Learning language is
challenging because words mean different things in different contexts. The
adjective 'big' conveys that the size of an object is greater than some
standard, but what that standard is depends on the context (e.g., a big shoe is
a lot smaller than a big building). Extant research suggests that by the time
children start producing the word 'big', they already understand its context-
sensitivity (big shoe vs. big building). Understanding the cues available to and
used by a child to form a context-sensitive interpretation of a sentence will
inform theories and models of language development. In addition, formalizing
with precise mathematical models how context-sensitive language is used and
understood will also help us build machines that understanding language in more
humanlike ways. &lt;br/&gt;&lt;br/&gt;The project encompasses a series of
experimental, corpus, and computational modeling studies to elucidate the
representations that underlie the incredible human capacity to learn and use
language flexibly. Under Objective 1, we extend state-of-the-art probabilistic
models for interpreting context-sensitive utterances (e.g. 'big') to address how
semantically identical but syntactically different utterances (e.g., "That Great
Dane is big" vs. "That is a big Great Dane") could provide cues to the relevant
standards or comparisons (e.g., big for a dog vs. big for a Great Dane). Under
Objective 2, we examine naturalistic video corpora of conversations between
young children and their care-givers to uncover the perceptual, linguistic, and
referential cues that the child listener could recruit to construct the relevant
comparisons for interpreting context-sensitive adjectives like 'big'. Under
Objective 3, we test the causal influence of such cues on adult and 4- to
5-year-old's inferences about the relevant comparisons. Testing our hypotheses
in both adults and young children sheds light on the developmental origins of
understanding context-sensitive language. This work makes new connections
between the fields of language acquisition and computational cognitive science
while furthering our understanding of both.&lt;br/&gt;&lt;br/&gt;This award
reflects NSF's statutory mission and has been deemed worthy of support through
evaluation using the Foundation's intellectual merit and broader impacts review
criteria.