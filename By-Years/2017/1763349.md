* 1763349
* AF: Medium: Collaborative Research: Foundations of Fair Data Analysis
* CSE,CCF
* 07/01/2018,06/30/2023
* Mallesh Pai, William Marsh Rice University
* Continuing Grant
* Tracy Kimbrel
* 06/30/2023
* USD 250,000.00

Machine learning algorithms increasingly make or inform critical decisions that
affect peoples' every day lives. For instance, algorithms make decisions
pertaining to hiring, college admissions, credit card and mortgage approvals,
sentencing and parole of the incarcerated, first-responder deployment, and what
advertisements and search results a user sees on the internet. An attractive
feature is that these algorithms can efficiently process large amounts of data
in making these decisions, thus hopefully improving economic and social
efficiency. Because such decisions are so consequential, their fairness has
become a matter of increasing concern. It has been argued that automation, by
removing the human element, guarantees fairness, but this is not so -- several
empirical studies have demonstrated that automation is no panacea. Further, the
reasons for unfairness and discrimination can be complex and non-obvious. This
project will study the frictions that may cause unfairness in algorithmic
decision making, and the costs of mitigating unfairness -- that is, quantitative
trade-offs between fairness and other desiderata, including accuracy,
computational efficiency, and economic efficiency.
&lt;br/&gt;&lt;br/&gt;Specifically, this project will study frictions to
fairness arising from several factors. There may not be sufficient data about
minority populations. There can be feedback loops arising from the fact that
observations can only be made on an individual if a risky action is taken, e.g.,
the person is granted a loan, or hired. Decision makers can be myopic, choosing
to maximize short-term gains rather than exploring riskier options that may pay
off in the long run. Economic frictions include self-confirming equilibria---
differing subjective perceptions of opportunities leading to choices by
individuals and communities which sustain those perceptions, and competition
among classifiers (for example, credit agencies) leading to less accurate
qualifiers in equilibrium. Finally, the problem of finding fair and accurate
classifiers can be computationally intractable. This project will seek ways to
mitigate the unfairness arising from these frictions. It will study the cost of
incentivizing myopic agents to explore and examine the short-term costs of such
incentives, and their long-term impact on fairness. It will also seek to design
computationally tractable classifiers that achieve provably good approximations
for fairness and accuracy.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.