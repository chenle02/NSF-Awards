* 1720713
* CHS: Small: Collaborative Research: Modeling Social Context to Improve Human-Robot Interaction
* CSE,IIS
* 09/16/2016,08/31/2019
* Laurel Riek, University of California-San Diego
* Standard Grant
* Ephraim Glinert
* 08/31/2019
* USD 161,250.00

For robots to be truly useful to people, it is critical that they be able to
understand and operate independently in human social environments (HSEs).
Decades of research into this problem by many investigators have to date failed
to yield a solution. The PIs on this collaborative project that spans two
partner institutions argue that a fundamental paradigm shift is necessary to
enable progress, and that this shift can be ignited through a contextually
driven approach to mobile robotics. Thus, the goal of this proposal is to create
and evaluate new models of social context in order to enable mobile robots to
interact appropriately with people in HSEs. Project outcomes will help give all
"things that think", from social robots to smart homes, a better understanding
of human social context and a greater capability to operate effectively in real-
world human spaces. By contributing new theoretical models, techniques, and open
source implementations that will accelerate the development and adoption of
machines that operate in HSEs, the PIs anticipate this work will have a
transformative impact on many fields within computer and information science,
including robotics, human-machine interaction, and ubiquitous computing. The PIs
also will make their context models available to other researchers.
&lt;br/&gt;&lt;br/&gt;The PIs' approach to context is unique in that, rather
than being techno-centric and entirely representational, it fully adopts
Dourish's approach to an interactional model of context inspired by the social
sciences - relational, dynamic, occasioned, and arising from activity - i.e.,
fluid. The key contribution of the approach is that it ties real-time sensor
data to models of situational context, which then inform a robot of the social
affordances of the environment. The PIs will engage in two primary research
activities. First, they will create a situational context processing capability
that can accept a multimodal, social scene snapshot from a robot and return back
a situational context frame (SCF) that contains an estimate of the scene's
salient objects, social activities, and situational context. Then, they will
contribute algorithmic techniques that enable a robot to leverage the SCF to
perform guided exploration to refine its model, and ultimately, goal-driven task
execution adapted to conform to social norms. The PIs' research emphasis on
using solely naturalistic, real-world, multimodal data, will enable them to make
unique contributions for increasing robustness in multimodal processing.