* 1423189
* CHS: Small: Looking Across the Uncanny Valley: Procedural and Data-Driven Methods for Gaze Modeling
* CSE,IIS
* 08/01/2014,07/31/2021
* Sophie Joerg, Clemson University
* Continuing Grant
* Ephraim Glinert
* 07/31/2021
* USD 520,513.00

Eye movements play a key role in human communication, yet they remain a
significant stumbling block for humanoid animation. Computer generated avatars
currently lack realistic gaze, which subconsciously distracts viewers and
thereby detracts from the usefulness of the many applications that employ these
graphical actors (e.g., educational / tutoring / training systems that
incorporate animated agents), a perceptual issue that has been dubbed the
"uncanny valley." This project represents a collaboration between two
investigators with complementary skills who will tackle the problem by
developing a holistic model of gaze dynamics for avatars, which combines
detailed real-world measurements (with the aid of binocular eye-tracking) and
signal analysis of both eye motions and the periocular skin region around the
eyes, to generate improved synthetic eye movement animations. Project activities
will include creation of a database of gaze motions, perceptual experiments to
improve our understanding of the saliency of different components of human gaze
(eyeball rotation, vergence, jitter, periocular skin motion) and their signal
properties in physical space, and the implementation of exemplary tasks (such as
reading and conversations) along with a software tool which will enable
animators to more easily design convincing gaze in frequently encountered
situations. The PI intends to open-source the software to be developed in this
research.

The gaze model under development by the PI differs from previous approaches in
the following ways. First, while others have modeled cyclopean avatar gaze few
have accessed the steadily growing eye tracking literature for inclusion of
binocular eye movement. The PI argues that binocular eye tracking in three-
dimensional physical space allows estimation of where the subject is fixating in
depth and, consequently, recording, analysis, and modeling of gaze vergence,
which will yield more believable characters. Second, the proposed model provides
a component of subtle gaze jitter, which is critical for dynamic realism as the
eyes are never perfectly still. Third, the description of the rotations of the
eyes is mathematically concise, follows physiological laws, and is easy to
implement. Finally, the proposed modeling effort includes perceptual studies
designed to investigate the influence of each model component and to optimize
the parameters of the resulting complete model. The procedural model is two-
staged and reminiscent of the functionality of human vision: a bottom-up stage
of eye rotation, which will be used to represent gaze when selecting a series of
look points, followed by a top-down stage of gaze orientation dependent on a
given task. Building a perceptual science underlying gaze modeling will foster
the believability of synthetic actors, and will more broadly impact diverse
areas such as social robotics where realistic gaze simulation is crucial for
creating likable robots.