* 1439237
* CompCog: Human Scene Processing Characterized by Computationally-derived Scene Primitives
* SBE,BCS
* 09/01/2014,02/28/2019
* Elissa Aminoff, Carnegie-Mellon University
* Standard Grant
* Betty Tuller
* 02/28/2019
* USD 463,158.00

How do our brains take the light entering our eyes and turn it into our
experience of the world around us? Critically, this experience seems to involve
a visual "vocabulary" that allows us to understand new scenes based on our prior
knowledge. The investigators explore the nature of this visual language,
exploring the specific computations that are realized in the brain mechanisms
used for scene perception. The work combines data from state-of-the-art computer
vision systems with human neuroimaging to both predict brain responses when
viewing complex, real-world scenes, and to analyze and understand the hidden
structure embedded in real-world images. This effort is essential for building a
theory of how we are able to see and for improving machine vision systems. More
broadly, biologically-inspired models of vision are essential for the effective
deployment of intelligent technology in navigation systems, assistive devices,
security verification, and visual information
retrieval.&lt;br/&gt;&lt;br/&gt;The artificial vision system adopted in this
research is highly data-driven in that it is learning about the visual world by
continuously "looking at" real-world images on the World Wide Web. The model,
known as "NEIL" (Never Ending Image Learner, http://www.neil-kb.com/), leverages
cutting-edge big-data methods to extract a vocabulary of scene parts and
relationships from hundreds of thousands of images. The relevance of this
vocabulary to human vision will then be tested using both functional magnetic
resonance imaging (fMRI) and magnetoencephalography (MEG) neuroimaging. The
hypothesis is that the application of prior knowledge about scenes expresses
itself through learned associations between the specific parts and relations
forming the vocabulary for scene perception. Moreover, different kinds of
associations may be instantiated within distinct components of the functional
brain network responsible for scene perception. Overall, this research will
build on a recent, highly-successful artificial vision system in order to
provide a more well-specified theory of the parts and relations underlying human
scene perception. At the same time, the research will provide information about
the human functional relevance of computationally-derived scene parts and
relations, thereby helping to refine and improve artificial vision systems.