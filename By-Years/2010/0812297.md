* 0812297
* RI-Small: Learning to Generate High Quality Paraphrases with a Broad Coverage Lexicalized Grammar
* CSE,IIS
* 09/01/2008,08/31/2012
* Michael White, Ohio State University Research Foundation -DO NOT USE
* Continuing Grant
* Tatiana Korelsky
* 08/31/2012
* USD 396,621.00

Automatic paraphrasing is considered vital to applications as diverse as machine
translation (MT), question answering, summarization, and dialogue systems.
Paraphrasing has also been shown recently to hold promise for automatic methods
of evaluating MT, when the paraphrases are of sufficiently high quality.
&lt;br/&gt;&lt;br/&gt;This project investigates novel methods for acquiring and
generating such high&lt;br/&gt;quality paraphrases in order to automatically
approximate the human translation&lt;br/&gt;error rate (HTER) metric for MT
evaluation, where human annotators post-edit MT&lt;br/&gt;outputs into
acceptable paraphrases of the reference translations. The
project&lt;br/&gt;emphasizes the use of a linguistically informed, grammar-based
parser and&lt;br/&gt;realizer for acquiring and generating paraphrases using
disjunctive logical&lt;br/&gt;forms (DLFs), in sharp contrast to most recent
work that relies entirely on&lt;br/&gt;shallow methods. Specifically, the
project investigates methods of (1)&lt;br/&gt;engineering a broad coverage
English grammar from the CCGbank, with semantic&lt;br/&gt;roles integrated from
Propbank; (2) scaling up OpenCCG for efficient parsing and realization with this
grammar, adapting supertagging and parse ranking methods for generation; (3)
adapting and extending previous methods of acquiring paraphrases to work on
DLFs; (4) generating high quality n-best paraphrases of one or more reference
sentences; and (5) experimentally evaluating whether the automatically generated
paraphrases can be used with current MT metrics to yield improved correlations
with human judgments of translation quality. &lt;br/&gt;&lt;br/&gt;By providing
a way to automatically approximate the HTER metric, the project will help drive
future MT research. Additionally, by dramatically extending the realization
capacity of OpenCCG, the project promises to benefit a wide range of NLP tasks
where the breadth of target texts is of crucial importance.