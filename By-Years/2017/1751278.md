* 1751278
* CAREER: User-Based Simulation Methods for Quantifying Sources of Error and Bias in Recommender Systems
* CSE,IIS
* 08/01/2018,07/31/2024
* Michael Ekstrand, Boise State University
* Continuing Grant
* William Bainbridge
* 07/31/2024
* USD 514,081.00

Systems that recommend products, places, and services are an increasingly common
part of everyday life and commerce, making it important to understand how
recommendation algorithms affect outcomes for both individual users and larger
social groups. To do this, the project team will develop novel methods of
simulating users' behavior based on large-scale historical datasets. These
methods will be used to better understand vulnerabilities that underlying biases
in training datasets pose to commonly-used machine learning-based methods for
building and testing recommender systems, as well as characterize the
effectiveness of common evaluation metrics such as recommendation accuracy and
diversity given different models of how people interact with recommender systems
in practice. The team will publicly release its datasets, software, and novel
metrics for the benefit of other researchers and developers of recommender
systems. The work also will inform the development of computer science course
materials about the social impact of data analytics as well as outreach
activities for librarians, who are often in the position of helping information
seekers understand the way search engines and other recommender systems affect
their ability to get what they need.&lt;br/&gt;&lt;br/&gt;The work is organized
around two main themes. The first will quantify and mitigate the popularity bias
and misclassified decoy problems in offline recommender evaluation that tend to
lead to popular, known recommendations. To do this, the team will develop
simulation-based evaluation models that encode a variety of assumptions about
how users select relevant items to buy and rate and use them to quantify the
statistical biases these assumptions induce in recommendation quality metrics.
They will calibrate these simulations by comparing with existing data sets
covering books, research papers, music, and movies. These models and datasets
will help drive the second main project around measuring the impact of feature
distributions in training data on recommender algorithm accuracy and diversity,
while developing bias-resistant algorithms. The team will use data resampling
techniques along with the simulation models, extended to model system behavior
over time, to evaluate how different algorithms mitigate, propagate, or
exacerbate underlying distributional biases through their recommendations, and
how those biased recommendations in turn affect future user behavior and
experience.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.