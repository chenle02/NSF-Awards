* 1617732
* SHF: Small: DeSCPar: Decoupled Supply-Compute Communication Management for Heterogeneous, Accelerator-Oriented Parallelism
* CSE,CCF
* 08/01/2016,07/31/2022
* Margaret Martonosi, Princeton University
* Standard Grant
* Danella Zhao
* 07/31/2022
* USD 300,000.00

Over the past decade, the deceleration of Moore's Law and Dennard Scaling has
required computing to make a dramatic shift towards the use of on-chip
parallelism in order to achieve computer systems performance scaling at
acceptable power budgets. Beyond that, systems have also dramatically increased
their use of heterogeneous processing elements and specialized accelerators.
Much of the complexity of this heterogeneous, accelerator-oriented parallelism
is exposed without sufficient abstraction to programmers and compiler writers.
As a result, achieving high performance often requires that programs include
detailed, platform-specific tailoring, particularly regarding the staging of
data as it moves between memory and compute elements, and from one compute
element to another. This platform-specific tailoring limits the portability of
such programs; when a new chip implementation is released, extensive software
reworks are often required to reclaim that high performance. Overall, the result
is that heterogeneous parallelism is reducing the performance portability of
application software. The DeSCPar research attacks this problem and represents
important research in improving programmability. Developed tools will be
distributed as free software, including a DeSCPar simulator and design tools. In
addition, the project includes a broad set of activities around improving the
diversity of the computing workforce.&lt;br/&gt;&lt;br/&gt;The DeSCPar approach
uses Decoupled Supply-Compute Parallelism to achieve portable performance on
highly parallel highly-heterogeneous systems. Inspired by Decoupled Access-
Execute approaches, DeSCPar likewise decouples value computations from the
memory accesses and address computations that "feed" them. By using automated
slicing techniques to split code into a data supply portion and a computation
portion, high-performance memory optimizations can be achieved while retaining
high-level application portability. In DeSCPar, value computation operations are
targeted to run on a CompD which may be a hardware accelerator, a specifically-
optimized CPU, or a general-purpose CPU. Likewise, memory supply code is aimed
at a SuppD, which can be specifically optimized for its task. By employing
varied combinations of SuppD and CompD units, richly heterogeneous systems can
be built, and software can be automatically mapped onto them. This project: (i)
proposes and prototypes automated compiler techniques (based on LLVM) for
slicing and optimizing DeSCPar code; and (ii) proposes and evaluates hardware
design optimizations based on the DeSCPar organizational structure.