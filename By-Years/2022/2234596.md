* 2234596
* PFI-TT:  Automatic Diagnosis of Video Quality Problems in Networked Camera Systems
* TIP,TI
* 03/15/2023,08/31/2024
* Rui Dai, University of Cincinnati Main Campus
* Standard Grant
* Samir M. Iqbal
* 08/31/2024
* USD 250,000.00

The broader impact/commercial potential of this Partnerships for Innovation -
Technology Translation (PFI-TT) project will enable a networked camera system to
produce videos with better quality. This project will design and demonstrate a
software prototype that automatically detects various video quality degradation
scenarios, provides feedback to human operators on the cause of quality
degradation, and recommends strategies to improve the quality of received
videos. The proposed prototype will save manual labor used for inspecting video
quality problems in networked camera systems. The solution can benefit various
video use cases in public safety, such as indoor and outdoor monitoring, traffic
surveillance, access control, and emergency operations. The results from this
project could also impact the design of a wide range of intelligent systems with
visual sensing in applications like smart health monitoring, industrial process
control, smart and connected vehicles, and virtual/augmented reality systems.
The students participating in this project will receive training in technology
commercialization and entrepreneurship. The project will also include
educational and outreach activities to broaden the participation of under-
represented minority students, helping to build the future workforce in the
field of computing.&lt;br/&gt;&lt;br/&gt;The proposed project aims to develop
and demonstrate a video quality assessment and adjustment software prototype for
networked camera systems. Multiple factors cause the degradation of video
quality in a networked camera system, such as noise or motion blur during video
capturing, degraded resolution, too much compression, and bad network
conditions. This project will develop a systematic video quality solution for
complex networked camera systems with sensing, processing, and communication
components. The proposed research will focus on: (1) investigating the system
settings and the data generated from a practical enterprise-level surveillance
system, (2) leveraging the characteristics of video quality evaluated by both
human users and automatic video analytics tools, (3) predicting video quality
through light-weight image analysis and video bitstream analysis, and (4)
predicting the types of video distortion and applying corresponding quality
restoration algorithms. The proposed technologies will be integrated in a
software prototype that could be used by the operators of enterprise-level
camera systems. Iterative development and evaluation tasks will be carried out
to ensure that the proposed prototype works well for systems with different
types of cameras, network scales and connections, and processing
units.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has
been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.