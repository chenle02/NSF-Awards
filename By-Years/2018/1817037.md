* 1817037
* SHF:Small: Tensor-Based Algorithm and Hardware Co-Optimization for Neural Network Architecture
* CSE,CCF
* 10/01/2018,03/31/2022
* Yufei Ding, University of California-Santa Barbara
* Standard Grant
* Sankar Basu
* 03/31/2022
* USD 499,998.00

Machine learning plays an important role in our daily life, including medical
data analysis, finance, autonomous driving and computer vision. Many popular
machine learning models are both data-intensive and computationally expensive.
In order to address this challenge, algorithm and architecture co-design and co-
optimizations are required to achieve better performance and energy efficiency.
This project aims to develop a more powerful learning architecture by
simultaneously optimizing the neural network algorithm and its hardware
implementation. The project will have a broad impact. The AI applications will
gain a significant performance boost if the computational and storage cost of
its algorithm can be reduced significantly. It will improve many applications
such as data mining, medical imaging analysis, computational biology, and
financial analysis. The project will greatly enrich the undergraduate and
graduate course curriculum and attract graduate and undergraduate students to
participate in this project and related workshops. Finally, this project will
develop new AI, VLSI and computer architecture workforce with solid background
in several areas including computational math, machine learning, and hardware
design.&lt;br/&gt;&lt;br/&gt;Tensors are a generalization of vectors and
matrices, and they are promising tools to represent and numerically process
high-dimensional data arrays. Leveraging the high effectiveness of tensor
computation in big-data analysis, this project will investigate three specific
topics towards designing high-performance and energy-efficient machine learning
hardware. First, theoretically sound and novel tensor numerical algorithms will
be developed to significantly reduce the training and inference cost of deep
learning. Second, the algorithm framework will be optimized on existing hardware
(e.g., GPU and FPGA) to achieve better performance, and to examine the main
challenges when running on hardware platforms. Finally, emerging design
technologies (e.g., 3-D process-in-memory) will be investigated to design
specific hardware libraries to perform fundamental tensor computation and to
further boost the performance and energy efficiency of the whole machine
learning architecture.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.