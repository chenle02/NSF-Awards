* 2046726
* CAREER: DeepTrust: Enabling Robust Machine Learning with Exogenous Information
* CSE,CNS
* 06/01/2021,05/31/2026
* Bo Li, University of Illinois at Urbana-Champaign
* Continuing Grant
* Dan Cosley
* 05/31/2026
* USD 186,970.00

Great advances in machine learning have led to state-of-the-art performance on a
wide range of tasks, such as image classification, machine translation, and
robotics. However, recent studies have shown that when machine learning models
are exposed to adversarial attacks, they can be fooled, evaded, and misled in
ways that would have profound security implications: image recognition, natural
language processing, and audio recognition systems have all been attacked
recently. As machine learning techniques are incorporated into safety-critical
systems, from financial systems to self-driving cars to medical diagnosis, it is
vitally important to develop trustworthy and robust learning approaches for
massive production and deployment of safety-critical machine learning
applications. Although there have been exciting progresses in the area of robust
learning, there is still a long way to go considering sophisticated real-world
adversaries. Thus, in this project the investigator aims to gain fundamental
understandings about adversarial properties and constraints, and develop machine
learning systems with robustness guarantees for different real-world
applications.&lt;br/&gt;&lt;br/&gt;One limitation of existing learning methods
is inherent in the fact that most existing methods have been treating machine
learning as a “pure data-driven technique” that solely depends on a given
training-set, without interacting with their rich exogenous information that is
not fully modeled by the data itself. This project aims to design novel
techniques to incorporate exogenous information in machine learning systems. In
particular, this project includes three aims, each of which addresses a unique
challenge of understanding and integrating exogenous information to design
robust machine learning systems: (1) the team of researchers will first focus on
understanding of intrinsic information such as model viability and leverage it
to design certifiably robust machine learning models/ensembles, (2) then the
researchers will focus on the extrinsic information such as domain knowledge to
design certifiably robust machine learning pipelines, (3) finally the
researchers will apply the proposed techniques to two safety-critical
applications, adversarial multimedia data detection and robust autonomous
vehicles, to demonstrate the practicality of the proposed
research.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.