* 1755593
* CRII: CHS: Predicting When, Why, and How Multiple People Will Disagree when Answering a Visual Question
* CSE,IIS
* 05/01/2018,04/30/2021
* Danna Gurari, University of Texas at Austin
* Standard Grant
* Ephraim Glinert
* 04/30/2021
* USD 174,947.00

The goal of a visual question answering (VQA) system is to empower people to
find the answer to any question about any image. For example, a VQA system could
enable blind people to address daily visual challenges such as learning whether
a pair of socks match or learning what type of food is in a can. VQA services
could also facilitate the creation of smarter environments, say to monitor how
many defective products are on a factory assembly line at any given time. A
limitation of existing VQA systems is that they do not account for the fact that
a visual question may elicit different answers from different people. VQA
systems could save time and reduce user frustration if they empowered users to
anticipate and resolve any answer disagreements that may arise. Blind and
sighted people could more rapidly and accurately learn about the diversity of
human perspectives on the visual world. VQA services also could teach people how
to ask visual questions that elicit the desired answer
diversity.&lt;br/&gt;&lt;br/&gt;This project will create artificial intelligence
(AI) models that can account for the possible diversity of answers inherent in
crowd intelligence. Specifically, AI models will be designed to predict when,
why, and how human answer disagreement occurs, which in turn will enable new
designs for human-computer partnerships. This is challenging because it
necessitates designing frameworks that simultaneously model and synthesize
different and potentially conflicting perceptions of images and language for the
many possible causes of disagreement. To ensure that the AI models generalize
across a broad range of applications, an existing corpus of over one million
visual questions asked by blind and sighted people will be used to create
annotated datasets that indicate when, why, and how much answer disagreement
arises. Methods will then be developed for automatically predicting directly
from a visual question how much answer diversity will arise from a crowd, and
why disagreement arises when it does. Finally, a system will be designed for
guiding visually-impaired users to more quickly formulate visual questions so
they can receive a single, unambiguous crowd response (e.g., guide the person to
better frame the visual content of interest with a mobile phone camera). User
studies with blind users will be conducted to empirically test the efficacy of
the new system, with a focus on uncovering human-based issues in real-world,
real-time situations.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.