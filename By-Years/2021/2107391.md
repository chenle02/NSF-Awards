* 2107391
* HCC: Medium: Improving Human-AI Collaboration on Decision-Making Tasks
* CSE,IIS
* 10/01/2021,09/30/2025
* Finale Doshi-Velez, Harvard University
* Standard Grant
* Todd Leen
* 09/30/2025
* USD 1,200,000.00

From loan approval to disease diagnosis, there are many situations in which
human decisions are being assisted by artificial intelligence (AI). For example,
a clinical decision support system might suggest a possible diagnosis or
highlight a potential medication interaction based on elements of the patient's
history that the human doctor might have otherwise missed. It was expected that
by combining the complementary strengths of people and AI systems (human+AI),
the quality of the decisions made in such settings would be better than that of
either people or machines alone. Unfortunately human+AI systems have not lived
up to this promise: Even with explainable AI, human+AI systems often perform
worse than either alone. Recent work shows that users of AI decision-support
often have a superficial understanding of the AI. This leads to inappropriate
levels of trust swinging from ignoring the AI to over-reliance. This project
will create human+AI systems that perform better than either alone. The research
team will develop and test specific tools and techniques that will be valuable
for creating effective human+AI decision systems across many
domains.&lt;br/&gt;&lt;br/&gt;The project will explore three ways of improving
AI-based decision support. Humans typically engage AI systems heuristically,
while successful interaction calls for an analytical approach by the human
partner. Only then can the human appropriately combine their knowledge with the
AI recommendation and its explanation. To encourage more analytic engagement,
the project will design and test (a) adaptive cognitive forcing functions:
cognitive interventions that guide the human to pay closer attention the AI's
information (applied only when most valuable to avoid frustrating the user), and
(b) intelligent contrasts: methods that ground the AI's information as a
contrast to what the human is likely to do. The latter will spark the human
user's curiosity about why the AI may be recommending something different than
the human. The last thrust involves building systems to help users understand
the AI in the context of the data that power it, enabling a more global
understanding of when the AI is likely to be useful. This project will explore
specific versions of each approach described above applied to clinical treatment
decision and to nutrition planning. The research results will enhance our
understanding of how to create better human+AI teams.&lt;br/&gt;&lt;br/&gt;This
award reflects NSF's statutory mission and has been deemed worthy of support
through evaluation using the Foundation's intellectual merit and broader impacts
review criteria.