* 8912767
* Functional VLSI Module-based Multiprocessor Architectures   for Real-time Vision
* CSE,CCF
* 07/15/1989,12/31/1992
* Dharma Agrawal, North Carolina State University
* Continuing Grant
*   name not available
* 12/31/1992
* USD 172,216.00

This project focuses on system integration of VLSI functional modules by
creating uniformity in their interface behavior. Such integration is aimed at
designing flexible, real-time, low-level vision systems using pipelining of
modules that correspond to individual operations. Two tasks are addressed in
this research. First, functional modules for benchmarking vision operations are
designed and characterized. Emphasis is placed on maintaining invariance in
control and input/output requirements with respect to changes in the parameters
of each operation. Second, algorithms and associated software for static mapping
of a given sequence of operations on a set of functional modules connected
through a network of switching nodes are developed. These algorithms balance the
workload of the modules in order to achieve high throughput. The
characterization of individual VLSI modules in terms of operation-specific
input/output, buffer sizes, and memory size allows more realistic prediction of
system performance. Multiprocessor architectures for vision can be classified as
homogeneous architectures and heterogeneous architectures. In homogeneous
architectures, exploiting parallelism optimally for the diversified operations
in vision is very difficult, while in heterogeneous architectures, only a small
set of low-level operations, relevant to the particular vision applications at
hand, are implemented. This research addresses the important problem of
developing functional modules and their integration in order to dynamically
tailor vision operations to the computer architecture at run time. Success in
this research allows better exploitation of parallelism for both low-level and
high-level vision operations.