* 1320498
* SHF:Small: Accurate and Computationally Efficient Predictors of Java Memory Resource Consumption
* CSE,CCF
* 09/01/2013,08/31/2017
* J. Eliot Moss, University of Massachusetts Amherst
* Standard Grant
* Anindya Banerjee
* 08/31/2017
* USD 450,000.00

The Java programming language is widely-used and of great commercial and
economic significance. It is favored in part because it features automatic
management of the computer memory resources it uses, simplifying such management
for the programmer. Memory management in Java (and other managed languages) has
reached a plateau in cost and effectiveness because most current techniques are
tuned based on a small number of coarse-grained measures gathered while programs
run. Substantial improvement might be gained from using more accurate estimation
of current and near-future memory use to drive better memory management
decisions. This would reduce the time, memory, and energy requirements to run
Java programs. This is of significance to the full range of Java applications
from small embedded systems through laptops and desktops to large servers. There
is therefore an urgent need for techniques to derive better online predictors of
Java memory use.

The long-term goal of the research program this award will support is to
substantially improve memory allocation and garbage collection effectiveness by
using better online predictors to drive more sophisticated allocator and
collector decisions. The objective of this particular project is to develop
machine learning techniques that induce accurate and computationally efficient
predictors of characteristics of Java memory allocation that influence memory
manager performance. Examples include predicting the volume of objects that
become "garbage" (can be reclaimed and reused for future allocations), as well
as objects that will be in use for a long time and will not become garbage soon.
The approach is to learn models that predict memory usage based on features
compiled from observable run-time events like calls to particular methods or
allocations of certain objects. Data to learn models will be obtained from
analysis of detailed program execution traces. Features will be selected that
are both informative of memory use and computable with low space and time
overheads. Programs will then be modified to compute these features as they run,
and real-time predictive models will be used to predict future memory usage as
programs execute. These predictions will be used to improve memory management
performance. This will be accomplished by, for example, improving the timing of
garbage collection so that it occurs at points during program execution that
result in higher memory reclamation with lower effort.