* 2127746
* Collaborative Research: III: Small: Entity- and Event-driven Media Bias Detection
* CSE,IIS
* 10/01/2021,09/30/2024
* Ruihong Huang, Texas A&M Engineering Experiment Station
* Standard Grant
* Sorin Draghici
* 09/30/2024
* USD 220,586.00

Democracy is shaped by public opinion, and public opinion in turn is
significantly influenced by the news that is read, watched, and listened to. It
is thus essential for an informed public to understand how the news they consume
is being selected, packaged, and presented. This project aims to build
computational systems to detect and quantify how media ideology affects the
creation and presentation of news at the level of articles and their constituent
events. This project will promote the transparency of news production and
enhance public awareness of media decisions. The developed tools can effectively
and efficiently support the measurement of media ideology at organization- and
article-levels, which facilitates research in broad areas, including political
science, social science, and communications. The proposed research will involve
graduate and undergraduate students from a diverse array of backgrounds,
especially underrepresented groups. The developed datasets and methods will form
the basis of modules in newly developed courses. The knowledge produced in the
project will be distributed to the public via demos, published blogs, talks at
podcasts, and guest essays to newspapers. &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;This
project will examine how media bias can result from the packaging of news via
the selection and organization of contents presented in news articles, and
develop entity- and event-driven computational models for detecting ideological
content selection and predicting article-level ideology. Three main research
tasks will be explored. First, discourse-aware event categorization models will
be developed to distinguish descriptions of main events from other context-
informing events and indirectly-related events. Second, an entity- and event-
driven contextual representation learning framework will be built to detect
media bias by capturing relations between entities and events. Third,
adversarial learning will be investigated to predict the political ideology of a
news article with a fine-grained score by disentangling media-specific languages
from ideological content.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.