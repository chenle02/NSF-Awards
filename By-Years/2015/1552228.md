* 1552228
* EAGER: Collaborative Research: Exploring Models for Conveying Imminent Robot Failures to Allow for Human Intervention
* CSE,IIS
* 09/01/2015,08/31/2017
* Holly Yanco, University of Massachusetts Lowell
* Standard Grant
* Ephraim Glinert
* 08/31/2017
* USD 200,656.00

In this exploratory research, the PIs will seek to advance the state of the
science on how best to convey a robot's imminent failure to a human (whether an
operator, supervisor, or bystander), in a manner that could allow the human to
intervene as effectively as possible to prevent the failure. This project has
the potential to dramatically increase the safety of humans in and around
autonomous robots and vehicles. Specific goals are to discover design principles
for robot systems with respect to conveying failure, and to identify methods for
expressing failure so that humans react appropriately. The research will focus
on three use cases: remote operation, co-located operation, and bystander
interaction. To these ends, the team will utilize a variety of robots in order
to support different applications and movement scales. Robots available to the
team include small and mid-size unmanned ground vehicles, human-scale torso
robots, a robot wheelchair, a telepresence robot, and an autonomous Jeep.
Project outcomes will impact the field of human-robot interaction and the future
use of robots in many application domains, particularly those of mobile and
manipulation robots, including autonomous vehicles, factory robots, and
assistive technology, by enhancing productivity and task performance, increasing
personal safety for those who work in hazardous occupations, and improving the
lives of persons with disabilities.&lt;br/&gt;&lt;br/&gt;The PIs' core research
questions are informed by their substantial prior work with task-oriented
robots. Based on that experience and other studies, they argue that the
following three main factors strongly influence user actions during robot
failure: perceived risk (e.g., a robot that crashes frequently is generally
perceived as a high risk robot), perceived severity (e.g., the failure of a
small robot made of soft materials is generally perceived as less severe than
that of a full body humanoid robot), and role (e.g., is the user an operators or
a bystander). Unexplored research questions about the manner in which these
factors impact failure include. How do these factors, both independently and in
combination, influence HRI during robot failures? How do humans utilize these
factors during robot failure, and does this utilization have high variability or
are humans very consistent? These factors will be used as independent variables
during studies which will advance knowledge in three core areas: formulation and
validation of generalizable quantitative and qualitative metrics for measuring a
person's response to an imminent failure in a robot system; discovery of
appropriate ways to communicate failure states to humans; and initial
development of common design guidelines for handling failures. The primary goal
is to make it easier for humans to rapidly understand failure events and to act
or assist appropriately in a timely manner. The PIs are specifically focused on
the human-robot interaction aspect of robot failures. As such, they will track
literature and research on diagnosing failures, but will not develop new systems
or concepts for this step. Instead, the team will seek appropriate and effective
ways to convey failures to humans, appropriate human responses during failures,
and appropriate failure states when human action is not possible or is
insufficient.