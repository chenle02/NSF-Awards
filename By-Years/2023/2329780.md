* 2329780
* PFI-TT: Broadening Real-Time Continuous Traffic Analysis on the Roadside using AI-Powered Smart Cameras
* TIP,TI
* 09/01/2023,08/31/2025
* Yezhou Yang, Arizona State University
* Continuing Grant
* Debora Rodrigues
* 08/31/2025
* USD 280,502.00

The broader impact/commercial potential of this Partnerships for Innovation -
Technology Translation (PFI-TT) project will allow democratization of advanced
Artificial Intelligence (AI) and computer vision technologies to enable
convenient and efficient traffic analysis for transportation system engineers
and local departments of transportation. Cities face various traffic-related
problems that need high-quality data to solve, such as congestion, accidents,
and road overload. With the smart roadside camera device developed from this
research, traffic operators can obtain real-time vehicle trajectory data at a
much lower cost and conduct traffic studies or make prompt decisions to improve
road safety and transportation efficiency. Moreover, the 21st century is the era
of information, and "data is the new oil" of digital prosperity. The
technologies generated from this proposed research can potentially spawn a set
of new applications for road transportation that benefit the nation's economy,
such as cheaper insurance with a fine-grained driving behavior analysis, safer
streets with accident alerts from roadside cameras, and better accommodation of
future automated vehicles with the insights from the data obtained through this
technology. Additionally, this research will broaden the research participation
in a primarily undergraduate institution and a Hispanic Serving Institution, as
well as train future leaders in innovation and entrepreneurship.

The proposed project focuses on novel technologies that allow traffic
researchers to collect fine-grained vehicle trajectory data that existing road
sensor systems cannot provide, analyze data in real-time, detect and classify
different vehicle types, estimate vehicle speeds and trajectories, and predict
potential collisions and accidents. Specifically, the project will develop three
technologies: First, a novel 3D vehicle model-based solution for accurate
vehicle tracking and localization using vehicle key point and Artificial
Intelligence (AI); Second, a method to accelerate AI on low-power edge devices
deployed on the roadside for real-time performance through AI model compression
and efficient parallel computing on the graphical processing unit (GPU); Third,
robustness improvement of machine vision in twilight by leveraging a novel type
of camera and multiple views. To demonstrate the usability of these novel
technologies, a set of road traffic data analysis applications will be
developed, including real-time online traffic visualization, fine-grained
traffic counting, road safety analysis with quantitative metrics, and traffic
incident detection. The outcome of this project will be realized in a roadside
smart camera device that can track and localize vehicles in the 3D space with
decimeter-level accuracy, real-time efficiency, and robustness under low
lighting conditions.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.