* 1618193
* RI: Small: Linguistic Semantics and Discourse from Leaky Distant Supervision
* CSE,IIS
* 08/01/2016,07/31/2020
* Hal Daume, University of Maryland, College Park
* Continuing Grant
* Tatiana Korelsky
* 07/31/2020
* USD 413,116.00

This project studies novel algorithms for building artificial intelligence (AI)
systems that can learn to improve their performance with a human in the loop.
Many recent AI successes are driven by large, expensive and difficult-to-collect
datasets. This yields systems that are deep, but narrow. The goal of this
project is to build technology that will allow AI systems to learn from their
interactions with people. The project focuses on key applications related to
natural language understanding: building technology to understand the meanings
of individual sentences, and integrate those meanings into the meaning of a
discourse or dialog. One specific application pursued herein relates to
extracting biomedical knowledge from text, which will pave the way to helping
biomedical researchers develop novel hypotheses. The work will fund students
from underrepresented groups in STEM, and encourage cross-disciplinary education
at the graduate and undergraduate levels. Finally, the work will be communicated
to the public not just with scientific papers, but internationally through
social media and locally through visits to middle schools and high
schools.&lt;br/&gt;&lt;br/&gt;Natural language processing (and other fields of
artificial intelligence) have had enormous success by training supervised
learning systems on large labeled datasets ("corpora"). Unfortunately, curating
such corpora is infeasible except for very specific problems. This happens
either because it is too expensive, or it is too difficult to get human labelers
to agree on an annotation standard. Instead of relying solely on human labeled
data, this project develops algorithms that can learn from human interaction.
These systems can continually improve their performance based on downstream
performance supervision, often with a human in the loop. This work leverages
recent developments on the structured contextual bandits learning framework
which provides a theoretically grounded and computationally efficient way in
which to develop novel approaches to distant supervision. This resulting
learning techniques will push advances in natural language understanding:
semantic parsing and discourse interpretation. Furthermore, the underlying
imitation learning technology is broadly applicable, including novel
applications to recurrent neural network models. To aid adoption by the research
community, code and data from this project will be released open source.