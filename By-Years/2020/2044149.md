* 2044149
* CAREER: Generalization and Safety Guarantees for Learning-Based Control of Robots
* CSE,IIS
* 08/01/2021,07/31/2026
* Anirudha Majumdar, Princeton University
* Continuing Grant
* Juan Wachs
* 07/31/2026
* USD 545,980.00

The ability of machine learning techniques to process rich sensory inputs such
as vision makes them highly appealing for use in robotic systems (e.g., micro
aerial vehicles and robotic manipulators). However, the increasing adoption of
learning-based components in the robotics perception and control pipeline poses
an important challenge: how can we guarantee the safety and performance of such
systems? As an example, consider a micro aerial vehicle that learns to navigate
using a thousand different obstacle environments or a robotic manipulator that
learns to grasp using a million objects in a dataset. How likely are these
systems to remain safe and perform well on a novel (i.e., previously unseen)
environment or object? How can we learn control policies for robotic systems
that provably generalize well to environments that our robot has not previously
encountered? Unfortunately, existing approaches either do not provide such
guarantees or do so only under very restrictive assumptions. This Faculty Early
Career Development (CAREER) project seeks to establish a foundational framework
for learning-based control of safety-critical robotic systems with guaranteed
generalization and safety. The project will impact challenging application
domains such as aerial inspection and manipulation (e.g., for infrastructure
repair tasks) and includes activities for (i) engaging regulatory agencies and
industry entities in discussions regarding the certification of learning-based
robotic systems, (ii) partnering with teacher preparation programs and other
educational programs to engage high-school and undergraduate students in
robotics, and (iii) widely disseminating materials from a new robotics course
which uses hands-on labs with drones. &lt;br/&gt;&lt;br/&gt;Motivated by the
need for guaranteeing the safety of learning-based robotic systems, this project
is developing a principled theoretical and algorithmic framework for learning
control policies for robotic systems with provable guarantees on generalization
to novel environments (i.e., environments that the robot has not previously
encountered). The key technical insight of this project is to leverage and
extend powerful techniques from generalization theory in theoretical machine
learning. The resulting framework provides bounds on the expected performance of
learned policies (including ones based on neural networks) across novel
environments. The project is developing algorithms (based on convex
optimization, gradient-based methods, and black-box optimization) for learning
policies that explicitly optimize these bounds. The project also seeks to
guarantee the robustness of learned policies to shifts in the distribution of
environments that the robot encounters. An important part of the effort is to
thoroughly validate the technical approach on hardware platforms including micro
aerial vehicles performing navigation, inspection, and aerial manipulation tasks
motivated by infrastructure repair applications. &lt;br/&gt;&lt;br/&gt;This
project is supported by the cross-directorate Foundational Research in Robotics
program, jointly managed and funded by the Directorates for Engineering (ENG)
and Computer and Information Science and Engineering
(CISE).&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has
been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.