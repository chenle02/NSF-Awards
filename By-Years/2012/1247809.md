* 1247809
* EAGER: Collaborative Research: Towards Modeling Human Speech Confusions in Noise
* CSE,IIS
* 08/01/2012,07/31/2015
* Jody Kreiman, University of California-Los Angeles
* Standard Grant
* Tatiana Korelsky
* 07/31/2015
* USD 100,000.00

This EArly-concept Grant for Exploratory Research (EAGER) supports an
exploratory study to evaluate model components for prediction of human speech
recognition in the presence of noise. Such a model has the potential to predict
confusions between fine phonetic distinctions in different levels of background
noise and at different speaking rates. The study takes advantage of modern
physiological results that indicate that the primary auditory cortex performs
spectro-temporal filtering; that is, that there are cells that are sensitive to
particular spectro-temporal modulations at each auditory frequency. In this
project, perceptual experiments in the presence of both stationary and non-
stationary additive noise and at different signal-to-noise ratios for a database
of CVC syllables recorded at 2 different speaking rates yield confusion
statistics. These statistics are then compared to those resulting from an
auditory model enhanced by elements incorporating these spectro-temporal
filters.

Successful results from this study will suggest enhancements to current hearing
models and ultimately, after a broader study for which this EAGER is a pilot,
advance the understanding of human speech perception. Background noise presents
a challenging problem for a variety of speech and hearing devices including
hearing aids and automatic speech recognition (ASR) systems. Since normal-
hearing human listeners are extremely adept at perceiving speech in noise, this
improved understanding of human models could lead to better artificial systems
for speech processing. The databases and tools developed for this study will be
disseminated to the research community.