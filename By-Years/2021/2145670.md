* 2145670
* CAREER: Foundations of Federated Multi-Task Learning
* CSE,IIS
* 06/01/2022,05/31/2027
* Virginia Smith, Carnegie-Mellon University
* Continuing Grant
* Rebecca Hwa
* 05/31/2027
* USD 589,057.00

Mobile phones, wearable devices, and smart homes form just a few of the modern
distributed networks generating a wealth of data each day. Due to the growing
computational power of edge devices, coupled with concerns over transmitting
private data, it is increasingly attractive to store data locally and push
network computation to the edge. Federated learning explores training machine
learning models at the edge in distributed networks. While federated learning
has shown tremendous promise for enabling edge applications, practical
deployment is currently stymied by a number of competing constraints. In
addition to being accurate, federated learning methods must scale to potentially
massive networks of devices, and must exhibit trustworthy behavior---addressing
pragmatic concerns related to issues such as user privacy, fairness, and
robustness. In this project, we explore multi-task learning, a technique that
learns separate but related models for each device in the network, as a unified
approach to address the competing constraints of federated learning. The
objective of the project is to develop scalable multi-task learning methods that
are suitable for practical federated networks, and to rigorously study the
foundational properties of federated multi-task learning in terms of the goals
of accuracy, scalability, and trustworthiness. In doing so, the research will
unlock a new generation of federated learning systems that can holistically
address the constraints of realistic federated
networks.&lt;br/&gt;&lt;br/&gt;The goal of this project is to establish and
rigorously study the use of federated multi-task learning. While the accuracy
benefits of federated multi-task learning are well-known, the work charts two
new directions. First, the project develops methods to realize multi-task
learning at scale in massive federated networks. Secondly, the project shows
that multi-task learning, by improving privacy, fairness, and robustness, is in
fact key for trustworthy federated learning. The technical aims of the project
work are divided into three thrusts. First, by approximating standard notions of
multi-task learning, the project will develop and rigorously study a family of
highly scalable federated multi-task learning objectives. Second, the privacy
implications of multi-task learning will be analyzed and evaluated in order to
understand trade-offs between privacy and utility in federated networks.
Finally, this project will explore tensions between fairness (in terms of
performance disparities across devices) and robustness (to data and model
poisoning attacks) in federated learning. Although these goals may be at odds,
this project aims to show that multi-task learning can inherently improve both
fairness and robustness, helping both to be achieved jointly. Taken together,
this work has the potential to cause a paradigm-shift in the way federated
learning systems are designed, implemented, and
analyzed.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.