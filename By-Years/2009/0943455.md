* 0943455
* Supercomputing on a Cluster of Workstations via Scalable Locality and Scalable Parallelism
* CSE,CCF
* 09/15/2009,02/28/2013
* David Wonnacott, Haverford College
* Standard Grant
* Almadena Chtchelkanova
* 02/28/2013
* USD 129,661.00

Modern scientific research often includes a substantial computational component,
which may use a supercomputer and special software to automatically tune
("optimize") the application for the computer. A cluster of standard
workstations can offer similar net processing power at a fraction of the cost,
but automatic optimization of some important numerical applications for these
systems remains an elusive challenge. The quest for good performance of parallel
applications on clusters of workstations has traditionally employed software
techniques that are quite different from those applied to the programming of
parallel supercomputers. In particular, static automatic parallelization has
been employed on supercomputers (especially for dense matrix codes on shared
memory systems) but has not been successful on clusters. The lack of success
with static parallelization is due in part to the inability of classic
parallelization techniques to expose sufficient memory locality.

The PI proposes to develop compiler techniques that will allow dense matrix
problems to run efficiently on clusters of workstations by dramatically
increasing locality while respecting the parallelism constraints of the code.
The PI plans to investigate techniques for automatically producing high
performance for dense matrix codes executing on clusters of workstations by
"tiling" time-skewed loop nests such that they can execute efficiently on a
cluster of multicore workstations. This research will enable automatic program
optimization for numerical applications. The proposed activity could advance the
state of performance models for tiling for clusters.