* 1925178
* NRI: FND: Creating Trust Between Groups of Humans and Robots Using a Novel Music Driven Robotic Emotion Generator
* ENG,CMMI
* 11/01/2019,10/31/2023
* Gil Weinberg, Georgia Tech Research Corporation
* Standard Grant
* Alex Leonessa
* 10/31/2023
* USD 803,892.00

This project will perform fundamental research contributing to the establishment
of trust between humans and robots through the development of novel emotional
communication channels. As co-robots become prevalent at home, work, and public
spaces, they need to become trust-worthy and socially believable agents if they
are to be integrated into and accepted by society. The research will utilize the
latest developments in Artificial Intelligence to gain knowledge about of the
role of non-linguistic expressions in trust building. Findings from studies
about non-linguistic emotional expressions such as prosody and gestures in music
- one of the most emotionally meaningful human experiences - will be implemented
in a group of newly developed personal robots. User experiments will be
conducted to explore humans' reactions to - and trust building with - these
prosody-driven robots. Results of the study will lead to novel approaches for
creating open and meaningful interactions between groups of humans and robots.
The research will advance national prosperity by increasing engagement,
relatability, and trust in large scale human-robot interactive scenarios such as
personal robots in private and public spaces, work place training, education,
and combat. The project takes an interdisciplinary approach, which will address
fields such as cognitive science, communication, and music, while leading to
progress in both science and engineering.&lt;br/&gt;&lt;br/&gt;Prosodic features
such as pitch, loudness, tempo, timbre, and rhythm bear strong resemblance to
musical features, which can inform a novel approach for generative emotion-
driven robotic prosody. The first phase of this project will focus on developing
machine learning techniques to derive features from a newly created emotionally
labeled musical dataset. It will use these features to drive a non-linguistic
robotic voice synthesizer that conveys emotional content and builds trust. The
results of this study will be integrated with previous work on conveying robotic
emotions through physical gestures. The second phase of the project will focus
on user experiments that will study subjects' preference to a variety of robotic
emotional responses when interacting with a single robot. It will use the
learned features to design a larger scale robotic emotional contagion engine in
an effort to improve and enrich emotion-driven human interaction with large
groups of robots.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.