* 2237830
* CAREER: Reinforcement Learning-Based Control of Heterogeneous Multi-Agent Systems in Structured Environments: Algorithms and Complexity
* ENG,ECCS
* 07/01/2023,06/30/2028
* Yi Zhou, University of Utah
* Continuing Grant
* Huaiyu Dai
* 06/30/2028
* USD 415,209.00

Reinforcement learning (RL) is a popular framework for learning optimal
decision-making in complex environments, and many RL algorithms have been
developed to improve decision-making of a single agent in normal environments.
However, modern large-scale distributed learning applications usually involve
multiple heterogeneous agents that interact with complex environments, making
the optimal decision-making fundamentally more challenging to learn. For
example, when navigating multiple drones in an open area, the drones need to
properly cooperative with each other and take the environment uncertainty into
account. As another example, in distributed wireless networks, the interaction
of the agents (e.g., base stations or mobile phones) are subject to
heterogeneous constraints on power and bandwidth, etc. This project aims to
develop a resilient RL framework for managing heterogeneous multi-agent systems
in complex environments, and systematically design efficient multi-agent RL
algorithms with comprehensive convergence and complexity analysis. The project
will produce RL algorithm packages that are fully accessible to the public. The
research activities will also generate positive educational impacts on
undergraduate and graduate students. The materials developed by this project
will be integrated into courses on machine learning and optimization, and will
benefit interdisciplinary students majoring in electrical and computer
engineering, statistics and computer science. The project will actively involve
underrepresented students and integrate research with education for
undergraduate and graduate students in STEM. It will also produce introductory
materials for K-12 students to be used in engineering summer research
programs.&lt;br/&gt;&lt;br/&gt;The overarching goal of this project is to
develop a resilient RL framework for managing multi-agent systems that involve
heterogeneous agents in complex and structured environments, and systematically
design scalable and computation-efficient RL algorithms with rigorous and
comprehensive convergence and complexity analysis for managing such systems. The
proposed research includes three major thrusts. First, to manage cooperative
agents with heterogeneous constraints in various types of structured
environments (e.g., homogeneity and uncertainty), the environment model
structure will be leveraged to develop fully decentralized policy optimization
algorithms with convergence and complexity analysis. Second, to manage
competitive agents with heterogeneous constraints in uncertain environment, new
tractable notions of constrained and robust equilibrium will be proposed. Their
fundamental structures and properties will be studied, based on which fully-
decentralized primal-dual type policy optimization algorithms and robust value-
based algorithms with convergence guarantees will be developed. Lastly, to
improve the generalizability of agentsâ€™ policies across heterogeneous
environments, a new assistive RL framework that can substantially enhance the
generalizability using few rounds of information exchange without data sharing
will be developed. These RL algorithms will be applied to learn resilient and
optimal control policies for interference management in wireless networks and
energy control in power networks.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.