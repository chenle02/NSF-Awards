* 0307906
* Representation and Reasoning about Adaptive Interfaces
* CSE,IIS
* 07/15/2003,06/30/2007
* Daniel Weld, University of Washington
* Continuing Grant
* Douglas H. Fisher
* 06/30/2007
* USD 506,951.00

Previous work on adaptive websites, wearable computing and intelligent user
interfaces has shown that these tasks present significant challenges to the
fields of machine learning, knowledge representation, and reasoning under
uncertainty. This project will address the following core artificial
intelligence problems using adaptive interfaces as inspiration and an
experimental testbed.&lt;br/&gt;&lt;br/&gt;1) Given a database of behavioral
data for one or more users, what is the best representation for encoding a
predictive model of user behavior? What are the best algorithms for learning
such a model? This project will generalize Markov models and Dynamic Bayes Nets
to create Relational Markov Models (RMMs) and Dynamic Probabilistic Relational
Models (DPRMs) respectively. Effective inference and learning algorithms will be
developed and evaluated against traditional propositional
methods.&lt;br/&gt;&lt;br/&gt;2) Representing user interfaces is a major
challenge. This project will extend the work on task-centered user-interface
design with ideas from the planning literature (sensory actions, exogenous
events) to develop an expressive task formalism with clear
semantics.&lt;br/&gt;&lt;br/&gt;3) Adapting an interface, which is represented
as an augmented plan schema, requires new methods for reasoning about actions.
In addition to analyzing causal dependency structures, restructuring operations
akin to partial evaluation will be necessary. Fast inference is an essential
component of this project. A satisficing plan is not good enough, so the work
will use a utility model combining plan length with a cognitive dissonance
factor. &lt;br/&gt;&lt;br/&gt;Methodologically, the project is composed of six
coupled activities: (1) Formalize the RMM and DPRM representations; (2) Devise
efficient particle-filtering inference methods; (3) Develop learning algorithms
based on shrinkage; (4) Formalize a declarative, plan-based interface
representation, and evaluate expressiveness on a corpus of adaptation examples;
(5) Devise a comprehensive set of adaptation transformations and a utility
metric; (6) Implement the methods, incorporate in a user interface platform, and
perform extensive experiments. &lt;br/&gt;&lt;br/&gt;The research will have
broad impact, because progress in user interfaces has been dwarfed by the
simultaneous enormous increase in the speed of computers. Artificial
intelligence techniques are perhaps the most promising avenue for harnessing
processing power to increase user productivity. This project will contribute to
improved user interfaces not only in desktop software but also in personalized
information systems for wearable computers.&lt;br/&gt;