* 1714566
* RI: Small: ConnotationNet: Modeling Non-Literal Meaning in Context
* CSE,IIS
* 09/15/2017,08/31/2021
* Yejin Choi, University of Washington
* Standard Grant
* Tatiana Korelsky
* 08/31/2021
* USD 499,838.00

The major goal of this research is to develop a new computational framework to
recover and reason about a wide range of connotative meanings in language, i.e.,
why something is written and how it will affect the readers. This contrasts with
the vast majority of previous research on semantic processing, where the primary
focus has been on understanding the denotational meaning of language, i.e., what
is written in text. This research will create new computational solutions to a
wide range of tasks that require understanding non-literal meaning in text,
including societally important challenges such as automatic detection and
revision of biases in modern literature and media that can work against
minorities and underrepresented groups.

This research will develop Connotation Frames as a new representation formalism
to organize a variety of connotative implications associated with a particular
choice of a predicate. This representation will substantially extend the
existing resources of frame semantics, which has focused primarily on
denotational meanings, by introducing new typed relations to encode various
aspects of connotative meanings. Capitalizing on recent advances in
distributional representation of words and phrases, this research will develop
algorithms that can infer connotation frames from a large-scale natural language
corpus, which reflects how connotative meanings arise from how people use
language in context. The learned representations will be organized as
ConnotationNet, an evolving broad-coverage connotation lexicon for words,
frames, and phrases. Knowledge encoded in this lexicon will then be used for
document-level text understanding, where partially present information in text
will be combined with the rich connotative knowledge stored in ConnotationNet to
infer the complete the document-level connotation of given text. In parallel,
this research will seek new language generation models that can learn to revise
or compose text with the desired connotative effects with specific focus on
unwanted biases in modern literature and media against underrepresented groups.