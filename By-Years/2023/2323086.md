* 2323086
* RI: Small: Integrating physics, data, and art-based insights for controllable generative models
* CSE,IIS
* 09/01/2023,08/31/2026
* Pavan Turaga, Arizona State University
* Standard Grant
* Jie Yang
* 08/31/2026
* USD 595,507.00

Generative models refer to a large class of machine learning techniques that can
generate user-specified media – including images, video, 3D environments, and
text – from inputs such as text prompts, sketches, or other user provide images.
New generative models are rapidly being developed and are seen as increasingly
important in many different applications such as in chatbots and automation.
Current generative models are characterized by extremely large models trained on
web-scale data, but on closer inspection are found to be unreliable in
critically important contexts. This project focuses on generative models for
visual media, where current generative models will be advanced by leveraging
prior knowledge about how visual features can be described by physical and
statistical laws. The sources of knowledge that will be leveraged include
physics-based knowledge, insights from traditional content creation techniques,
and advances in modeling latent-spaces using novel geometric methods. The
anticipated benefits include more robust models, smaller scale models, and more
interpretable and modular models.

This research systematically investigating the basics of generative-adversarial
networks. The first task considers the role of the input probability
distribution from which samples are drawn, generalizing to non-parametric
distributions tuned to reduce distribution mismatch under sample mixing. The
second task involves architectural novelty in terms of detail layering, where
synthesis is broken into a series of simpler architectures. The third task
focuses on developing reduced parameter discriminator models, using
orthogonality-type constraints as a proxy for physical variables like lighting,
texture, and deformation. The fourth task focuses on developing shape-aware
architectures, using learnable polynomial basis functions to represent shape
more directly. Applications for these methods include augmenting training-sets
to create trustworthy machine learning models in contexts such as manufacturing
and health, where it is difficult to gather large training sets. Curricular
innovations include creating access to these approaches for non-STEM students,
in a class titled Machine Learning for Media Arts.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.