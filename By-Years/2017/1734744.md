* 1734744
* NCS-FO: Active Listening and Attention in 3D Natural Scenes
* EDU,DUE
* 08/01/2017,07/31/2023
* Cynthia Moss, Johns Hopkins University
* Standard Grant
* Ellen Carpenter
* 07/31/2023
* USD 1,155,675.00

As humans and other animals move around, the distance and direction between
their bodies and objects in their environment are constantly changing. Judging
the position of objects, and readjusting body movements to steer around the
objects, requires a constantly updated map of three-dimensional space in the
brain. Generating this map, and keeping it updated during movement, requires
dynamic interaction between visual or auditory cues, attention, and behavioral
output. An understanding of how spatial perception is generated in the brain
comes from decades of research using visual or auditory stimuli under restricted
conditions. Far less is known about the dynamics of how natural scenes are
represented in freely moving animals. This project will bridge this gap by
studying how freely flying bats navigate through their environment using
echolocation. Specifically, a team of engineers and neuroscientists will
investigate how the bat brain processes information associated with flight
navigation. The project team will provide education and training in engineering
and science to public school, undergraduate and graduate students, and to
postdoctoral researchers. This research will also contribute to a rich library
of materials, including videos and a website, which will be available to
educators and scientists working in both the private and public
sectors.&lt;br/&gt;&lt;br/&gt;This project leverages innovative engineering
tools, cutting-edge neuroscience methods and neuroethological modeling to pursue
a multidisciplinary investigation of dynamic feedback between 3D scene
representation, attention and action-selection in freely moving animals engaged
in natural tasks. The echolocating bat, the subject of the project's research,
actively produces the acoustic signals that it uses to represent natural scenes
and therefore provides direct access to the sensory information that guides
behavior. The specific goals of the project are to test the hypotheses that 1)
natural scene representation operates through the interplay between sensory
processing, adaptive motor behaviors, and attentional feedback, 2) spatio-
temporal responses to sensory streams across ensembles of neurons sharpen when
an animal adapts its behavior to attend to selected targets, and 3) spatio-
temporal sharpening of neural responses enables figure-ground segregation in the
natural environment. The project integrates 1) novel acoustic measurements and
computational analyses to represent the sonar scene based on reconstructions of
the bat's sonar transmitter and receiver characteristics, combined with a 3D
acoustic model of the environment, 2) quantitative analysis of the echolocating
bat's adaptive echolocation and flight behaviors as it negotiates complex
environments, 3) multichannel neural telemetry recordings from the midbrain of
the free-flying bat as it attends to targets, obstacles and other acoustic
signals in its surroundings, and 4) computational modeling of auditory system
architecture, attention and working memory mechanisms. Collectively, this
research will deepen the understanding of behavioral modulation of natural scene
representation. &lt;br/&gt;&lt;br/&gt;This project is funded by Integrative
Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a
multidisciplinary program jointly supported by the Directorates for Computer and
Information Science and Engineering (CISE), Education and Human Resources (EHR),
Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE).