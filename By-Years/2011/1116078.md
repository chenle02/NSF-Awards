* 1116078
* RI: Small: Coordinating Multi-Agent Learning through Emergent Distributed Supervisory Control
* CSE,IIS
* 09/01/2011,08/31/2014
* Victor Lesser, University of Massachusetts Amherst
* Standard Grant
* Hector Munoz-Avila
* 08/31/2014
* USD 450,000.00

The project is focused on developing coordination policies for large-scale
multi-agent systems operating in uncertain environments through the use of
multi-agent reinforcement learning (MARL). Existing MARL techniques do not scale
well. This research addresses the scaling issue by using coordination technology
to "coordinate" the individual agent learning so as to speed up convergence and
lead to learned policies that better reflect overall system objectives. This
novel idea is being implemented using an emergent supervisory organization with
low overhead that exploits non-local information to dynamically coordinate and
shape the learning processes of individual agents while still allowing agents to
react autonomously to local feedback. A key question is how to automate the
development of the supervisory control process (including supervisory
information generation and organization formation). One approach to automation
is using a formal model of interactions among agents that also includes a model
of global system objectives and policy space of agents to derive the information
necessary for appropriate supervisory control. Another approach is the
formulation of the supervision problem as a distributed constraint optimization
problem. The results of this work provide a necessary component for the
development of a wide variety of next-generation adaptive applications, such as
smart power grids, cloud computing, and large-scale sensor networks. The broader
impact stems from the wide applicability of the resulting learning technology
for distributed control, undergraduate and graduate educational activities at
UMass, dissemination efforts that make the experimental domain and algorithms
publically available, and the development of international collaborations.