* 0306611
* Markov Decision Problem and Linear Programming
* MPS,DMS
* 08/15/2003,07/31/2007
* Yinyu Ye, Stanford University
* Standard Grant
* Henry Warchall
* 07/31/2007
* USD 205,100.00

The aim of this proposal is to further develop the complexity &lt;br/&gt;theory
of Linear Programming (LP), which continually plays a &lt;br/&gt;central role in
complexity analysis. In particular, we analyze the &lt;br/&gt;Markov Decision
Problem (MDP) with n states and m actions &lt;br/&gt;for each state, a special
class of real-number linear programs &lt;br/&gt;with the Leontief matrix
structure. The research objectives and &lt;br/&gt;activities include the
following: 1) Develop a new class of &lt;br/&gt;algorithms, "combinatorial
interior-point algorithms", for &lt;br/&gt;solving the MDP, with the best
achievable complexity result and &lt;br/&gt;practical efficiency; and establish
certain complexity lower &lt;br/&gt;bounds for the MDP, which may provide a
"negative result" on &lt;br/&gt;the quest for whether or not there is a strongly
polynomial time &lt;br/&gt;algorithm for LP. 2) Both undergraduate and graduate
students &lt;br/&gt;will participate in the project, new course materials on the
MDP &lt;br/&gt;will be produced, and the PI will also give presentations to the
&lt;br/&gt;Stanford Summer Program for grades K-12 and community
&lt;br/&gt;college students in the Bay Area. 3) Apply the new fast MDP
&lt;br/&gt;algorithm to research activities in function areas such as Call
&lt;br/&gt;Admission and Routing, Strategic Asset Allocation,
Supply-&lt;br/&gt;Chain Management, Emissions Reductions, and Semiconductor
&lt;br/&gt;Wafer Fabrication.&lt;br/&gt;&lt;br/&gt;Due to the relentless
research effort in LP algorithms, a linear &lt;br/&gt;program can be solved
today one million times faster than it was &lt;br/&gt;done twenty years ago.
Businesses, large and small, use linear &lt;br/&gt;programming models to
optimize communication systems, to &lt;br/&gt;schedule transportation networks,
to control inventories, to plan &lt;br/&gt;investments, and to maximize
productivity. Furthermore, LP &lt;br/&gt;has become a popular subject now taught
in undergraduate, &lt;br/&gt;graduate, and MBA curriculums, advancing human
knowledge &lt;br/&gt;and promoting scientific understanding. Recently, there has
been &lt;br/&gt;a renewed and strong interest in the MDP (a special large-scale
&lt;br/&gt;LP) due to its wide applications. With the rising demand in
&lt;br/&gt;telecommunication network resources, effective management is
&lt;br/&gt;as important as ever. Call Admission (deciding which calls to
&lt;br/&gt;accept/reject) and routing (allocating links in the network to
&lt;br/&gt;particular calls) are examples of decisions that must be made at
&lt;br/&gt;any point in time. The objective is to make the "best" use of
&lt;br/&gt;limited network resources. Such sequential decision problems
&lt;br/&gt;can be addressed by a dynamic programming model and the
&lt;br/&gt;MDP. Another application: the threat of global warming that
&lt;br/&gt;may result from the accumulation of carbon dioxide and other
&lt;br/&gt;"greenhouse gases" poses a serious dilemma. In particular, cuts
&lt;br/&gt;in emission levels bear a detrimental short-term impact on
&lt;br/&gt;economic growth. At the same time, a depleting environment
&lt;br/&gt;can severely hurt the economy - especially the agricultural
&lt;br/&gt;sector - in the longer term. To complicate the matter further,
&lt;br/&gt;scientific evidence on the relationship between emission levels
&lt;br/&gt;and global warming is inconclusive, leading to uncertainty about
&lt;br/&gt;the benefits of various cuts. One systematic approach to
&lt;br/&gt;considering these conflicting goals involves the formulation of a
&lt;br/&gt;dynamic system and MDP model that describes our
&lt;br/&gt;understanding of economic growth and environmental science,
&lt;br/&gt;as is done by Nordhaus. However, these MDP problems are too
&lt;br/&gt;complex to be solved by the current MDP solvers. A major
&lt;br/&gt;objective of the project is to develop new Markov Decision
&lt;br/&gt;Algorithms such that these models would be effectively
&lt;br/&gt;analyzed to satisfaction. Progress in the area of developing
&lt;br/&gt;efficient algorithms for solving large-scale stochastic decision
&lt;br/&gt;problems will be of great significance in improving industrial
&lt;br/&gt;competitiveness, scientific understanding, and technology
&lt;br/&gt;learning.&lt;br/&gt;