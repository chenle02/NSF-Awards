* 2143440
* CAREER: Approximate inference at the intersection of neuroscience and machine learning
* CSE,IIS
* 10/01/2022,09/30/2027
* Ralf Haefner, University of Rochester
* Continuing Grant
* Kenneth Whang
* 09/30/2027
* USD 154,649.00

Finding patterns in complex data is of great importance to modern society. It
lies at the heart of forecasting in business and economics, analyzing data from
large-scale experiments, and powering the ongoing revolution in artificial
intelligence and machine learning. The brain faces exactly the same challenge:
how to extract behaviorally relevant patterns in the large amounts of data it
receives from its senses, including millions of photoreceptors in the eyes. This
project will investigate two important aspects of the computations underlying
this process: how to decide whether to combine two pieces of information, for
instance, from two photoreceptors, or even two different senses, and the
consequences of doing so not instantaneously and exactly, but over time and
approximately. By investigating these questions in the brain, this project aims
to extract insights that are relevant for both neuroscience and machine
learning. The main contributions of this project to neuroscience and cognitive
science are a deeper understanding of the central computational motif underlying
sensory processing and new computational theories of confirmation bias and
attention. The central contributions to machine learning will consist in
suggesting architectural changes to current deep learning architectures and in
evaluating their performance benefits. In its educational part, this project
will develop and evaluate a curriculum for an interdisciplinary, research
project-based college-level course for educating the next generation of
computational neuroscience and machine learning
researchers.&lt;br/&gt;&lt;br/&gt;This project focuses on two key questions: (1)
What is the architecture of the deep probabilistic model that the brain has
learned, and (2) How does the brain perform approximate and sequential, as
opposed to exact and instantaneous, inference in this model? The researchers
will address the first question by proposing a deep hierarchical causal
inference-based model for motion perception. They will quantitatively test this
model using human psychophysical experiments and collaborate to test it using
neurophysiology experiments. The relationship of the probabilistic model's
central computational motif to other computations such as divisive normalization
and predictive coding will be explored. In collaboration with machine learning
researchers the benefits of incorporating the computational insights into deep
learning systems will be quantified. The second research aim investigates the
consequences of approximate inference computations in two contexts. First, the
researchers will develop a rigorous computational theory relating limited
biological and computational "resources" during approximate inference. Second,
they will compare the biases due to approximate inference with those found in
humans using psychophysical evidence integration tasks. In preliminary data the
emergence of a conﬁrmation bias as the result of approximate inference was found
-- both in the context of passive interpretation of visual evidence, and in the
context of active inference using eye-movements. In addition to a better
understanding of inference in the brain, the goal of this work is to yield
insights into strategies for how to counter biases and design efficient
artiﬁcial intelligence systems.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.