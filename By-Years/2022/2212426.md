* 2212426
* Collaborative Research: SHF: Medium: Approximate Computing for Machine Learning Security: Foundations and Accelerator Design
* CSE,CCF
* 08/01/2022,07/31/2026
* Nael Abu-Ghazaleh, University of California-Riverside
* Continuing Grant
* Almadena Chtchelkanova
* 07/31/2026
* USD 388,873.00

Deep Neural Networks (DNNs) are achieving state-of-the-art performance on a
large and expanding number of application domains. However, one of the threats
to their wide-scale deployment is vulnerability to adversarial machine learning
attacks, where an adversary injects small perturbations to the input data that
cause the DNN to misclassify, with potentially dangerous outcomes (for example,
mistaking a stop sign for a speed limit sign). In this project, the researchers
will explore how building DNNs with approximate computing elements improves
their robustness to these adversarial attacks. Approximate computing is a
technique to build computing elements that are simpler (and therefore higher
performing and more sustainable) but do not compute the exact result of an
operation. The investigators will explore how to select approximate computing
elements and use them in building sustainable DNN accelerators that balance
performance, accuracy, and security.&lt;br/&gt;&lt;br/&gt;The proposal's
expected contributions include developing new insights into the relationship
between approximation and robustness of DNNs. The project will explore what
types of approximation techniques result in effective DNNs that balance
accuracy, performance, sustainability, and protection against adversarial
attacks and develop optimization frameworks that can find optimal operating
points along these dimensions. It will also explore how to build new approximate
computing elements specifically targeted toward this application. The project
will use these findings to build sustainable, performant, and accurate DNN
accelerators. The project will also explore other approximate computing-based
techniques to protect against other types of attacks threatening the security
and privacy of DNNs, as well as for different deep neural network learning
structures. The project is expected to have significant impacts on security,
sustainability, and accuracy of machine learning models. The research team will
share all of the byproducts of the research with the research community. The
project will train graduate and undergraduate students. The investigators will
develop new educational material for use in machine learning, computer
architecture, and computer security classes.&lt;br/&gt;&lt;br/&gt;This award
reflects NSF's statutory mission and has been deemed worthy of support through
evaluation using the Foundation's intellectual merit and broader impacts review
criteria.