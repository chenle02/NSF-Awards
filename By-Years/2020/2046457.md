* 2046457
* CAREER: Towards Conversational Recommendation Systems: Explainability, Fairness, and Human-in-the-Loop Learning
* CSE,IIS
* 10/01/2021,09/30/2026
* Yongfeng Zhang, Rutgers University New Brunswick
* Continuing Grant
* Sylvia Spengler
* 09/30/2026
* USD 335,771.00

Recent advances in Artificial Intelligence (AI) have accumulated a rich toolbox
of models for information retrieval, natural language processing and
personalized recommendation. By optimizing over benchmark datasets, many of the
models were developed with an algorithmic consideration instead of putting human
as the central consideration. However, the ultimate goal of AI is to serve
humans, collaborate with humans, and, ultimately, benefit humans. As a result,
algorithmic approaches to AI must put humans in the loop for model design,
implementation and validation. This project focuses on conversational AI, a
promising approach towards putting humans in the loop, which enables direct
conversation between human and AI for model learning. In particular, the project
explores conversational recommender systems to help users in information seeking
and decision making. It will develop explainable and fairness-aware algorithms
for conversational recommendation. Presentation of the work and demos will help
to engage with wider audiences that are interested in computational research. By
integrating transparency and fairness principles into computer science courses
on areas such as Information Retrieval, Data Mining and Artificial Intelligence,
results from the project will educate students to understand how AI can be not
only useful but also socially responsible.&lt;br/&gt;&lt;br/&gt;This project
will develop a general framework for conversational recommendation that bridges
natural language understanding and dialog state management. With the framework,
the project will explore three directions. The first direction aims at
developing explainable conversation strategies based on human-machine
collaborative reasoning, which brings cognitive ease to users and helps to build
trust between human and AI. The second direction explores fairness-aware
conversation strategies based on short-term and long-term fairness learning,
which helps to achieve fair recommendation experiences between advantages and
disadvantaged users. The third direction aims at developing a learning to
evaluate protocol for conversational recommendation, which unifies the
advantages of online crowd-sourcing and offline model learning for evaluation.
The project will also develop a prototype conversational recommendation platform
as a class project to support the education of responsible AI. The project will
result in the dissemination of shared data and evaluation platforms to the
Information Retrieval, Data Mining, Recommender System, and broader AI
communities.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission
and has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.