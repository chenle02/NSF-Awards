* 2305532
* Uncertainty Modeling of Learning to Enable Probabilistic Perception
* CSE,IIS
* 09/15/2023,08/31/2026
* Mark Campbell, Cornell University
* Standard Grant
* Cang Ye
* 08/31/2026
* USD 598,876.00

Modern prediction models (e.g., neural networks) have revolutionized
applications ranging from business analysis to robotics. Much of the development
has focused on increasing average prediction accuracy via extensive data
collections and architectures. However, a key weakness of many of these models
is that they simply provide an output, with no sense of the confidence or the
accuracy of the result. Prediction accuracy of these models can vary based on
the amount and diversity of the training data, the model architecture, and the
test environment. For example, visual localization models degrades in poor
weather, and object detectors do more poorly in environment in which objects can
be obscured. Yet in either example, there is typically no measure of accuracy
for the predictions. However, other types of prediction models do include
measures of the accuracy in their outputs. A success approach has been shown in
the probabilistic perception algorithms, which have been handling uncertain
outputs, including outliers, for many years. GPS navigation systems must
function in the presence of multi-path errors from buildings, and radar tracking
sensors must function even with the return of many false positives due to
clutter. Successful perception algorithms using these sensors have been
developed because there exists uncertainty models capturing most errors. This
project will develop new predictions models that merge deep learning outputs
with probabilistic perception/reasoning algorithms to improve the ability of
robots to navigate in uncertain environments.

This research will develop formal uncertainty models of deep learning outputs in
combination with probabilistic perception/reasoning algorithms to create
holistic, high-integrity frameworks for key robotics functions such as
localization, tracking and forecasting. This project leverages the best of both
deep learning (processing large amounts of data quickly and accurately) and
perception (reasoning over errors and mistakes). By considering three different
classes of learning and perception problems (localization, tracking,
forecasting), the work will more easily transition to other application domains
such as robots in the home, warehouse, busy hotels/museums/train stations, and
warehouses; and aerial and underwater vehicles. The project will make datasets
and software available to the community, and research results will be
disseminated through publications, conferences, courses, industry-targeted
workshops and PI meetings. A comprehensive plan for broadening participation
will be implemented including hosting under-represented students, working with
high school and under-represented students, and training and mentoring
undergraduate and graduate students.

This project is supported by the cross-directorate Foundational Research in
Robotics program, jointly managed and funded by the Directorates for Engineering
(ENG) and Computer and Information Science and Engineering (CISE).

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.