* 2303735
* POSE: Phase II:  Building an Open-Source Ecosystem for Deep-Learning Hardware-Software Co-Design
* TIP,TI
* 09/01/2023,08/31/2025
* Yakun Sophia Shao, University of California-Berkeley
* Standard Grant
* Peter Atherton
* 08/31/2025
* USD 1,499,708.00

Domain-specific acceleration is one of the most promising approaches to further
improve performance and energy efficiency applications like deep learning.
Despite the large number of startups and large companies developing specialized
hardware and software for deep learning, all the existing implementations are
proprietary, without a viable, freely open-source deep-learning hardware-
software stack. The lack of an open and shared ecosystem not only makes it
extremely hard to compare different implementations, it also significantly slows
innovation and increases design costs as every organization needs to start their
implementations from scratch.

The overall objective of this proposal is to establish an open-source ecosystem
that enables the development of full-stack deep-learning systems at scale to
build next-generation deep-learning platforms. If successful, the outcomes of
this project point toward a future in which developers with a great idea in
either deep-learning hardware or software can quickly evaluate, design, and
demonstrate their idea in an end-to-end fashion on real hardware and software,
significantly lowering the design cost and accelerating the pace of innovation.
Specifically, the open-source product consists of three key components based on
our mature research projects: Exo for code generation (https://github.com/exo-
lang/exo), Gemmini for deep-learning accelerator design (https://github.com/ucb-
bar/gemmini), and Chipyard for system-on-chip integration
(https://github.com/ucb-bar/chipyard). In particular, the proposed hardware-
software ecosystem will fundamentally address challenges in 1) how to evaluate
the end-to-end performance of deep-learning accelerators with the software
stack; 2) how to generate efficient deep-learning hardware accelerators for
specific scenarios; and 3) how to integrate accelerators with general-purpose
cores and evaluate them in FPGA and fabrication. The hardware-software ecosystem
established from this project will create a diverse and highly motivated open-
source community for future developments on deep-learning acceleration through
hardware-software co-design.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.