* 1801307
* SaTC: CORE: Medium: Collaborative: Contextual Integrity: From Theory to Practice
* CSE,CNS
* 09/01/2018,08/31/2024
* Helen Nissenbaum, Cornell University
* Continuing Grant
* James Joshi
* 08/31/2024
* USD 399,980.00

Current user-facing computer systems apply a "notice and consent" approach to
managing user privacy: the user is presented with a privacy notice and then must
consent to its terms. Decades of prior research show that this approach is
unmanageable: policies are vague, ambiguous, and often include legal terms that
make them very difficult to understand, if they are even read at all. These
problems are magnified across Internet of Things (IoT) devices, which may not
include displays to present privacy information, and may become so ubiquitous in
the environment that users cannot possibly determine when their data is actually
being captured. This project aims to solve these problems by designing new
privacy management systems that automatically infer users' context-specific
privacy expectations and then use them to manage the data-capture and data-
sharing behaviors of mobile and IoT devices in users' environments. The goals of
this research are to better understand privacy expectations, design privacy
controls that require minimal user intervention, and demonstrate how emergent
technologies can be designed to empower users to best manage their
privacy.&lt;br/&gt;&lt;br/&gt;The theory of "Privacy as Contextual Integrity"
(CI) postulates that privacy expectations are based on contextual norms, and
that privacy violations occur when data flows in ways that defy these norms. The
framework can be applied by modeling data flows in terms of the data type,
sender, recipient, as well as the specific context (i.e., the purpose for which
data is being shared). While this model makes intuitive sense, there are several
open research questions that have prevented it from being applied in computer
systems. Specifically, the project investigates how privacy expectations change
across varying contexts through the use of surveys, interviews, and behavioral
studies, and designs systems to automatically infer contextual information so
that the process of determining whether or not a data flow is likely to defy
user expectations can be automated. The investigators develop a prototype of the
novel privacy controls and validate their usability and privacy-preserving
properties through iterative laboratory and field
experiments.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission
and has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.