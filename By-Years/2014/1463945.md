* 1463945
* CRII: RI: Planning and learning with macro-actions in cooperative multiagent systems
* CSE,IIS
* 02/01/2015,11/30/2016
* Christopher Amato, University of New Hampshire
* Standard Grant
* Hector Munoz-Avila
* 11/30/2016
* USD 174,798.00

The proposal aims at studying the problem of decentralized planning. The general
technical area is decentralized partially observable Markov decision process
(Dec-POMDP). The PI proposes a theory on macro-actions by using finite-state
controllers of Dec-POMDPs. Macro-actions enable the planner to perform multiple
planning steps in a single computation cycle whereas a planner using regular
actions can only perform one action in each computation cycles. As a result,
macro-actions have the potential to solve planning problems much more
efficiently enabling (1) distributed planning tasks across multiple agents, (2)
planning in environments where agents have only limited knowledge about the
state of the world, and (3) planning in uncertain environments where actions
might have multiple outcomes.&lt;br/&gt;&lt;br/&gt;There are many potential
areas of application of this research including distributed agents monitoring a
network for security breaches, distributed military planning, and coordinating
multiple robots involved in disaster recovery tasks.