* 1640078
* E2CDA: Type I: Collaborative Research: Energy Efficient Learning Machines (ENIGMA)
* CSE,CCF
* 09/01/2016,08/31/2021
* H S Philip Wong, Stanford University
* Continuing Grant
* Sankar Basu
* 08/31/2021
* USD 678,480.00

The project will aim to develop computing hardware and software that improve the
energy efficiency of learning machines by many orders of magnitude. In doing so
it will enable large societal adoption of such machines, paving the way for new
applications in diverse areas such as manufacturing, healthcare, agriculture,
and many others. For example, machines that learn the behavioral trends of
individual human beings by collecting data from myriads of sensors may be able
to design the most appropriate drugs. Similarly, one may envision machines that
learn trends in the weather and thereby assist in predicting the most optimized
preparations for the next crop cycle. The possibilities are literally endless.
However, the canonical learning machines of today need huge amount of energy,
significantly hindering their adoption for widespread applications. The goal of
this project will be to explore, evaluate and innovate new hardware and software
paradigms that could reduce energy dissipation in learning machines by a
significant amount. The team of researchers consists of experts in mathematics,
neuroscience, electronic devices and materials and computer circuit and system
design that will foster a unique platform for both innovative research and
interdisciplinary training of graduate students.&lt;br/&gt;&lt;br/&gt;We are
witnessing a regimental shift in the computing paradigm. For a vast number of
applications, cognitive functions such as classification, recognition,
synthesis, decision-making and learning are gaining rapid importance in a world
that is infused with sensing modalities, often paraphrased under a common term
of "Big Data", that are in critical need of efficient information-extraction.
This is in sharp contrast to the past when the central objective of computing
was to perform calculations on numbers and produce results with extreme
numerical accuracy. We aim to approach this problem by exploiting cognitive
models that have shown efficacy in "one shot" learning. In this approach, the
information is represented by means of high dimensional (HD) vectors. These
vectors follow a set of predetermined mathematical operations that ensure that
the resulting vector after such operations is unique. The uniqueness can in turn
be used as "learning" and the predefined nature of mathematical operations make
the learning "one shot". When paired with traditional artificial neural network
or deep learning algorithms, such "one shot" learning could significantly reduce
the number of necessary computing operations, leading to orders of magnitude
reduction in energy dissipation. We shall explore the entire computer hierarchy,
staring from materials and devices, all the way up to system design and
optimization to exploit the unique capabilities afforded by the HD computing,
with the ultimate objective of realizing energy efficient learning machines
(ENIGMA).