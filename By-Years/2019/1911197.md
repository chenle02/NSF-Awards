* 1911197
* RI: Small: Understanding Subtle Non-Social Facial Expressivity to Boost Learning and Computer Interaction
* CSE,IIS
* 10/01/2019,09/30/2023
* Aaron Seitz, University of California-Riverside
* Standard Grant
* Jie Yang
* 09/30/2023
* USD 499,999.00

Facial expressions play a significant role in everyday communication among
humans. Computer understanding of these complex and subtle expressions will lead
to highly capable interactive cyber-human systems with proactive computers that
make more appropriate responses to human interactions. This project brings
together an interdisciplinary team of investigators to address key challenges
associated with spontaneous microexpression recognition in non-social scenarios.
The project concentrates on generating bio-feedback from humans while learning
skills, such as online learning, and being recorded and analyzed in continuous
color and depth video streams. It will develop computer algorithms for human-
machine synergy and test how this information can provide for superior learning
when training applications are augmented with expression-informed bio-feedback
in near real-time. This represents a significant step forward in training
machines to recognize and classify facial microexpressions and maximizing the
synergy of cyber-human systems that will improve the quality of life
experiences. It will provide a computing environment within the reach of common
people in which the interests or even the health of people can be detected and
predicted, with significant impacts on skill learning, education and information
retrieval.&lt;br/&gt;&lt;br/&gt;The project develops an approach to the
understanding of complex and subtle facial microexpressions and bio-feedback
where the synergy between cyber and human systems can be fully exploited. It
addresses key challenges associated with computational understanding and
modeling of intelligence in challenging, realistic contexts. It uses assessment
and intervention based on facial microexpressions to maximize synergy of cyber
and human systems for skill learning. First, it considers deep learning and
closed-loop video analysis for optimized skill learning in a reinforcement
learning framework. Second, it develops novel representation of facial
microexpressions from color and depth video streams and use them for person
independent emotion recognition as well as person-specific emotions recognition
when a learning task is adapted. Third, it exploits not only the color camera
but also the integrated depth camera for precise measurements, which has not
been used for microexpressions. The focus is to determine the extent to which
real-time classification of microexpressions can provide for more appropriate
interactivity that will facilitate human learning in real applications. The
results will be broadly disseminated through a website that will have regular
releases of databases and software tools by offering tutorials, workshops and
demos at major professional meetings.&lt;br/&gt;&lt;br/&gt;This award reflects
NSF's statutory mission and has been deemed worthy of support through evaluation
using the Foundation's intellectual merit and broader impacts review criteria.