* 1918140
* FMitF: Collaborative Research: Track I: Preventing Human Errors in Cyber-human Systems with Formal Approaches to Human Reliability Rating and Model Repair
* CSE,CCF
* 08/15/2019,07/31/2023
* Eunsuk Kang, Carnegie-Mellon University
* Standard Grant
* Pavithra Prabhakar
* 07/31/2023
* USD 399,000.00

Human error is a major factor in failures across safety-critical domains. Such
failures are very complex, with human errors often arising as a result of
unexpected interactions between system automation and human behavior. Thus,
researchers have investigated how formal methods tools and techniques, which
have been developed to mathematically prove properties about complex computer
systems, can be adapted to human-automation interaction (HAI) problems. These
techniques are powerful and capable of discovering unexpected, critical human
errors and system failures. However, existing techniques do not provide a means
for fixing discovered human errors. Further, interface changes both introduce
new unforeseen errors and risk negative transfer effects, where changes that
conflict with previously learned behaviors can also cause problems. This project
will investigate a novel approach to HAI evaluation and repair that will help
designers and analysts efficiently eliminate many kinds of potential interaction
errors while minimizing the risk of introducing additional human errors. The
developed methods will be validated in design cases of real safety-critical
systems including an industrial furnace, nuclear power plant procedures, a
radiation therapy machine, and pharmacy medication dispensing processes. The
knowledge and tools produced in this research will be made available to
researchers and designers and have potential applications to a wide range of
many safety-critical systems. This, in turn, will help avoid system disasters,
prevent injuries, save lives, and protect critical resources across
society.&lt;br/&gt;&lt;br/&gt;The project is divided into three main thrusts.
First, the team will develop a theoretically grounded method for scoring the
likelihood that humans will behave erroneously for a given HAI design through a
novel synthesis of formal methods, erroneous human behavior models, negative
transfer theory, and human reliability analyses. Second, it will introduce a new
theory of formal model repair in interactive systems that will underlie the
development of methods for removing problematic HAI errors by adapting both
human-machine interfaces and the workflow of the associated tasks. Third, the
scoring and model repair methods will be combined to allow automated model
repair to find design interventions that will reduce the likelihood of changes
causing problematic human errors, using a database of common error patterns and
solutions to be developed through the project. Across all three of these
thrusts, the team will use human subject experiments, testing, and formal proofs
to validate that the advances achieve their hypothesized capabilities. The work
will lead to improved methods for evaluating human reliability aspects of
interfaces, widen the application of formal methods to new contexts, and provide
resources for researchers, designers, and engineers to improve the reliability
of cyber-human systems.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.