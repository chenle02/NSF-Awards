* 1725743
* SPX: CISIT: Computing In Situ and In Memory for Hierarchical Numerical Algorithms
* CSE,CCF
* 10/01/2017,09/30/2020
* Lizy John, University of Texas at Austin
* Standard Grant
* Marilyn McClure
* 09/30/2020
* USD 800,000.00

High performance computing holds an enormous promise for revolutionizing
science, technology, and everyday life through modeling and simulation,
statistical inference, and artificial intelligence. Despite the numerous
successes in software and hardware technologies, energy efficiency barriers have
become a major hurdle towards more powerful computers -- from mobile devices all
the way to supercomputers. The originally natural separation between the memory
subsystem and the central processing unit (CPU) of a computer has emerged as one
the main reasons for energy inefficiency. Data movement between the memory and
the CPU requires orders of magnitude more energy than the computations
themselves. To address these challenges, this project will consider novel
architectural design paradigms and algorithms that are aimed at blurring these
traditional boundaries between separated memory and computation subsystems and,
by distributing computations to be performed directly in the memory or as part
of the memory data transfers, achieve order of magnitude gains inenergy
efficiency and performance. This project will investigate such novel approaches
in the context of a class of methods in computational mathematics, which appear
at the core of many problems in computational science, large-scale data
analytics, and machine learning.&lt;br/&gt;&lt;br/&gt;Specifically, this project
will focus on data-driven rather than compute-driven co-design of algorithms and
architectures for the construction, approximation, and factorization of
hierarchical matrices. The end-goal of the project is the design of a novel
architecture, CISIT (for ``Computing In Situ and In Transit''), that
specifically aims to address acceleration of both computation and data movement
in the context of hierarchical matrices. CISIT will uniquely combine traditional
general-purpose CPU and GPU cores with: (1) acceleration of core algorithmic
primitives using custom hardware; (2) in-situ computing capabilities that will
comprise both processing in or near main memory as well as computing within on-
chip caches and memory close to the cores; (3) novel in-transit compute
capabilities that will enable cutting down on and in many cases completely
eliminating unnecessary roundtrip data transfers by processing of data
transparently as it is transferred between main memory and local compute cores
across the cache hierarchies. Upon success, CISIT will influence future
architectural implementations. Along with the research activities, an
educational and dissemination program will be designed to communicate the
results of this work to both students and researchers, as well as a more general
audience of computational and application scientists.