* 2129173
* SaTC: CORE: Small: Probing Fairness of Ocular Biometrics Methods Across Demographic Variations
* CSE,CNS
* 10/01/2021,09/30/2024
* Ajita Rattani, Wichita State University
* Standard Grant
* Jeremy Epstein
* 09/30/2024
* USD 200,000.00

Biometrics technology related to recognizing the identities and traits of people
has been widely adopted in intelligence gathering, law enforcement, and consumer
applications. Recent studies suggest that face-based biometric technology does
not work equitably across demographic variations. There is a pressing need to
investigate fair biometric solutions and modalities toward accurate, fair, and
trustworthy technology for enhanced security and public safety. Ocular
biometrics, which consists of regions in and around the eyes, offers an
alternate solution to face biometrics due to its accuracy and privacy.
Furthermore, ocular biometrics can be acquired using regular cameras even in the
presence of face covering. This project investigates the fairness of ocular
biometric technology and develops solutions to mitigate unequal accuracy gaps
across demographic variations. This project spans a highly multidisciplinary
research area, which integrates engineering, statistics, mathematics, computing,
and policy. The findings of this project are used to update the engineering
curricula, including computer vision, image analysis, machine learning, deep
learning, and biometrics. The advances made in this project are disseminated
through publications, the investigator website, and seminars. This project also
provides opportunities to broaden the participation of women, underrepresented
minorities, and undergraduate students in computing.&lt;br/&gt;&lt;br/&gt;This
project investigates the fairness of ocular biometrics scanned in visible and
NIR (Near-infrared) spectrum across demographic variations. The machine and deep
learning models trained for ocular-based individual analysis are evaluated for
unequal accuracy rates across demographic variations. The cause of unequal
accuracy rates in the machine and deep learning algorithms are analyzed using
explainable AI. The fairness-aware classifiers are developed by modifying the
objective function, using ensemble techniques, and learning fair feature
representation. Existing and publicly available ocular datasets are utilized for
the evaluation and security analysis of the classifiers used in this study. The
efficacy of the proposed solutions is assessed through standard biometric
performance and fairness evaluation metrics.&lt;br/&gt;&lt;br/&gt;This award
reflects NSF's statutory mission and has been deemed worthy of support through
evaluation using the Foundation's intellectual merit and broader impacts review
criteria.