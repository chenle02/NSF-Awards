* 1464553
* RI: Small: Language Induction meets Language Documentation: Leveraging bilingual aligned audio for learning and preserving languages
* CSE,IIS
* 09/01/2014,09/30/2018
* David Chiang, University of Notre Dame
* Continuing Grant
* D.  Langendoen
* 09/30/2018
* USD 470,000.00

Thousands of the world's languages are in danger of dying out before they have
been systematically documented. Many other languages have millions of speakers,
yet they exist only in spoken form, and minimal documentary records are
available. As a consequence, important sources of knowledge about human language
and culture are inaccessible, and at risk of being lost forever. Moreover, it is
difficult to develop technologies for processing these languages, leaving their
speech communities on the far side of a widening digital divide. The first step
to solving these problems is language documentation, and so the goal of this
project is to develop computational methods based on automatic speech
recognition and machine translation for documenting endangered and unwritten
languages on an unprecedented scale.

To be successful, any approach must guarantee both the sufficiency and
interpretability of the documentation it produces. This project ensures
sufficiency by using a combination of community outreach, crowdsourcing
techniques, and mobile/web technologies to collect hundreds of hours (millions
of words) of speech. The interpretability is enabled by augmenting original
speech recordings with careful verbatim repetitions along with translations into
a well-resourced language. Finally, computational models are developed to
automate transcription of recordings and alignment with translations, resulting
in bilingual aligned text. The result is a kind of digital Rosetta Stone: a
large-scale key for interpreting the world's languages even if they are not
written, or no longer even spoken.