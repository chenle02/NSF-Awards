* 2139936
* AF: Small: An Algorithmic Theory of Brain Behavior:  Concept Representation and Learning in Spiking Neural Networks
* CSE,CCF
* 06/01/2022,05/31/2025
* Nancy Lynch, Massachusetts Institute of Technology
* Standard Grant
* Peter Brass
* 05/31/2025
* USD 500,000.00

This project aims at understanding computation in the brain, in terms of
abstract, interacting, distributed algorithms. It assumes a mathematical model
of computation based on directed graphs (nodes and connecting edges), where the
nodes correspond to neurons and the edges correspond to nerve fibers by which
neurons may influence each other. The project studies problems that are typical
of those solved by actual brains, such as problems of focusing attention, making
decisions, detecting similarity between sensed odors or visual scenes, and
recognizing and learning concepts with interesting structure. It studies these
problems using techniques from theoretical computer science. This work has both
biological and computer-science motivations. The algorithmic perspective is
expected to help in understanding the computational mechanisms employed by
biological neural networks. On the other hand, many of the problems that are
solved by these networks are also fundamental in computer science and artificial
intelligence; studying them in the setting of biological neural networks is
expected to offer a new perspective and yield new results. Biological algorithms
are naturally flexible, robust, and adaptive---properties that are also
desirable for modern computer systems.&lt;br/&gt;&lt;br/&gt;In more detail, this
work is based on a synchronous, stochastic Spiking Neural Network (SNN) model.
Previously, the investigator and collaborators used this type of model to study
several problems including Winner-Take-All decision-making, data compression and
clustering, and learning of simple hierarchically-structured concepts. They
produced new algorithms (networks) and analyzed them in terms of costs such as
network size and convergence time. They also discovered some cost tradeoffs and
proved related lower bound results. This project continues this research
program, but now focusing on the central issues of how concepts are represented
in the brain, how those representations are used, and how they may be learned.
"Concepts" here encompass both logical concepts, such as hierarchical structures
and linguistic constructs, and physical concepts, such as moving objects. A main
thesis is: "Structure that is naturally present in real-world concepts gets
mirrored in their neural representations, in a way that facilitates both
learning and recognition." This project uses approaches from theoretical
computer science, notably, distributed and probabilistic algorithms, as well as
linear algebra and complexity theory, to investigate this hypothesis. Another
emphasis of the project is on how noise and uncertainty affect the costs of
solving problems in brain networks, as well as the choice of representations.
Still another is on how the brain may combine networks that solve simpler
problems into larger networks that solve more complex problems. Specifically,
the project is studying (1) fundamental theoretical questions about SNN models
and their computing power, (2) common neural primitives (such as Winner-Take-
All) that may be used to solve more complex brain problems, (3) questions about
efficient static representations of structured concepts in brain networks, and
(4) questions about how such representations can be
learned.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.