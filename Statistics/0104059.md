
* 0104059
* Computer-intensive Methods for Nonparametric Time Series Analysis
* DMS,STATISTICS
* 07/01/2001,06/14/2001
* Dimitris Politis,CA,University of California-San Diego
* Standard Grant
*  Shulamith T. Gross
* 06/30/2004
* USD 94,500.00

Resampling and subsampling offer viable approaches to obtaining valid
distributional approximations in the context of dependent data while assuming
very little about the underlying stochastic mechanism. Many important questions
still need to be addressed in order for these modern approaches to be applied
safely and accurately in practice. The main issues the investigator wishes to
tackle include the following: (a) Extend the realm of applicability of
subsampling by considering self-normalized statistics and/or extrema of time
series with possibly heavy tails together with extrapolation/interpolation of
subsampling estimators. (b) Investigate the performance of the Local Bootstrap
in forming confidence bands for conditional moments and prediction intervals for
future values of a Markov process, as well as constructing hypothesis tests for
time-reversibility. (c) Show that nonparametric estimation of conditional
moments via flat-top kernel smoothing is not appreciably affected by the curse
of dimensionality when the underlying function is ultra-smooth. (d) Investigate
the performance of the newly proposed Local Block-Bootstrap in the case of a
nonstationary series with a slowly-changing stochastic structure. (e) Propose
the Tapered Block-Bootstrap algorithm, and show that it achieves superior
performance as compared to the well-known Block-Bootstrap. (f) Propose a new
block/bandwidth choice estimator with superior rate of convergence. And finally
(g) consider the issue of a possibly integrated time series, and propose a new
computer-intensive procedure, the Continuous-Path Block-Bootstrap, for
statistical inference. Correlated data, such as time series and spatial data,
are often encountered in many diverse scientific disciplines including
economics, meteorology, electrical engineering, etc. The general goal of this
project is to further the development of computer-intensive statistical analysis
methods that are applicable in the setting of correlated data but do not rely on
unrealistic or unverifiable model assumptions. Addressing this issue fruitfully
will have many practical applications. For example, in a daily series of
exchange rates or stock returns spanning a decade (or more), there may be
evidence that the stochastic structure of the series has not been invariant over
such a long stretch of time. Creating a practical way to model such
nonstationarities and devising appropriate resampling methods for inference
would be most helpful for economic applications. For a different application,
consider the problem of stochastic simulation of manufacturing systems or a
Gibbs-type sampler simulation; the development of subsampling/resampling for
`almost' stationary time series would be most helpful in order to assess
convergence and accuracy of the simulation. In the context of spatial statistics
(e.g., mining and geostatistics, atmospheric and environmental science, etc.),
the data typically correspond to measurements obtained at spatial points that
are irregularly spaced. For example, a measurement may indicate the quality or
quantity of the ore found in some location X, or a measurement of precipitation
or air quality at location Y during a fixed time interval. The irregular nature
of the measurement locations presents an added complication that, however, can
be by-passed by specially designed versions of resampling/subsampling.
