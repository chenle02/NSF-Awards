* 1617639
* RI: Small: High Confidence, Efficient Learning Under Rich Task Specifications
* CSE,IIS
* 08/01/2016,07/31/2020
* Scott Niekum, University of Texas at Austin
* Standard Grant
* James Donlon
* 07/31/2020
* USD 470,000.00

Artificially intelligent machines such as autonomous vehicles and personal
robots are poised to contribute in many economic sectors, but cannot be deployed
on a large scale without measurable confidence that they will operate correctly.
This is especially true for safety-critical systems in which humans could be
injured or infrastructure could be damaged by incorrect behavior. The proposed
research will address this key issue by developing methods that allow
intelligent agents to learn to perform challenging tasks and adapt to new
situations, while simultaneously providing strong guarantees of correctness and
safety. Once deployed, these future robotic systems will have broad impacts on
society ranging from automating small manufacturing to giving new freedom to
disabled and elderly populations through safe and personalized in-home care. The
proposed robotics applications will additionally create opportunities for
interactive educational K-12 programs to encourage interest in STEM areas, as
well as undergraduate and graduate education.&lt;br/&gt;&lt;br/&gt;Towards these
goals, the proposed work focuses on three primary research thrusts: 1) We will
design safe learning algorithms that provide theoretical probabilistic
satisfaction and data efficiency guarantees over both the expected reward of a
policy and its correctness with respect to a high-level specification. 2) In
order to account for the gap between theoretical and practical efficiency in
learning, we will develop model-based and model-free off-policy evaluation
methods that leverage active sampling strategies and bootstrapping to achieve
practical efficiency. 3) We will develop hybrid techniques that combine and
amplify the advantages of both strong theoretical and efficient practical
guarantees. The merit of the proposed algorithms will be systematically
evaluated on complex, real-world problems in robotic reconfigurable
manufacturing that require learning optimized, yet safe policies with a high
degree of confidence in settings with low-to-medium quantities of available
data.