* 2008741
* RI: Small: Neural Sequences as a Robust Dynamic Regime for Spatiotemporal Time Invariant Computations.
* CSE,IIS
* 10/01/2020,09/30/2023
* Dean Buonomano, University of California-Los Angeles
* Standard Grant
* Kenneth Whang
* 09/30/2023
* USD 499,634.00

The temporal dimension is of fundamental importance to understanding the brain
because one of the brain's primary function is temporal in nature: the brain
uses information about the past (memories) to predict the future. As a result of
the inherently temporal nature of brain function the brain has evolved
mechanisms to tell time, encode time, and perform time-dependent computations.
These computations endow animals with the ability to quickly learn to anticipate
external events (for example when a red light should change), and to recognize
and generate complex temporal patterns (such as those that underlie speech or
Morse code). A feature of the brain's computational abilities is referred to as
"temporal scaling," for example, the ability to talk, play music, or tap a Morse
code message at different speeds. The neural mechanisms underlying timing and
temporal scaling remain poorly understood. Furthermore, although dramatic
advances have taken place in the field of machine learning, current machine
learning approaches do not capture how the brain performs temporal computations
or achieves temporal scaling. Emerging experimental data suggest that the brain
may encode time and implement temporal scaling through a number of different
dynamic regimes including ramping (increasing firing rates with time) or neural
sequences (transient sequential activation of neurons). This project seeks to
understand how time-dependent computations are performed in recurrent neural
networks, and proposes that neural sequences provide an optimal solution to the
problem of temporal scaling. This project will contribute to advances in the
ability of artificial systems to capture the computational power of the brain.
Associated education and outreach efforts are closely related to the
research.&lt;br/&gt;&lt;br/&gt;Two main approaches will be used. First, machine-
learning based supervised recurrent neural networks will be trained on a number
of different timing tasks--including a Morse code task that requires producing a
complex temporal pattern at different speeds--in order to determine if neural
sequences represent a general solution to the problems of encoding time and
temporal scaling. Second, neuronal and synaptic properties that are mostly
absent from current machine learning approaches will be used to develop a model
of how neural sequences emerge and undergo temporal scaling in a biologically
plausible fashion. Specifically, cortical synapses exhibit short-term synaptic
plasticity, in which the strength of synapses change in a use-dependent manner
over the course of hundreds of milliseconds, these dynamics can in turn be
modulated--accelerating or slowing short-term synaptic plasticity. It is
hypothesized that this modulation of short-term synaptic plasticity is one way
the brain implements temporal scaling. Overall, this project will lead to novel
biological principles being applied towards machine learning, and further
advance the ability to emulate the brainâ€™s computational
strategies.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.