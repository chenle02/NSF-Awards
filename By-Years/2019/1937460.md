* 1937460
* RTML: Small: Collaborative: A Programming Model and Platform Architecture for Real-time Machine Learning for Sub-second Systems
* CSE,CCF
* 10/01/2019,09/30/2024
* Simon Laflamme, Iowa State University
* Standard Grant
* Sankar Basu
* 09/30/2024
* USD 248,000.00

This project develops and evaluates novel frameworks for achieving real-time
machine learning; that is, for a given target application that is producing a
lot of data, how to process that data to concurrently prediction what comes next
while learning from the past data at the same pace of the target application.
The developed framework will produce adaptive models suitable to predict the
behavior of the complex dynamics found in sub-second systems. Such systems
include adaptive airbag deployment mechanisms, hypersonic vehicles, and active
impact mitigation systems. Solutions will be developed to learn the dynamics at
the data rates required to enable real-time decision-making systems such as
those used for active control and adaptive operations. These solutions are
designed for direct integration into sub-second systems to increase their
resilience, robustness, safety, and viability. It follows that this research
will impact society by enabling sub-second systems and empowering decision-
making capabilities at speeds never reached before. Several undergraduate
students will be included in the project with an emphasis on providing research
experiences to underrepresented, first-generation, and low-income students by
leveraging existing and valuable resources at both the University of South
Carolina and Iowa State University. This project will also produce two
multidisciplinary Ph.D. students with expertise in machine learning, high-rate
dynamics, and control. &lt;br/&gt;&lt;br/&gt;The novelty of the approach taken
in this project is to tune hyper-parameters to facilitate the use of an array of
concurrent models to hide training latency. More specifically, field
programmable gate arrays (FPGAs) are used to store and update the parameters of
multiple concurrent long short-term memory networks as well as embed physical
knowledge at the neurons' input level. This will require that the machine
learning algorithm learn the temporal dependencies across operating regimes and
adapt to varying dynamics. The resulting algorithm is a novel type of long
short-term memory recurrent neural network that enables the prediction of
nonlinear and non-stationary time series. Multiple iterations of this algorithm
will be run in parallel on a single FPGA where the training time of one
algorithm can be effectively hidden by another algorithm performing inference in
parallel. The formulated algorithm will advance the field of real-time machine
learning by furthering knowledge on: 1) how parallel models interact to hide
training latency; 2) the effect of automated tuning of model parameters; 3) the
role of physical knowledge in designing input spaces; 4) the benefits of
subdividing non-stationary time series into local stationary systems; and 5)
sustaining sufficient accuracy while meeting real-time constraints in the micro-
second realm.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission
and has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.