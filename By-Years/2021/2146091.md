* 2146091
* CAREER: Advancing Fair Data Mining via New Robust and Explainable Algorithms and Human-Centered Approaches
* CSE,IIS
* 08/15/2022,07/31/2027
* Xiaoqian Wang, Purdue University
* Standard Grant
* Sylvia Spengler
* 07/31/2027
* USD 576,351.00

Predictive discrimination is widespread in artificial intelligence (AI)
applications that affect human life. Automated decisions can replicate,
exaggerate social inequities, and even implement and legitimize new forms of
discrimination. The fairness and equity of data mining and machine learning
models are becoming a growing concern in many communities, but the constraints
of sensitive information in data and the complexity of models bring critical
challenges to building fair AI frameworks. This project focuses on undertaking
fundamental research activities to advance fairness in data mining and machine
learning, and to enable efficient human-machine interaction in human-centered
and wellness-focused real-world problems. This project will result in algorithms
and software that facilitate broader research of fair AI technologies in high-
stake application areas, such as improving healthcare diversity. The project's
impacts are easing humans' effort to build, adopt, and interact with fair
models. Furthermore, this project will encourage underrepresented students into
cutting edge computational research and contribute to graduate and undergraduate
education in multidisciplinary areas.&lt;br/&gt;&lt;br/&gt;The research
objective of this project is to create fair and explainable AI and human-in-the-
loop control paradigm: designing a family of fair, explainable, and robust data
mining algorithms with high expressive ability, faithful explanations, and
rigorous theoretical foundations. From a data equity perspective, the
investigator will design effective algorithms to achieve fair predictions while
being able to protect sensitive information. From an algorithm perspective, the
investigator will design novel explainable and robust models with rigorous
theoretical guarantees on generalization ability and Pareto efficiency. From a
human-machine interaction perspective, the project will promote human-in-the-
loop interventions and integrate human feedback to repair incorrect or biased
predictions. This research effort combines rigorous theoretical analysis with
emerging application problems, and is applicable to addressing the grand
challenges that society faces in building responsible data
science.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.