* 0130807
* Collaborative Research: Processing of Temporally-Coded Auditory Representations for Sound Separation and Localization
* CSE,CCF
* 01/15/2002,12/31/2003
* Peter Cariani, Massachusetts Eye and Ear Infirmary
* Continuing Grant
* Mitra Basu
* 12/31/2003
* USD 243,067.00

EIA-0130807 Peter A. Cariani Mass Eye &amp; Ear Infirmary Collaborative
Research: Processing of Temporally-Coded Auditory Representations for Sound
Separation and Localization&lt;br/&gt;&lt;br/&gt;The proposed work investigates
the use of two temporally-coded representations and temporal processing
strategies for the separation of auditory objects. Two temporal representations
and temporal processing strategies for the separation of auditory objects will
be used. Two temporal representations of input signals will be used. These are
1) phase-locked spike train responses in a simulated auditory nerve array
(Auditory Temporal Images), and 2) an auditory-inspired signal representation
based on adaptive demodulation (Adaptive Demodulation and Real-Zero Conversion)
that converts bandpass signals into timings of certain zero
crossings.&lt;br/&gt;&lt;br/&gt;Temporal coding through phase locking is a very
general strategy for representing sensory information through the relative
timings of spikes. Temporal coding is found in many sensory systems: audition
(periodicity and frequency discrimination, localization, echolocation),
mechanoception (flutter-vibration, localization, movement), electroception
(localization), and vision (fly motion detection). The unsurpassed capabilities
of biological auditory systems to separate, analyze, and recognize multiple
sounds may be due to the early use of temporal codes and computations, but thus
far there have been relatively few attempts to effectively exploit these time
domain strategies in artificial signal processing contexts. This collaborative
project will combine understanding of the neural substrates of auditory
perception (Cariani) with mathematical insights and expertise in signal
processing (Kumaresan) to develop new biologically inspired time-domain
approaches to auditory scene analysis.&lt;br/&gt;