* 1636586
* Gaze Control during Scene Viewing: Behavioral and Computational Approaches
* SBE,BCS
* 10/30/2015,06/30/2017
* John Henderson, University of California-Davis
* Standard Grant
* Lawrence Gottlob
* 06/30/2017
* USD 135,071.00

When we view the visual world, our eyes flit from one location to another about
three times per second, in movements called saccades. Useful visual information
is acquired only during fixations, brief periods of time when gaze rests on an
object or scene feature. The cognitive and neural processes that direct saccades
and fixations through a scene in real time fall under the term 'gaze control'.
This project focuses on unraveling how human gaze control operates during active
real-world scene perception. This project approaches human gaze control by
starting with the insight that understanding eye movement timing will provide
key insight into the underlying cognitive and neural systems that control gaze.
The research combines innovative eye-tracking methods with a working
computational model that simulates eye movement control. In this research
program, the empirical and computational threads are complementary and
synergistic. On the one hand, we can test our understanding of gaze control by
determining whether the model can produce eye movements that look like those
produced by people. On the other hand, insights from the model can be used as a
tool to enhance our theoretical understanding of gaze control, and these
insights can be further tested with new experiments. The results from this
project will enhance basic scientific understanding of how humans perceive and
understand the visual world. The project also has wide-ranging implications for
the creation of new display technologies and machine interfaces that can be
controlled by eye movements. And the results are relevant for the design of new
artificial vision systems that actively track and focus on relevant information
in the environment.