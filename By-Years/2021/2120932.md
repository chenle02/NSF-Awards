* 2120932
* Identifying multimodal dynamics of coordination to understand joint performance in diverse tasks
* SBE,BCS
* 09/15/2021,08/31/2024
* Rick Dale, University of North Carolina at Charlotte
* Standard Grant
* Betty Tuller
* 08/31/2024
* USD 349,020.00

People need to coordinate their actions in order to carry out a wide range of
daily activities. For example, cooking a meal together, moving a large couch,
and working as a team in sport or business, all require coordination among the
participants. Despite evidence that collaborating partners in these joint tasks
adapt their behavior to one another in real time, it is unclear what features of
coordination lead to the best outcomes. The aim of this project is to develop a
framework for predicting optimal coordination among people across diverse
settings and roles. Using a combination of empirical studies and dynamical
computational modeling, the investigators will unpack issues surrounding the
roles of dialogue, perspective-taking, and collaboration in successfully
performing joint tasks. Understanding the principles that underlie successful
coordination among people engaged in a joint task has potential commercial and
societal impact in a wide variety of settings, including health care, education,
aviation, military operations, and search-and-rescue scenarios. The project will
also contribute to the development of an interdisciplinary workforce by
increasing opportunities to engage undergraduate and graduate students in
cognitive science research at two academic institutions.&lt;br/&gt;&lt;br/&gt;A
prominent view of how interpersonal coordination influences task performance is
that when task partners align or match their behavior, their joint task
performance improves. Alignment of, for example, pronunciation, word choices,
sentence structure, or movement has been documented in tasks that require
partners to monitor each other’s perspective. However, it is unknown how
different tasks may increase or decrease alignment for successful performance.
In this project, the investigators will manipulate a number of task features:
the goals of the task, the symmetry of the partners’ roles, and the number of
perspectives that partners have to adopt. Eye movement measurements and dialogue
transcripts will be analyzed in order to quantify how aligned partners are in
their attention and language use. The aim is to evaluate and model how task
performance is predicted by task features and by the degree of interpersonal
coordination. For example, interpersonal alignment might increase and be more
useful in tasks that require partners to monitor one another closely (e.g., when
partners have asymmetrical roles because they hold distinct information). In
tasks that require less monitoring, excessive alignment might be detrimental to
task outcomes. A dynamical model of collaborative performance, which has
parameters for task constraints and interpersonal coordination, will be
evaluated against the experimental data and will be used to generate predictions
about performance in new tasks.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.