* 2113684
* Foundations of High-Dimensional and Nonparametric Hypothesis Testing
* MPS,DMS
* 07/01/2021,06/30/2024
* Matey Neykov, Carnegie-Mellon University
* Standard Grant
* Pena Edsel
* 06/30/2024
* USD 250,000.00

Statistical inferential tools are the main export from the discipline of
statistics to the empirical sciences, serving as the primary lens through which
natural scientists interpret observations and quantify the uncertainty of their
conclusions. However, in the analysis of modern large datasets the most common
inferential tools available to us are fraught with pitfalls, often requiring
various technical conditions to be checked before their valid application. This
in turn has led to misuse of the inferential tools and subsequent
misinterpretation of results. This research project will aim to address this
issue by developing and analyzing new user-friendly methodologies for
statistical inference in complex settings. The methods we develop will be
broadly applicable to a wide variety of challenging inferential problems in the
physical and biological sciences, will eliminate the need to verify technical
conditions, and will ultimately be robust in their application. The principal
and co-principal investigators will be involved in advising and mentoring
graduate students, in curricular and course development, and in integrating the
project with a research group on Statistical Methods in the Physical Sciences
(STAMPS).&lt;br/&gt;&lt;br/&gt;This project will advance our understanding of
high-dimensional and non-parametric inference along three frontiers. Firstly, we
aim to develop statistical inferential tools for irregular models, which are
valid under weak conditions. Our particular focus will be on mixture models, and
on methods which use sample-splitting to avoid strong regularity conditions.
Secondly, we will show that our methods achieve these strong guarantees at a
surprisingly small statistical price. To rigorously quantify the statistical
price paid for avoiding strong regularity conditions we will use minimax theory.
However, standard minimax theory, in many cases, does not adequately capture the
difficulty of statistical inference since the difficulty of inference can vary
significantly across the parameter space. A more refined theory -- called local
minimax theory -- leads to a more accurate picture, and we will study our
methods via this lens. Finally, we will address the problem of conditional
independence (CI) testing. Despite its central role in regression diagnostics,
and in the study of probabilistic graphical models, the task of CI testing and
its intrinsic difficulty is poorly understood. We will address two fundamental
aspects of CI testing, by studying methods to appropriately calibrate CI tests,
and by developing and analyzing powerful new CI tests.&lt;br/&gt;&lt;br/&gt;This
award reflects NSF's statutory mission and has been deemed worthy of support
through evaluation using the Foundation's intellectual merit and broader impacts
review criteria.