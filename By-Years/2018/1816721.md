* 1816721
* CHS: SMALL: Methods to Assess Automotive Augmented Reality Head-up Display Effects on Driver Performance
* CSE,IIS
* 08/15/2018,07/31/2022
* Joseph Gabbard, Virginia Polytechnic Institute and State University
* Standard Grant
* Dan Cosley
* 07/31/2022
* USD 499,996.00

Augmented Reality (AR) windshield displays have the potential to provide
fundamentally new driving experiences by displaying computer graphics directly
on the roadway, and with the increasing commercialization of AR technologies are
likely to become more common in cars. If designed properly, AR has the potential
to enhance driving and driver safety. However, we currently do not know how to
evaluate the safety of emerging AR driving interfaces, as existing methods used
for evaluating other in-vehicle information displays (such as navigation and
entertainment systems) are not rich enough to capture effects of AR displays on
driver performance. This project will develop new methods for assessing drivers'
visual distraction when using AR displays. These methods will be specifically
tuned for developing AR user interfaces for driving that reduce injuries and
minimize loss of life and property. If successful, this project will help auto
manufacturers more quickly create and release new and safe AR driving
applications, and may have a positive impact on other areas where AR is used,
such as in construction and manufacturing. The project will also support
educational impacts, through the training of researchers better able to consider
both human and technical factors in system design and evaluation, and through
efforts to recruit students who are members of populations traditionally
underrepresented in engineering.&lt;br/&gt;&lt;br/&gt;The project will address
open questions that arise from expected increases in the field of view provided
by AR heads-up displays (HUDs). This will support a wider variety of possible
interfaces and information locations than current displays; however, we
currently do not know how to effectively quantify the effects of AR user
interfaces on driving. This project will evaluate glance allocation and visual
attention capabilities of drivers with AR HUDs, and apply this knowledge to
inform new methods of AR HUD assessment. Specifically, the team will establish
thresholds for AR HUD glance durations along with a set of ecologically valid
visual AR HUD tasks that can be broadly adopted by both researchers and
designers of automotive AR HUDs. The team will further create a set of methods
to assess the effects of AR HUD visual demand on drivers' ability to detect
events occurring in both the drivers' central and peripheral fields of view.
Lastly, the research will employ user studies to test the refined methods on an
actual roadway and recommend best practices for applying the
methods.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.