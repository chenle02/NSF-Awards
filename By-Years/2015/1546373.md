* 1546373
* BIGDATA: F: Protection of Data Privacy via Differentially Private Multiple Synthesis
* CSE,IIS
* 01/01/2016,05/31/2019
* Fang Liu, University of Notre Dame
* Standard Grant
* Sylvia Spengler
* 05/31/2019
* USD 243,503.00

This project seeks better ways to protect individual privacy in big data without
compromising the accuracy of population-level information for research and
public use. The differential privacy community has explored private release of
datasets, but this has largely been within the computer science theory community
and has not rigorously evaluated the practical utility of the methods. This
project develops techniques and tools to create synthetic "surrogate datasets"
with the same structure and statistical properties as the original dataset, but
satisfying differential privacy. The work includes development of techniques to
generate synthetic data amenable to statistical analysis, evaluation of the
techniques in real-life big data, and to develop and release as open source
tools for dataset creation. This project brings a statistician's viewpoint to
the utility question, and evaluates against both simulated data, the census
record based ADULT dataset frequently used in anonymization studies, and two
real datasets, one with hospital inpatient data and the other a social science
study on poverty. The work is being featured in several community outreach
programs to stimulate interests in STEM careers among K-12
students.&lt;br/&gt;&lt;br/&gt;The project builds on multiple synthesis
(generating multiple datasets from posterior distribution-derived sufficient
statistics). The project is first establishing theoretical and methodological
foundations, including but not limited to mathematical derivation of the global
sensitivity of the sufficient statistics in commonly used statistical models,
establishment of a theory that guarantees individual privacy protection in
released data, and establishment of large-sample inferential theories on the
synthetic data. Probability theory, stochastic process, asymptotic theory,
Bayesian modelling and computing, and missing data analysis techniques are
heavily employed. To ensure scalability to Big Data, sufficient statistics whose
scalar components do not increase as the number of data items increases are
being investigated. The developed method is evaluated by simulation studies and
applications to real life data sets (including social/financial data and health
care data) benchmarked against current methodologies for releasing individual-
level data. Finally, open-source software is being developed for release on the
Comprehensive R Archive Network that produces a synthetic dataset matching the
schema of the original data, as well as certain statistics to explain disclosure
risk and support analysis of data utility.