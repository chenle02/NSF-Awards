* 9612028
* PDS: Pursuing a Petaflop: Point Designs for 100TF Computers Using PIM Technologies
* CSE,OAC
* 09/01/1996,08/31/1997
* Peter Kogge, University of Notre Dame
* Standard Grant
* John Van Rosendale
* 08/31/1997
* USD 100,000.00

There are two major problems with the current state of the art in high-
performance computing. First, the cost of the very highest end machines lies far
beyond the point where widespread deployment is feasible, and second (and more
critical) the software environments for these machines are awkward at best, and
capable of eking out only fractions of the performance that the hardware is
capable of supplying. The thesis of this is that much of the problem stems from
our historical separation of memory and CPU logic parts. Individual CPU clock
rates and internal architectures continue to accelerate, and thus require ever
increasing amounts of bandwidth from the memory subsystem. These rates have far
exceeded the bandwidth capabilities of our densest DRAM memory parts (needed to
control system costs), and the gap will widen over time. The net effect is
complex memory hierarchies, which in turn drives cost and software complexity in
addressing these hierarchies efficiently. A new technology is emerging to
counter this fundamental defect: the combination on one chip of both dense DRAM
and very significant amounts of logic. This capability permits new architectures
termed Processing-In-Memory (PIM) to place computing either right next to, or
even inside of, the memory macros, where there are huge amounts of raw
bandwidth. The first such chip, EXECUBE, integrated onto a 4Mbit DRAM chip 8
complete CPUs configured in a 3D binary hypercube, and was capable of being used
as a one chip-type building block for MPPs of both MIMD and SIMD organization.
The objective of this project is to look at utilizing PIM technology potentials
over the next decade and demonstrate that they promise efficient solution. The
approach to be used involves configuring and studying some "point design" MPPs
with 100 tera(fl)op potential for several interesting classes of problems, and
then utilizing the novel features of these architectures, along with matching
system software and software development tools, to attack them in ways that may
permit not only exceptional performance, but also greatly simplified programming
environments.