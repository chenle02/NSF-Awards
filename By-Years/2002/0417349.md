* 0417349
* Extending Locally Dependent Item Response Models for Analyzing Psychological and Social Surveys
* SBE,SES
* 09/01/2004,08/31/2007
* Edward Ip, Wake Forest University School of Medicine
* Standard Grant
* Cheryl Eavey
* 08/31/2007
* USD 70,000.00

This research concerns the development of flexible statistical and psychometric
methods for analyzing item-response data from educational tests and social
surveys. The project contains two main components. The first component is the
methodological development of item response models and extensions, specifically
the locally dependent hybrid kernel models for dichotomous and polytomous
responses. These methods are applicable to items that do not function
independently after conditioning on subject effect. Examples of locally
dependent items include items that have a common reading stem (as in a reading
comprehension test), or items that survey related quantities such as the
frequency and the intensity of a feeling (as in a psychological test). The
project is expected to advance standard item response models in several ways:
(1) the handling of dependency within item clusters with separable submodels,
(2) the incorporation of multiple scales, (3) the accommodation of item- and
person-specific covariates, and (4) the exploitation of rating scales of items.
The second component of this project addresses applications. Three data sets
from three different areas - education, psychology, and health-related social
study - have been identified, and each will be analyzed using the locally
dependent models.

Item response models are increasingly used in calibrating scientific instruments
used for measuring human traits and behavior. Recent examples include large-
scale educational assessment and health-related quality-of-life research. This
research supplements the most commonly used item response model - the
unidimensional model - with flexible ways of dealing with potential minor
deviations from the unidimensionality assumption. The benefits of the project
include providing more flexible analytic methods that are compatible with the
standard item-response models, which means that interpretability is retained,
and adding novel features such as the handling of a wide range of response data
(e.g., data with covariates or data that can be formulated as a rating scale).
Given the increasing interest in the applications of refined item-response
models to newer and often more complex tests and surveys, this project is
expected to have an impact on improving both the quality of instruments and the
subsequent analysis of gathered responses. This research is supported by the
Methodology, Measurement, and Statistics Program and a consortium of federal
statistical agencies as part of a joint activity to support research on survey
and statistical methodology.