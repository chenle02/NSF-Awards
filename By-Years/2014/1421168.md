* 1421168
* RI: Small: Robot Developmental Learning of Skilled Actions
* CSE,IIS
* 09/01/2014,08/31/2020
* Benjamin Kuipers, Regents of the University of Michigan - Ann Arbor
* Standard Grant
* Erion Plaku
* 08/31/2020
* USD 446,823.00

The goal of this project is to show how a robot --- using a continuous stream of
visual and tactile data --- can learn to work at a human level of skill in tasks
normally done by humans. To function at a human level, it must be able to plan
with "object-level" abstractions such as putting a red block into the box, and
it must also be able to grasp objects and move them while avoiding bumping into
things and causing damage to its surroundings. This project is inspired by human
cognitive development. A baby learns about objects and actions by bootstrapping
from early regularities and unreliable actions to hierarchies of more complex
and reliable actions. The hypothesis to be tested is that this bootstrap
learning approach allows a robot to achieve human levels of skillful and robust
action in a wide range of human-dominated
environments.&lt;br/&gt;&lt;br/&gt;This project draws on extensive prior work on
foundational knowledge representations and machine learning. Learning begins by
detecting low-level contingencies --- regularities among observed events --- and
refining them into increasingly accurate predictive rules, that can be used to
define reliable actions. For a given rule, a simple MDP model is formulated, and
reinforcement learning methods learn a policy for accomplishing an action at the
next level of the action hierarchy. Learned actions are initially unreliable,
but policies and actions improve with experience. Attention is focused where
learning is likely to be most productive by intrinsic motivation methods that
reward actions that result in successful learning, including the important
special case of rewarding attempts to imitate the successful actions of other
agents.