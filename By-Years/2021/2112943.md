* 2112943
* Automated Causal Discovery with Observational Data via Directed Graphical Models - New Theory and Methods
* MPS,DMS
* 07/01/2021,06/30/2024
* Yang Ni, Texas A&M University
* Continuing Grant
* Yulia Gel
* 06/30/2024
* USD 179,960.00

Establishing causality is crucial in many fields of science including biology,
psychology, neuroscience, climate science, robotics, and quantum mechanics.
While the gold standard for establishing causality remains controlled
experimentation, it can be expensive, unethical, and even impossible in many
cases. Therefore, establishing causality from passively observed data (as
opposed to experimental data) is often desirable and, sometimes, the only
option. In this project, the PI will develop a series of causal discovery
methods that are theoretically sound and practically useful for identifying
causality with observational data. Efficient open-source software accompanying
the proposed methods will be developed and the project also provides research
training opportunities for graduate students. &lt;br/&gt;&lt;br/&gt;The proposed
methods will be based on directed graphical models (DGMs). Despite the
popularity of DGMs across disciplines, using DGMs to establish causality from
observational data remains difficult, both theoretically and methodologically,
due to several prominent challenges. First, DGMs are generally non-identifiable
due to Markov equivalence class in which all DGMs encode the same set of
conditional independencies and hence are not distinguishable from each other
without further assumptions. Second, the class of DGMs is not closed under
marginalization and therefore the structure learning can be misled by unmeasured
confounders. Third, the vast majority of existing methods rely on relatively
strong distributional assumptions on the data generating mechanism, which can
cause significant estimation biases when the assumptions are seriously violated.
This project aims to address these three challenges by developing new DGMs for
non-iid data and establishing their causal identifiability theories in the
presence of confounders and model misspecification. As validation, the proposed
methods will be used to reverse engineer gene regulatory networks from genomic
datasets. Results will be disseminated through workshops, publications, and new
graduate courses.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.