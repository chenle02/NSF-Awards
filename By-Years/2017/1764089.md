* 1764089
* CHS: Medium: Scaling Qualitative Inductive Analysis through Computational Methods
* CSE,IIS
* 08/01/2018,07/31/2023
* Danielle Szafir, University of Colorado at Boulder
* Continuing Grant
* William Bainbridge
* 07/31/2023
* USD 1,081,143.00

This project focuses on the integration of people and computation in the context
of qualitative inductive methods (QIMs), in which experts deeply engage with
text corpora such as open-ended surveys, transcribed interviews, or collections
of social media content. This engagement can produce insights, but constraints
on expertise and time make these methods hard to scale to large datasets.
Technologies like machine learning and natural language processing (NLP), which
can mine certain kinds of patterns from text data at scales not feasible for
even large teams of humans, may offer a way forward; however, machines make
mistakes understanding the nuances of language, lack the context and expertise
of human analysts, and may fail to detect interesting small-scale patterns
necessary to solve particular problems. The goal of this project is to scale up
the use of QIMs by inverting traditional models where humans are used to verify
computational results ("human-in-the-loop"), starting instead with human
insights that can be amplified through computational models, support, and
suggestions for analysis ("computer-in-the-loop"). Working with collaborators in
domains including mental health, public health, disaster response, policy
making, and philanthropy, the team will conduct qualitative studies of their QIM
practices and needs, then develop and evaluate systems with the goal of
improving both the quality and scale of the insights experts can generate. The
team will produce publicly available versions of the tools and disseminate them
through an online community for interested researchers from all fields. The
project activities will also inform courses on information visualization, human
computer interaction, and applied machine learning, along with workshops aimed
at recruiting high school women to careers in
computing.&lt;br/&gt;&lt;br/&gt;The work is organized around three main threads.
The first thread is to conduct a deep analysis of qualitative work processes,
using both existing accounts of qualitative work in the literature and
participant observation methods with at least 10 teams who approach QIM from a
range of disciplines, domains, and scales. Through analysis of interviews, logs,
and artifacts, the team will generate rich descriptions of these work processes
that will further both understanding of QIMs as a method and identify open
problems amenable to computational support. The second thread is to develop
computational models of QIMs that align with analysts' processes and judgments
around qualitative data, using a variety of datasets from the research team and
their partners. Because many QIM methods label specific text passages as
relevant to a specific concept, taking those as positive examples and nearby,
unlabeled data as negative examples may allow QIMs to be modeled as a series of
binary classification problems. This will allow the team to use NLP methods
guided by domain knowledge and insights from the first thread to generate
features for machine learning-based models. The third thread involves connecting
these models to analysts' processes through a series of passage-level, document-
level, and theme-level visualizations that leverage the models' predictions to
suggest other passages relevant to a concept in a given document, hierarchical
aggregation of patterns across documents to support the extraction of higher-
level themes along with ways to merge and divide concepts, and statistical
analysis of the prevalence of themes in corpora-level analysis. The algorithms
and tools will be evaluated through a series of offline tests against existing
analyzed datasets, short analysis challenge contests in workshop settings to
evaluate usability and reactions to the tool, longitudinal three-month
deployments with partners that involve weekly semi-structured questionnaires
about their usability in practice, and in an online community to both provide
support for and collect feedback about the system while growing a methodological
community of practice around this style of big data
analysis.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.