* 2003182
* MLWiNS: Resource Constrained Mobile Data Analytics Assisted by the Wireless Edge
* CSE,CNS
* 07/01/2020,06/30/2024
* Yao Wang, New York University
* Standard Grant
* Dan Cosley
* 06/30/2024
* USD 300,000.00

Increasing amounts of data are being collected on mobile telephones and
internet-of-things (IoT) devices. Users are interested in analyzing this data to
extract actionable information, for example, identifying objects of interest
from high-resolution mobile phone pictures. The state-of-the-art technique for
such data analysis is via deep learning which makes use of sophisticated
software algorithms modeled on the functioning of the human brain. Deep learning
algorithms are, however, too complex to run on small, battery constrained mobile
devices. The alternative, i.e., transmitting data to the mobile base station
where the deep learning algorithm can be executed on a powerful server, consumes
too much bandwidth. This project seeks to devise new methods to compress data
before transmission, thus reducing bandwidth costs while still allowing for the
data to be analyzed at the base station. Departing from existing data
compression methods optimized for reproducing the original images, the project
will use deep learning itself to compress the data in a fashion that only keeps
the critical parts of data necessary for subsequent analysis. The resulting deep
learning based compression algorithms will be simple enough to run on mobile
devices while drastically reducing the amount of data that needs to be
transmitted to mobile base stations for analysis, without significantly
compromising the analysis performance. The proposed research will provide
greater capability and functionality to mobile device users, enable extended
battery lifetimes, and more efficient sharing of the wireless spectrum for
analytics tasks. The project also envisions a multi-pronged effort aimed at
outreach to communities of interest, educating and training the next generation
of machine learning and wireless professionals at the K-12, undergraduate and
graduate levels, and broadening participation of under-represented minority
groups.&lt;br/&gt;&lt;br/&gt;The project seeks to learn “analytics-aware”
compression schemes from data by training low-complexity compressor deep neural
networks (DNNs) that execute on mobile devices and achieve a range of
transmission rate and analytics accuracy targets. As a first step, efficient DNN
pruning techniques will be developed to minimize the DNN complexity, while
maintaining the rate-accuracy efficiency for one or a collection of analytics
tasks. Next, to efficiently adapt to varying wireless channel conditions, the
project will seek to design adaptive DNN architectures that can operate at
variable transmission rates and computational complexities. For instance, when
the wireless channel quality drops, the proposed compression scheme will be able
to quickly reduce transmission rate in response while ensuring the same
analytics accuracy, but at the cost of greater computational power on the mobile
device. Further, wireless channel allocation and scheduling policies that
leverage the proposed adaptive DNN architectures will be developed to optimize
the overall analytics accuracy at the server. The benefits of the proposed
approach in terms of total battery life savings for the mobile device will be
demonstrated using detailed simulation studies of various wireless protocols
including those used for LTE (Long Term Evolution) and mmWave
channels.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.