* 9526325
* Efficient Compilation Issues for Scalable                   Distributed-Memory Multicomputers
* CSE,CCF
* 09/15/1996,08/31/1999
* Prithviraj Banerjee, Northwestern University
* Standard Grant
* Frank D. Anger
* 08/31/1999
* USD 91,408.00

Distributed-memory, massively-parallel multicomputers can provide the high
levels of performance required to solve the Grand Challenge computational
science problems. Multicomputers offer significant advantages over shared-
memory multiprocessors in terms of cost and scalability. Unfortunately,
extracting all the computational power from these machines requires users to
write efficient software for them, which is an extremely laborious and error-
prone process. The distribution of data across processors is of critical
importance to the efficiency of the parallel program in a distributed memory
system. In this project the problem of automated data distribution in such
machines is being investigated. The approach is unique in that it is based on
sophisticated cost models of communication and computation that are
parameterized by architectural metrics empirically measured for different target
machines. Using the cost estimates, data distributions are selected to minimize
the overall execution time of the program by maximizing parallelism (while
maintaining load balance) and minimizing the amount of communication overhead
(by maximizing data locality). Both static and dynamic distribution will be
supported in a unified framework to automatically select data distributions
which can dynamically change over the course of a program's execution in order
to provide scalable parallel performance for large, complex applications. This
approach not only has a solid theoretical basis, but is being integrated into a
sophisticated compiler which can actually generate code for a variable number of
processors supporting all block, cyclic, and block-cyclic data distributions.
The compilation techniques investigated in this project will also be integrated
with simultaneous support for regular and irregular accesses in parallel
applications through a novel interval-based representation. ***