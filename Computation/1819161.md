
* 1819161
* Inexact Optimization Methods for Structured Nonlinear Optimization
* DMS,COMPUTATIONAL MATHEMATICS
* 07/15/2018,07/12/2018
* Hongchao Zhang,LA,Louisiana State University
* Standard Grant
* Leland Jameson
* 06/30/2022
* USD 200,000.00

New efficient computational algorithms will be developed for solving large-scale
optimization problems with particular structure. Structured nonlinear
optimization has played a central role in various modern applications ranging
from image processing, optimal control to stochastic learning in big data area.
The algorithms developed in the project will provide solutions in a more robust
and faster way, and will be made publicly available to benefit both optimization
and computational data science community. The student supported in this project
will have excellent opportunities for interdisciplinary research.

The current methods for solving structured optimization problems often need to
solve a sequence of subproblems according to the problem structure. This project
aims to develop efficient methods and software that allow to solve their
subproblems inexactly while still theoretically guarantee the global convergence
and maintain the same or almost the same computational complexity of the
corresponding methods that require exact solve of the subproblems. In
particular, the investigator will develop (I) a framework of inexact alternating
direction methods of multipliers for separable convex optimization, where the
subproblem is solved to the accuracy relative to the whole problem KKT error;
(II) inexact stochastic gradient methods for the composite optimization, which
combines the(accelerated) proximal gradient methods and stochastic variance
reduction techniques; (III) inexact active-set algorithms for polyhedral
constrained nonlinear optimization.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.
