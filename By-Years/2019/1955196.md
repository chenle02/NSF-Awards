* 1955196
* Collaborative Research: CNS Core: Medium: Exploiting Synergies Between Machine-Learning Algorithms and Hardware Heterogeneity for High-Performance and Reliable Manycore Computing
* CSE,CNS
* 06/15/2020,05/31/2024
* Krishnendu Chakrabarty, Duke University
* Continuing Grant
* Jason Hallstrom
* 05/31/2024
* USD 450,000.00

Advanced computing systems have long been enablers for breakthroughs in science,
engineering, and new technologies. However, with the slowing down of Mooreâ€™s law
and the relentless needs of Big-Data applications, e.g., deep learning, graph
analytics, and scientific simulations, current solutions are not adequate. There
is a need for innovative computer architectures and computationally efficient
methods to design application-specific hardware systems to optimize performance,
power consumption, and reliability. The main focus of this work is design and
demonstration of a heterogeneous single-chip manycore platform, integrating CPU,
GPU, accelerator, and memory cores, via a network-on-chip to avoid expensive
off-chip data transfers. The goal of this project is to address the design of
application-specific heterogeneous manycore systems that are poised to achieve
unprecedented levels of performance and energy-efficiency for Big-Data
applications. The PIs will disseminate research outcomes via publications,
seminars, tutorials, and workshops. The project is also leading to the
development of an interdisciplinary research-based curriculum integrating
computer architectures, machine learning, and data-driven design optimization.
Undergraduate and graduate students involved in this research will be trained to
apply classroom knowledge to research problems that require next-generation
hardware, software, and theoretical expertise. &lt;br/&gt;&lt;br/&gt;The project
will lay the foundations for a novel computing paradigm for Big-Data
applications that allows us to quickly design and autonomously self-manage
heterogeneous manycore computing systems to improve performance, reduce power
consumption, and enhance reliability. In-memory processing can overcome the
memory wall, but it introduces new challenges in overall application-specific
system optimization. The specific research tasks include: 1) Data-driven multi-
objective design space exploration and optimization algorithms for heterogeneous
manycore architectures; 2) Reliability assessment and system design for
reliability; 3) Structured learning framework for autonomous resource
management; and 4) Performance, power, and reliability evaluation using emerging
Big-Data application workloads. This framework will combine the benefits of
multi-objective design space exploration and optimization, heterogeneity in
computation and communication, and data-driven algorithms to improve
performance, energy-efficiency, and reliability of manycore
platforms.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.