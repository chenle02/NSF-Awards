* 1815238
* III: Small: An end-to-end pipeline for interactive visual analysis of big data
* CSE,IIS
* 09/01/2018,08/31/2021
* Carlos Scheidegger, University of Arizona
* Standard Grant
* Hector Munoz-Avila
* 08/31/2021
* USD 485,849.00

Computer scientists, statisticians, and data scientists use sophisticated
analysis techniques to extract insights from their massive sources of data, from
astronomic data gathered from telescopes to climate simulations run on
supercomputers to user activity in online social networks. At the same time,
they would like to make use of interactive visualization, so they can understand
and explore their data by means of graphics and visual interfaces. These visual
analytics systems are more intuitive and more powerful, and allow analysts to
make better decisions more confidently. Currently, these visualization systems
are not fast enough for broad applicability in large-scale settings. In this
project, novel techniques are developed to speed up the methods used in data
analyses in order for stakeholders to combine the sophisticated analyses they
need with the interactive visualization systems they prefer to use. This project
has the potential to transform how current infrastructure and systems for
interactive and exploratory data analysis are designed. Open-source software
that integrates directly with the libraries and programming languages used by
scientists and other data analysts will be broadly disseminated. In addition,
the concepts and technologies developed here will be used in classrooms to train
future generations of researchers and computer
scientists.&lt;br/&gt;&lt;br/&gt;There currently is a major obstacle for the
application of interactive visualization systems in large-scale data analysis:
many techniques require repeated loops (or scans) over the dataset in order to
collect the appropriate aggregation information. The recently developed
hierarchical, spatiotemporal data cube data structures replace many of scans,
but are only suitable for basic bar charts, histograms, and heatmaps, since they
accelerate only a small number of queries available to database management
systems. In contrast, this project aims at developing novel data structures that
support a broader swath of the exploratory data analysis and visualization
pipeline, such as k-means, logistic regression, least-squares optimization,
dimensionality reduction, etc., and connect these data structures directly to
the APIs and calls made by visualization libraries that use these methods. The
performance of proposed infrastructure for interactive and exploratory data
analysis will be evaluated on specifically designed benchmarks to compare
existing and novel interactive data cube systems. The benchmarks will enable
synthesis of knowledge that is spread across a somewhat fractured research area.
The benchmarks will, in turn, guide the evaluation of the development of
improvement for these data structures, aiming at a decrease between 30% to 80%
in storage costs, and likely comparable gains in preprocessing time, that
translate directly into better interactive visualization capabilities. APIs for
integrating these data structures in modern data science environments such as R
and Python will be developed and widely disseminated in order to increase the
impact of this project.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.