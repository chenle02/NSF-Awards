* 1763469
* CHS: Medium: Collaborative Research: Manipulation Assistance for Activities of Daily Living in Everyday Environments
* CSE,IIS
* 08/01/2018,07/31/2024
* Holly Yanco, University of Massachusetts Lowell
* Continuing Grant
* Ephraim Glinert
* 07/31/2024
* USD 539,000.00

While many people with disabilities need help with activities of daily living
(ADLs) in their homes or at other locations, they care deeply about maintaining
their sense of independence, which implies limiting the tasks that professional
or family caregivers are asked to provide. There is the potential for robots to
have a huge impact here, by enabling people to live independently for longer.
The goal of this research is to develop a robotic wheelchair-manipulator system
(RoWMan) consisting of a power wheelchair with a robotic arm mounted on it, that
will help its user perform ADLs either as an assistive device or by performing
manipulation tasks autonomously. In assistive mode, the user would ride in the
wheelchair, with the RoWMan system manipulating items as requested. Whereas in
autonomous mode, the user could ask RoWMan to navigate on its own through the
house, retrieve items, and place them as directed. This project will necessitate
the development of new user interfaces as well as an array of new machine
learning and robotics techniques that will enable successful autonomous robotic
navigation and manipulation in unstructured environments. To ensure broad
impact, project outcomes will be evaluated with a user population at Crotched
Mountain Rehabilitation Center.&lt;br/&gt;&lt;br/&gt;In recent focus groups it
was found that users want a number of capabilities, including the ability to
pick up something from the floor, the ability to unlock and open a door, the
ability to manipulate items on a tightly packed shelf, etc. RoWMan will be
designed so as to enable users to perform these sorts of tasks, by focusing on
two areas: robotic manipulation and human-robot interaction. The manipulation
work will develop new algorithms that perform well with novel objects in
unstructured environments. Traditionally, manipulation planners assume that the
shapes of the objects involved are known in advance or can be estimated on the
fly, but these assumptions often cause problems in practice. The focus here will
be to develop new algorithms based on deep reinforcement learning that can
perform manipulation tasks reliably even when the geometry of the world is
unknown in advance. The project will also support research into a new class of
human-robot interaction based on laser pointers. Recent work suggests that laser
pointing can be very effective for the target user community because it enables
users to point directly in the environment rather than on a screen which induces
additional cognitive load. This project will develop new ways of communicating
sophisticated intent using a combination of environmental context, laser
pointing, and laser gestures.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.