* 1900941
* CHS: Medium: Collaborative Research: Empirically Validated Perceptual Tasks for Data Visualization
* CSE,IIS
* 10/01/2019,12/31/2022
* Enrico Bertini, New York University
* Standard Grant
* Balakrishnan Prabhakaran
* 12/31/2022
* USD 402,405.00

Understanding quantitative data is a foundation of science, education, and the
public communication of information about public policy and health. Our brains
process and understand numbers far more efficiently when we can rely on data
visualizations, allowing us to process patterns in data by leveraging the 40% of
our brain that processes visual patterns in the real world. Decades of research
in data visualization has produced evidence-backed guidelines for how to design
the best data visualization for a given data analysis or communication task. But
this process is limited by our incomplete understanding of the process by which
we recognize patterns in visualized data. When people see a weather map color-
coded by temperature, are they processing the hot and cold colors at the same
perceptual moment, or just one? When they inspect a scatterplot, are people
processing individual points, or the shape of the whole collection? This project
will combine past research in the study of human vision, research in data
visualization, and new research at the intersection of those two fields to
create a model of how the visual system pulls patterns and statistics from
visualized data. This model will lead to a more complete understanding of how to
best harness the power of human vision to analyze a given dataset and to
communicate a critical pattern clearly to an audience; this model will then be
used to improve existing visualization tools.&lt;br/&gt;&lt;br/&gt;Data
visualization research has sought to find the best visualization for a given
data analysis task. For example, scatterplots allow relatively precise judgment
of correlations, while line graphs are a powerful way to inspect trends over
time. But systematically testing the performance of many tasks across many
visualizations has not revealed systematic patterns of performance that would
allow us to predict why some matches lead to better performance, what design
changes might alter that performance, or how novel visualizations might perform.
One problem is that current work is limited to focusing on what viewers want to
accomplish, without being able to capture how viewers actually perform these
tasks. The goal of the proposed research is to refine and empirically evaluate a
lower-level model of "perceptual tasks" that underlie higher level tasks (e.g.
"What is the average value in the dataset?") based on established results in
perceptual psychology. First, the team will conduct a qualitative study that
documents how people break a high-level task down into perceptual tasks,
followed by an empirical evaluation of those qualitative findings. Next, the
team will measure the precision and operation of the proposed perceptual tasks
-- Filter Image, Judge Shape, Compute Distributions and Compute Ratio -- along
with other tasks identified in the first study; together, these will provide a
set of empirically-backed design guidelines to improve visualization
effectiveness. Finally, the team will validate the model by comparing its
predictions to findings from previous literature, then integrate new guidelines
as constraints into the Draco visualization recommender system, which should
improve its ability to predict the performance of different visualization
designs. The resulting guidelines, model, and integration into Draco promise in
turn to improve visualization education and practice.&lt;br/&gt;&lt;br/&gt;This
award reflects NSF's statutory mission and has been deemed worthy of support
through evaluation using the Foundation's intellectual merit and broader impacts
review criteria.