* 1908375
* III: Small: Collaborative Research: Cost-Efficient Sampling and Estimation from Large-Scale Networks
* CSE,IIS
* 10/01/2019,01/31/2022
* Chul-Ho Lee, Florida Institute of Technology
* Standard Grant
* Sylvia Spengler
* 01/31/2022
* USD 249,999.00

Sampling and estimating structural information from &lt;br/&gt;large-scale
networks or graphs has been central to our &lt;br/&gt;understanding of the
network dynamics and its rich set &lt;br/&gt;of applications. Markov Chain Monte
Carlo (MCMC) has &lt;br/&gt;been the key enabler for a broader context of graph
&lt;br/&gt;sampling, including estimating the properties of large
&lt;br/&gt;graphs, sampling the corpus of documents indexed by &lt;br/&gt;search
engines, sampling records from hidden databases &lt;br/&gt;behind Web forms,
identifying subgraphs of certain &lt;br/&gt;characteristics and frequent graph
pattern matching. &lt;br/&gt;Despite versatile applications of the MCMC methods
and &lt;br/&gt;their customized algorithms for analyzing &lt;br/&gt;graph-
structured data in various forms, there still &lt;br/&gt;exist critical
challenges and limitations in the &lt;br/&gt;literature centered around the MCMC
methods. One is the &lt;br/&gt;'cost' consumption/constraints associated with
the &lt;br/&gt;sampling operation, which limits the size of total
&lt;br/&gt;samples obtained and negatively affects the accuracy of
&lt;br/&gt;any estimator based on the obtained samples. Another
&lt;br/&gt;limitation is that the recent advances in MCMC, &lt;br/&gt;especially
built up on favorable non-reversible Markov &lt;br/&gt;chains, cannot be
leveraged to the various large-graph &lt;br/&gt;sampling tasks, due to their
required global knowledge &lt;br/&gt;of the underlying state space, lack of
distribution &lt;br/&gt;implementation, unconstrained state space, as well as
&lt;br/&gt;the simplified cost assumption. The goal of this research is to fully
exploit the &lt;br/&gt;potentials of a set of crawling samplers by making the
samplers adaptive and possibly &lt;br/&gt;interactive on a properly constructed
graph domain, to &lt;br/&gt;transcend the current status-quo in the wide range
of &lt;br/&gt;graph sampling tasks. &lt;br/&gt;&lt;br/&gt;Specifically, the
project aims to: (i) build a theoretical framework to &lt;br/&gt;construct a
suite of cost-efficient sampling policies &lt;br/&gt;by optimally balancing the
tradeoff between the sample &lt;br/&gt;quality and quantity under challenged
access &lt;br/&gt;environments with a given cost budget, (ii) design a
&lt;br/&gt;class of adaptive random walks by fully exploiting the
&lt;br/&gt;past information to achieve minimal temporal &lt;br/&gt;correlations
over the obtained samples and by &lt;br/&gt;controlling the random walks
collectively to enable &lt;br/&gt;maximal space exploration, and (iii) extend
the &lt;br/&gt;standard MCMC toolkits toward faster and more &lt;br/&gt;cost-
efficient exploration of feasible &lt;br/&gt;subgraphs/configurations and
computing/optimization on &lt;br/&gt;a graph, along with extensive validations
to create &lt;br/&gt;practical and usable solutions in reality. This
&lt;br/&gt;research has a high potential impact on a vast range of
&lt;br/&gt;multi-disciplinary applications, including sampling &lt;br/&gt;large-
scale graphs for statistical inference and &lt;br/&gt;efficient estimation and
randomized algorithms for &lt;br/&gt;combinatorial optimizations in various
disciplines, &lt;br/&gt;where the standard MCMC methods have been dominant but
&lt;br/&gt;also constrained our understanding.&lt;br/&gt;&lt;br/&gt;This award
reflects NSF's statutory mission and has been deemed worthy of support through
evaluation using the Foundation's intellectual merit and broader impacts review
criteria.