* 1847096
* CAREER: Learning and Control Algorithms for Electricity Demand Response with Humans-in-the-Loop
* ENG,ECCS
* 03/01/2019,02/29/2024
* Mahnoosh Alizadeh, University of California-Santa Barbara
* Continuing Grant
* Aranya Chakrabortty
* 02/29/2024
* USD 500,000.00

Electricity Demand response (DR) technologies aim to inform electricity end-
users about the operational state of the power grid and enable them to take an
active role in grid operations. Specifically, DR programs can incentivize price-
responsive customers to consume more electric energy when supply is abundant and
less when supply is scarce, hence increasing the customers' ability to
opportunistically consume wind and solar energy and relieve sources of grid
stress. However, two main challenges of balancing demand and supply in the grid
under such scenarios is the unpredictability of renewable energy outputs, as
well as the need to know customers' price response behavior, i.e., how they
change their electricity consumption patterns given different prices. Such
information is not available to electricity retailers and cannot be easily
solicited from the customers either. The goal of this project is to advance
scientific knowledge on the design of DR mechanisms that operate in the absence
of reliable generation forecasts and customer price response models. To
demonstrate the value of our proposed algorithms for a specific type of price
responsive electricity demand, we will highlight the application of our methods
for electric vehicle smart charging in public parking lots and fast charging
stations. The proposed CAREER plan integrates research with teaching and
training activities that provide exposure to exciting opportunities in power
systems engineering to students at University of California - Santa Barbara,
both at the undergraduate and graduate levels. Our outreach efforts will
introduce smart grid concepts to local middle and high school
students.&lt;br/&gt;&lt;br/&gt;The intellectual merit of this project is to
build on algorithmic techniques for online learning and control of stochastic
systems with unknown parameters in order to generate novel systematic tools for
demand response and retail market operation in the presence of high levels of
uncertainty. Due to the direct involvement of humans in the DR control loop and
high levels of renewable integration, a principal challenge we now face is how
we can optimize system operations and dispatch resources in the absence of: 1)
algebraic models of the system, e.g., due to unknown price response of
customers; 2) a characterization of the uncertainty faced by the system in the
future, e.g., due to renewables. We will develop real-time dispatch and pricing
solutions that provide optimality guarantees in the face of uncertainty about
users demand flexibility as well as grid conditions. Our proposed learning and
optimization techniques will be integrated with grid reliability and cyber-
security constraints. Furthermore, to study the practical impact of this
proposal for an important application, we study online learning and dispatch
methods for the mobility-aware real-time electric vehicle (EV) demand management
problem, which suffers from both of the challenges highlighted
above.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has
been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.