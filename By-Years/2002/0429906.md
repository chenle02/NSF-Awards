* 0429906
* Collaborative Research:      Studies on Average Complexity
* CSE,CCF
* 08/15/2004,10/31/2007
* Jie Wang, University of Massachusetts Lowell
* Continuing Grant
* Eun K. Park
* 10/31/2007
* USD 161,992.00

Abtract&lt;br/&gt;This project studies the average complexity of computational
problems in three directions.&lt;br/&gt;The first direction concerns with the
notion of average NP-completeness, which was first&lt;br/&gt;introduced by Levin
as a tool to prove the hardness of a problem in average-case
analysis.&lt;br/&gt;Levin's original notion of reductions for average NP-
completeness, however, seems too rigid&lt;br/&gt;to be applied to a wide class
of problems that are believed to be hard-on-average. In this&lt;br/&gt;proposal,
a less restrictive notion of reductions is introduced, and is proposed as a new
tool to&lt;br/&gt;prove new average NP-hard problems, including distributional
function inverting problems.&lt;br/&gt;The second direction of this project
investigates the relations between instance com-&lt;br/&gt;plexity and average
time-complexity. Intuitively, the average complexity of a
distributional&lt;br/&gt;problem is low if and only if the instance complexity
of a random instance is low. Thus,&lt;br/&gt;instance complexity is a useful
concept in the study of average complexity. This project will&lt;br/&gt;apply
the formal notion of instance complexity, introduced by Ko et al. and closely
related to&lt;br/&gt;Kolmogorov complexity, to study average complexity. It will
examine the size and distribu-&lt;br/&gt;tion of hard instances of average
polynomial-time solvable problems, average NP-complete&lt;br/&gt;problems, and
pseudorandom generators.&lt;br/&gt;The third area of this investigation concerns
with the average complexity of numerical&lt;br/&gt;computation. Because of the
continuous nature of numerical computation, the notion of&lt;br/&gt;average
complexity is much different from that of discrete computation. The PIs
propose&lt;br/&gt;to extend the Turing machine-based (worst-case) complexity
theory of real functions, intro-&lt;br/&gt;duced by Ko and Friedman, to develop
a unified average complexity theory for numerical&lt;br/&gt;computation. It will
focus on the relations between average complexity and
randomization,&lt;br/&gt;and the average-case analysis of functions defined on
two-dimensional domains, based on the&lt;br/&gt;Lebesgue measure and the
Hausdorff dimension/measure.&lt;br/&gt;Intellectual Merit. Average complexity is
an important issue in analysis of algorithms.&lt;br/&gt;Average completeness,
instance complexity, and average complexity of real functions
are&lt;br/&gt;fundamental concepts in computational complexity theory, as well
as numerical analysis.&lt;br/&gt;Connections between these concepts are critical
to our understanding of average complexity&lt;br/&gt;of hard problems, and have
potential to generate major breakthrough.&lt;br/&gt;The PIs are experts in these
areas. They have played key roles in the introduction of
the&lt;br/&gt;fundamental concepts and the development of the average complexity
theory and complexity&lt;br/&gt;theory of real functions.&lt;br/&gt;Broader
Impact. Advances in average complexity are expected to have a
substantial&lt;br/&gt;effect on many areas of computer science and mathematics,
including analysis of algorithms,&lt;br/&gt;numerical analysis, fractals and
chaos theory, and pseudorandomness; and have significant&lt;br/&gt;applications
in more practical areas of cryptography and computer security.&lt;br/&gt;The PIs
will integrate this research into graduate teaching. Results from this study
will&lt;br/&gt;be presented broadly in professional conferences and workshops,
and in the form of survey&lt;br/&gt;papers and lecture notes. Graduate and
undergraduate students will participate in various&lt;br/&gt;activities of this
project.