* 1509516
* Adaptive dynamic programming for uncertain nonlinear systems through coupling of nonlinear analysis and data-based learning
* ENG,ECCS
* 08/01/2015,07/31/2019
* Warren Dixon, University of Florida
* Standard Grant
* Anil Pahwa
* 07/31/2019
* USD 325,543.00

Optimal control methods provide a means to associate a user-defined cost with
control actions or decisions. These methods have made pervasive impacts in a
wide class of application domains. The shift towards autonomy by the automotive
industry in examples such as replacing mechanical systems with computer
controlled electronic control systems, has resulted in efficiencies in fuel
injection, braking, throttling, etc. For electric vehicles, fuel economy,
drivability, and emission control are functions of the engine design and the
control strategies. For robotic systems, the desire to achieve optimal behavior
is essential for efficient task execution. Likewise, aerospace systems have
always been a mainstream application domain for optimal control methods because
there has always been (and always will be) a tight coupling between performance
and energy/fuel costs. As the cost of energy and the awareness of the
environmental impacts of producing energy have risen, optimal control may now
play a timely role in a broader spectrum of application domains. The Energy
Efficiency and Renewable Energy office of the U.S. Department of Energy
indicates that as much as 10-20 percent of American energy use could be saved by
optimizing industrial systems. It is self-evident that optimal control solutions
can have significant impacts in a wide range of industries, but the development
of optimal control solutions for real engineering systems is limited by numerous
technical barriers. The most fundamental and open-ended problems arise from
barriers associated with developing optimal solutions in the presence of
uncertainty. The driving question in this project is how to arbitrate between
gaining knowledge about a system while simultaneously making the optimal control
decision for engineering systems that are uncertain and complex.

The technical aims of this project are motivated by the hypothesis and
observations from preliminary efforts that nonlinear analysis methods can be
exploited to design real-time approximate optimal solutions, while concurrent
background processing methods can be used to update the optimal control
approximation for improved performance. Intellectual merits in this project are
realized through the development of classes of closed-loop controllers with
associated stability analysis, and advanced function approximation methods, that
ensure sufficient exploration of the system response while learning the
approximate optimal control solution. Outcomes of this research would allow for
optimal control implementation in a broader class of application domains where
the system exhibits nonlinear behaviors and uncertainty. The broad impact of
this framework is a merger of methods that bridge the gap between the
computational intelligence community and control systems community to enable
data-based learning methods to optimize control performance.