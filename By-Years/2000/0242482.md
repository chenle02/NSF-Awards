* 0242482
* CISE Research Instrumentation: Data-Driven Modeling for     Real-Time Interaction and Animation
* CSE,EIA
* 09/01/2000,01/31/2003
* Jessica Hodgins, Carnegie-Mellon University
* Standard Grant
* Rita Rodriguez
* 01/31/2003
* USD 48,394.00

9818287&lt;br/&gt;Hodgins, Jessica K.&lt;br/&gt;Atkeson, Christopher
G.&lt;br/&gt;Georgia Institute of Technology&lt;br/&gt;&lt;br/&gt;CISE Research
Instrumentation: Data-Driven Modeling for Real-time Interaction and
Animation&lt;br/&gt;&lt;br/&gt;This research instrumentation enables research
projects in:&lt;br/&gt;&lt;br/&gt;- Perception of Action&lt;br/&gt;- Learning
from Demonstration&lt;br/&gt;- Animating with Experimentally Determined
Parameters, and&lt;br/&gt;- Modeling Facial Expressions&lt;br/&gt;&lt;br/&gt;To
support the aforementioned projects, for the capture, modeling, recognition, and
generation of human motion, this award contributes to the purchase of motion
capture equipment, graphics workstations, and digital cameras at College of
Computing in Georgia Institute of Technology. The equipment will be used for
several projects aimed at making it easy to create, control, and interact with
artificial humans in interactive&lt;br/&gt;environments for training and
entertainment. The cameras and motion capture equipment will capture full body
and facial motion of the users. The processing power of the graphics
workstations and other available&lt;br/&gt;multi-processors will be used to
create data-driven models for recognition and generation of human actions
ranging from full body motions such as a tennis swing to subtle facial
expressions. The power of this technology will be demonstrated by constructing
interactive environments in which the cameras and motion capture equipment will
be used for on-line recognition of user actions and the graphics workstation
will be used to animate human figures in real-time, based on the models derived
off-line. The prototype applications will be environments where interactivity
and realism are key, such as training environments for physical tasks and
animation of highly interactive and responsive characters.&lt;br/&gt;&lt;br/&gt;