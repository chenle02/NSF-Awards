* 1815538
* III: Small: A New Machine Learning Approach for Improved Entity Identification
* CSE,IIS
* 09/01/2018,08/31/2022
* Theodoros Rekatsinas, University of Wisconsin-Madison
* Standard Grant
* Sylvia Spengler
* 08/31/2022
* USD 320,377.00

Modern analytics rely on data integration to combine heterogeneous data into a
unified repository they can tap into for insights, services, and scientific
knowledge. The typical goal of data integration is to combine heterogeneous data
about the same real-world entity into a canonical representation of that entity.
Traditionally, entity canonicalization methods focus on structured data and
leverage the semantics of the schema accompanying the data to come up with
canonical entity representations. This dependency on data semantics makes
existing entity canonicalization methods inapplicable to dark data, i.e.,
operational data that corresponds to unstructured, noisy, and incomplete data.
This project will develop entity canonicalization methods that focus on
unstructured and semi-structured data and are suitable for large-scale
integration applications. This work will help ease the currently challenging
procedure of heuristically consolidating matching information about the same
entity into unified representations and thus enable dark data to be more
effectively used in downstream analytics applications.&lt;br/&gt;&lt;br/&gt;The
emphasis of this work is on entity canonicalization techniques that leverage
representation learning (a.k.a. feature learning) and deep learning. The
combination of distributed representations with deep architectures has emerged
as the de facto standard for analyzing and processing unstructured data. This
project will develop new deep learning architectures for: (1) record linkage,
i.e., clustering unstructured data records that provide information about the
same entity; and (2) data fusion, i.e., combining matching unstructured records
into a canonical representation of the underlying entity. For record linkage,
this work will introduce new deep learning techniques that capture multi-context
domain-specific knowledge to learn the semantic similarity between records. For
data fusion, this project will design new multi-sequence to one-sequence
encoder-decoder recurrent neural networks for data fusion with a particular
focus on incomplete data. The outcomes of this project have the potential to
advance the state-of-the-art in large scale data integration methods as well as
machine learning methods for high-dimensional, sparse, and noisy
data.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has
been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.