* 1348522
* Verb Learning and The Early Development of Sentence Comprehension: Experimental and Computational Studies
* SBE,BCS
* 09/01/2014,02/28/2019
* Cynthia Fisher, University of Illinois at Urbana-Champaign
* Standard Grant
* Tyler Kendall
* 02/28/2019
* USD 190,210.00

Understanding how children learn language--how they gather data from language
experience and use it to uncover linguistic structure--is a key challenge for
cognitive science, in part because native mastery of a language is one of the
foundations of both formal and informal education. Infant language learners
encounter sentences paired with world situations; at the start, these sentences
are made up of unknown words, combined by the rules of an unknown grammar. Based
on such data, toddlers begin to understand sentences early in the second year of
life, and ultimately build a lexicon and grammar that support nearly unlimited
generalization to new sentences. Accounts of how children begin to understand
sentences necessarily begin with the non-linguistic world. The infant, not yet
knowing the words or the grammar, must figure out what words and sentences mean
in large part by observing the world situations in which they occur. But aspects
of the meanings of verbs challenge the assumption that learners can
straightforwardly recover verb (and thus sentence) meanings from situations.
This problem inspired the syntactic bootstrapping theory, which proposes that
children use their growing knowledge of syntax itself to learn verbs and
interpret sentences.

This research is will provide important insight into normal language
acquisition, but it may, in the future, contribute also to the diagnosis and
treatment of developmental language disorders. In this project, Dr. Fisher and
Dr. Roth explore how syntactic bootstrapping works, and how it begins, extending
the structure-mapping account of the origins of syntactic bootstrapping. On this
account, infants approach language armed with an innate bias toward one-to-one
mapping between nouns in sentences and participant-roles in events. Given this
bias, children find the number of nouns in a sentence inherently meaningful: For
example, as soon as children can identify some nouns, they can assign different
interpretations to transitive and intransitive verbs, essentially by counting
the nouns. A corollary of this account is that children identify words as verbs
by learning their syntactic combinatorial properties.

This project asks how syntactic bootstrapping scales up to the complexity of
verbs' predicate-argument structures and the ambiguity of sentences. The project
addresses two linked proposals, by combining verb-learning experiments with
children and experiments with a computational model based on systems for
Semantic Role Labeling (SRL). The first proposal is that distributional learning
creates detailed syntactic-semantic combinatorial knowledge about verbs. This
knowledge plays two roles: (a) it permits syntactic bootstrapping, as children
use verbs' combinatorial behavior to identify them as verbs, and to compute
their semantic structure; and (b) it supports online sentence processing, by
reducing ambiguity and improving children's sentence representations (this is
known as 'verb bias'). The second proposal is that an expectation of discourse
continuity facilitates verb learning by letting learners gather evidence for
verb argument-structure across nearby sentences. Combinatorial learning about
verbs guides this process, by cuing children to seek referents for missing
arguments in the discourse context.