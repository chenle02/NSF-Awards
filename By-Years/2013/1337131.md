* 1337131
* XPS: SDA: Collaborative Research: A Scalable and Distributed System Framework for Compute-Intensive and Data-Parallel Applications
* CSE,CCF
* 09/01/2013,08/31/2017
* Wuchun Feng, Virginia Polytechnic Institute and State University
* Standard Grant
* Tevfik Kosar
* 08/31/2017
* USD 375,000.00

Whereas traditional high-performance computing (HPC) applications are
computationally intensive, recent HPC applications require more data-intensive
analysis and visualization to extract knowledge. In many cases, these
applications execute the same computational algorithm as in the past (e.g.,
parallel search or parallel rendering) but now must do so for significantly
larger data sets. For example, the life sciences, along with the cross-cutting
area of scientific visualization, constitute an emerging category of HPC
applications that not only perform sophisticated calculations but also ingest a
sea of data. Running these new HPC data-parallel applications on today's
computing platforms imposes new challenges and demands additional
functionality.&lt;br/&gt;&lt;br/&gt;However, today's HPC platforms still adopt a
compute-centric model and do not handle these new challenges well. Such a model
often moves a large amount of data to various parallel computational processes.
Consequently, long CPU wait times for I/O to complete and enormous data-movement
overhead become major stumbling blocks to high performance and scalability. This
project encompasses the creation of a scalable cross-layer software framework to
enable both computationally intensive and data-intensive parallel HPC
applications to run on distributed file systems. This framework consists of two
interwoven research tasks: (1) an adaptive, data locality-aware, middleware
system that dynamically schedules compute processes to access local data by
monitoring physical data locations and (2) a framework that captures the
computation and data I/O processing relationship from parallel applications and
coordinates the scheduling of the corresponding process and I/O execution for
maximum parallel efficiency. The success of this project contributes enhanced
productivity and return on investment on HPC resources via the elimination of
both CPU wait time and network transfer of frequently accessed data in
scientific applications. An open-source, sustainable, and reusable software
framework is delivered to speed-up the discovery and innovation process in areas
such as bioinformatics, climate, high-energy physics, cosmology, astrophysics,
and chromodynamics. The synergy in the two proposing institutions, Virginia Tech
and the University of Central Florida, and their collaborating DOE national
laboratories, will catalyze new and beneficial perspectives in the graduate
education of students and prepare a 21st-century workforce in HPC.