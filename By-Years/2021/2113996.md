* 2113996
* SHF:Small:Performance Portable Parallel Programming on Extremely Heterogeneous Systems
* CSE,CCF
* 09/01/2021,08/31/2024
* Barbara Chapman, SUNY at Stony Brook
* Standard Grant
* Almadena Chtchelkanova
* 08/31/2024
* USD 500,000.00

The computers that are deployed today are increasingly complex as their
designers strive to increase the speed with which computations are performed,
while simultaneously maintaining or even reducing their power consumption. Many
of them include energy-efficient accelerator devices. Adapting existing
application programs so that they can execute well on new computer systems where
such devices are configured is a labor-intensive and error-prone activity that
requires significant expertise. Moreover, unless portable standards are used,
different versions of a program may need to be created for different hardware.
The effort required to do so may delay, or even prevent, many codes from fully
exploiting new systems. This project will learn how to effectively utilize
Machine Learning methods to help automate the adaptation process. Specifically,
it will learn how to modify applications that already run on multicore platforms
so that they can effectively exploit accelerator devices. At the same time, it
will study and develop best practices with respect to utilizing Machine Learning
in the context of improving the performance of
applications.&lt;br/&gt;&lt;br/&gt;This project will study and develop Machine
Learning (ML)-based strategies and techniques to identify and extract code
regions in technical applications that are suitable for mapping to the devices
configured on a heterogeneous architecture. It will moreover develop the runtime
technology needed to manage the execution of the resulting code. To accomplish
this, the project will focus on application codes that have been parallelized to
exploit multiple processing cores using the widely adopted, portable industry
standard OpenMP and will use and extend features of the most recent OpenMP
specification to express the device code and data mappings in a manner that is
portable and permits subsequent manual optimization. The embedding of key
choices in the code will aid performance portability. A key element of this
research is the study of state-of-the-art ML methods, including classical ML and
Deep-Learning techniques, with respect to their suitability for enhancing
compilers and tools. An exploration of their relative merits for use in the
compiler includes how to represent a compiler problem as a regression or
classification problem. Research will also study approaches to code
representation and the generation of sufficient data to train quality ML models.
A set of benchmarks and mini-apps will be used to guide and evaluate the
research. The project will participate in the work of the OpenMP Language
Committee, will make practical results available via the open source LLVM
infrastructure, will contribute to teaching and training materials, and will use
this effort to enrich an ongoing collaboration with an
HBCU.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has
been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.