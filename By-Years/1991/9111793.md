* 9111793
* RIA: Asynchronous Computer Architecture
* CSE,CCF
* 08/01/1991,01/31/1994
* Erik Brunvand, University of Utah
* Standard Grant
*   name not available
* 01/31/1994
* USD 70,000.00

Computer architecture is becoming a well-understood science. However, it is
currently dominated by traditional synchronous implementations of architectural
ideas. As techniques for building asynchronous circuits, and self-timed circuits
in particular, improve, it becomes more reasonable to ask what effect these
circuit techniques might have on the architecture of computers. Clocked
synchronous circuits, for example, tend to reflect worst- case behavior because
the clock cycle must be long enough for the worst-case path through some
component of the system. Asynchronous systems, on the other hand, tend to
reflect average-case performance because results from one component are
available as the computation completes. Asynchronous systems can also take
direct advantage of incremental process or technology improvements and can thus
remain productive over longer periods of time. This research studies the ways in
which asynchrony can be used to increase performance at an architectural level.
A framework is developed that allows different processor organizations to be
considered. The result of this study proposed architecture that uses asynchrony
to improve processor performance. Parts of the proposed architecture are tested
by using an automatic translation system to generate circuits from program
descriptions.