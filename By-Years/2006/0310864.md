* 0310864
* Video Coding Using Multihypothesis Motion Compensation in the Redundant Wavelet Domain
* CSE,CCF
* 08/15/2003,07/31/2007
* James Fowler, Mississippi State University
* Continuing Grant
* John Cozzens
* 07/31/2007
* USD 239,615.00

ABSTRACT&lt;br/&gt;0310864&lt;br/&gt;James E. Fowler&lt;br/&gt;Mississippi State
U&lt;br/&gt;&lt;br/&gt;In video coding, multihypothesis motion compensation
(MHMC) forms a prediction composed of multiple motion-compensated hypothesis
predictions in an effort to combat the uncertainty inherent in the motion-
estimation process. MHMC techniques---such as those that choose predictions that
are diverse spatially (e.g., fractional-pixel prediction), as well as those
exploiting temporal diversity (e.g., bidirectional prediction)---have formed an
integral part of modern video coders. This research investigates a new form of
MHMC---redundant wavelet multihypothesis (RWMH)---which performs motion
compensation in the domain of an overcomplete, or redundant, wavelet transform
in order to produce motion-compensated predictions that are diverse in transform
phase. The redundancy of the transform yields distinct phases that view motion
from different perspectives with each phase contributing its own hypothesis as
to the true nature of the motion, resulting in rate-distortion performance
significantly superior to traditional single-phase
systems.&lt;br/&gt;&lt;br/&gt;The present research focuses on the incorporation
of RWMH into modern video-coding systems in order to demonstrate that the RWMH
technique functions complementary to other advanced video-coding techniques.
Specifically considered is the incorporation of RWMH into a traditional hybrid
system consisting of motion-compensating prediction, transform, and
quantization, namely the state-of-the-art H.264 reference model. Additionally,
RMHW is deployed into modern 3D coders employing motion-compensated temporal
filtering (MCTF) in an effort to provide full temporal, resolution, and fidelity
scalability. In both systems, RWMH has the benefit that lower-resolution
information is predicted with a greater number of hypotheses, corresponding to
the greater difficulty inherent in estimating motion at low spatial resolution.
Broader impacts of the work stem from the fact that all resulting source code is
provided to the video-coding community as part of a large library under an open-
source license.&lt;br/&gt;