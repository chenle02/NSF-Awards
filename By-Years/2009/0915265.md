* 0915265
* RI: Small: Exploiting Bilingual Resources to Improve Monolingual Syntactic Tools
* CSE,IIS
* 09/15/2009,08/31/2010
* Dan Klein, University of California-Berkeley
* Standard Grant
* Tatiana Korelsky
* 08/31/2010
* USD 100,000.00

Natural language processing systems currently degrade when used outside of their
training domains and languages. However, when text is analyzed along with
translations into another language, the two languages provide powerful
constraints on each other. For example, a syntactic construction which is
ambiguous in one language may be unambiguous in another. We exploit such
constraints by using multilingual models that capture the ways in which
linguistic structures correspond between one language and another. These models
are then used to accurately analyze both sides of parallel texts, which can in
turn be used to train new, better, models for each language alone. Multilingual
models are challenging because each language alone is complex, and the
correspondences between languages can include deep syntactic and semantic
restructurings. Focusing on syntactic parsing, we address these complexities
with a hierarchy of increasingly complex models, each constraining the next. Our
approach of multilingual analysis improves three technologies: resource
projection, wherein tools for resource-rich languages are transferred to
resource-poor ones, domain adaptation, wherein tools are transferred from one
domain to another, and multilingual alignment, wherein correspondences between
languages are extracted for use in machine translation pipelines. In addition to
publishing the research results from this work, we also make freely available
the multilingual modeling tools we develop.