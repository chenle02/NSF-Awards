* 2015361
* Parameter Estimation Theory and Algorithms under Latent Variable Models and Model Misspecification
* MPS,DMS
* 07/01/2020,06/30/2023
* Xuanlong Nguyen, Regents of the University of Michigan - Ann Arbor
* Standard Grant
* Pena Edsel
* 06/30/2023
* USD 200,000.00

Latent variables models have become one of the most powerful tools in modern
statistics and data science. They are indispensable in the core data-driven
technologies responsible for advancing a vast array of domains of engineering
and sciences. While these tools represent remarkable achievements in which
statisticians have played fundamental and decisive roles, there are urgent and
formidable challenges lying ahead. As these tools are increasingly applied to
ever bigger data sets and systems, there are deep concerns that they may no
longer be understood, nor is their construction and deployment reliable or
robust. When treated as merely black-box modeling devices for fitting densities
and curves, latent variable models are difficult to interpret and can be hard to
detect or fix when something goes wrong, either when the model is severely
misspecified or the learning algorithms simply break down. This project aims to
address the theoretical and computational issues that arise in modern latent
variable models, and the learning efficiency and interpretability of such
statistical models when they are
misspecified.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;The goals of this project are to
develop new methods, algorithms and theory for latent variable models. There are
three major aims: (1) a statistical theory for parameter estimation that arises
in latent variable models; (2) scalable parameter learning algorithms which
account for the geometry of the latent structures, as well as the geometry of
the data representation arising from specific application domains; and (3)
impacts of model misspecification on parameter estimation motivating the
development of new methods. These three broadly described aims are partly
motivated by the PI's collaborative efforts with scientists and engineers in
several data-driven domains, namely intelligent transportation, astrophysics and
topic modeling for information extraction. In all these domains, latent variable
models are favored as an effective approximation device, but practitioners are
interested in not only predictive performance but also interpretability. In
terms of methods and tools, this research draws from and contributes to several
related areas including statistical learning, nonparametric Bayesian statistics
and non-convex optimization. In terms of broader impacts, the development of
scalable geometric and variational inference algorithms for latent variable
models will help to expand the statistical and computational tool box that are
indispensable in the analysis of complex and big data. The investigation into
the geometry of singularity structures and the role of optimal transport based
theory in the analysis of models and the development of algorithms will help to
accelerate the cross-fertilization between statistics and mathematics, computer
science and operations research. In terms of education and training, the
interdisciplinary nature of this project provides an exciting opportunity to
attract and train a generation of researchers and students in variational
methods and optimization, statistics and mathematics, as well as machine
learning and intelligent infrastructure. The materials developed in this project
will be integrated into an undergraduate honor course and a summer school for
statistical science and big data analytics developed at the University of
Michigan.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.