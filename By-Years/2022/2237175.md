* 2237175
* CAREER: Logical Form Induction
* SBE,BCS
* 04/15/2023,03/31/2028
* Aaron White, University of Rochester
* Continuing Grant
* Mary Paster
* 03/31/2028
* USD 95,010.00

Artificial intelligence (AI) systems’ natural language processing capabilities
have made remarkable strides in recent years. Beyond their numerous commercial
applications, these advances suggest that AI systems might be powerful tools for
deepening our understanding of how humans comprehend natural language. A major
obstacle to using them for this purpose is that, while they seem to simulate
certain aspects of reasoning by analogy quite well, their capacity to simulate
complex logical reasoning shows much room for improvement. This project develops
a framework for integrating complex logical reasoning capabilities into the
components of AI systems that make their ability to reason by analogy possible.
To support the development of this framework, the project builds a large dataset
capturing the logical relationships among sentences in three languages by using
AI systems to determine which kinds of logical relationships are most useful for
improving that system’s own logical reasoning capabilities. Through integration
with graduate and undergraduate curricula, the project serves as a vehicle to
enhance programming and statistical literacy as well as data collection and data
management skills through training with hands-on applications.
&lt;br/&gt;&lt;br/&gt;The framework integrates logical representations into AI
systems by imposing constraints on the sorts of numeric representations that
those systems use to make inferences on the basis of some natural language
input. These constraints are defined in terms of a mapping from the system’s
numeric representations of natural language to logical representations. This
mapping is learned from scratch and itself constrained (a) to correctly predict
inferences that actual speakers of a language make – as captured by the large-
scale datasets collected under the project – and (b) to be compositional: the
meaning of some piece of language must be predictable from the meanings of its
parts.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has
been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.