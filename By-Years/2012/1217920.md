* 1217920
* SHF: Small:Scalable Support for Concurrency in Multicore Systems
* CSE,CCF
* 07/01/2012,06/30/2016
* Sandhya Dwarkadas, University of Rochester
* Standard Grant
* tao li
* 06/30/2016
* USD 415,997.00

Processor designs are predicted to continue the many-core trend, often with
heterogeneous computational components. While the raw compute power may increase
roughly linearly with the core count, unfortunately, realizing the available
computational power at the application level remains a challenge. The gap
between CPU and memory speeds continues to widen, resulting in the memory system
often being unable to feed the computational demands. Parallel application
developers and users alike must be aware of the details of the underlying
hardware and runtime details in order to extract the most benefit from the
system, compromising performance portability. Programmers are also increasingly
exploiting concurrency via the use of pre-parallelized libraries, resulting in
poor composability. The proposed research aims to address these issues by
improving the ease of use, scalability, and energy efficiency of multicore and
multiprocessor systems, with impact on environments ranging from smart phone to
servers.&lt;br/&gt;&lt;br/&gt;As part of this research, a "pay-as-you-use"
application-adaptive approach is used to develop a novel on-chip memory system.
The key observation leveraged is that high-level modular application structure
has predictable spatial locality. Rather than use a rigid parameter for the
cache line granularity as in current designs, the underlying cache design adapts
to match existing access granularity. Additionally, this research aims to
develop runtime techniques that map application tasks to hardware compute
resources by a) respecting the dependencies across tasks, b) matching task needs
with the computational and memory capabilities of the resource, and c)
determining the appropriate degree of parallelism at each level to minimize
execution time and energy consumption. The new memory system design will improve
on-chip storage utilization, eliminate energy wasted in transferring unused
bytes of data, and reduce the pressure on off-chip memory bandwidth. The new
runtime techniques will improve the ease of use and scalability of computational
utilization by the increasingly innovative applications of the future.