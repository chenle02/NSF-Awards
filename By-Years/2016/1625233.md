* 1625233
* Research on Optimizing Testing Feedback for Improved Student Learning
* EDU,DUE
* 09/01/2016,08/31/2021
* Jamie Schneider, University of Wisconsin-River Falls
* Standard Grant
* John Haddock
* 08/31/2021
* USD 498,483.00

General chemistry is often taught in large lecture sections, which can influence
an instructor's choice to utilize multiple-choice exams and limit the testing
feedback students receive. This project will build on prior work (DUE Awards
#1140351 and #1140914) to further understand the best ways provide feedback to
students and to help instructors employ best practices that maximize student
learning through testing. Based on existing research in cognitive science, this
project will collect evidence on current practices of testing feedback in
general chemistry and measure the impacts on student learning of various forms
of feedback with a diverse set of student populations. Findings from this work
will be applicable to general chemistry programs across the nation as well as
other STEM disciplines that utilize complex content items in multiple-choice
testing. Developing and using evidence-based strategies to enhance and support
student learning is a critical step in producing a well-prepared and diverse
STEM workforce.&lt;br/&gt;&lt;br/&gt;This project aims to generate evidence
regarding the role of testing feedback to promote and support learning in
general chemistry. It will pursue three related sets of studies. Laboratory and
classroom testing feedback studies will examine the impact of different
corrective feedback types and timings on future test performance and confidence-
accuracy calibration. Qualitative testing feedback studies will employ semi-
structured interviews to reveal how students use feedback in a testing
environment and how this feedback may affect their learning, testing strategies,
and confidence. Lastly, a national survey will be developed and administered to
examine instructors' testing feedback practices and perceptions in first-term
general chemistry to better connect theory developed through this project with
current practices. The results of this work will generate evidence for selecting
and using testing feedback with a goal of using multiple-choice testing as a
learning tool as well as an evaluation tool.