* 2007955
* Collaborative Research: RI: Small: Modeling and Learning Ethical Principles for Embedding into Group Decision Support Systems
* CSE,IIS
* 01/01/2021,12/31/2023
* Nicholas Mattei, Tulane University
* Standard Grant
* Roger Mailler
* 12/31/2023
* USD 167,374.00

Many settings in everyday life require making decisions by combining the
subjective preferences of individuals in a group, such as where to go to eat,
where to go on vacation, whom to hire, which ideas to fund, or what route to
take. In many domains, these subjective preferences are combined with moral
values, ethical principles, or business constraints that are applicable to the
decision scenario and are often prioritized over the preferences. The potential
conflict of moral values with subjective preferences are keenly felt both when
AI systems recommend products to us and when we use AI enabled systems to make
group decisions. This research seeks to make AI more accountable by providing
mechanisms to bound the decisions that AI systems can make, ensuring that the
outcomes of the group decision making process aligns with human values. To
achieve the goal of building ethically-bounded, AI-enabled group decision making
systems, this project takes inspiration from humans, who often constrain their
decisions and actions according to a number of exogenous priorities coming from
moral, ethical, or business values. This research project will address the
current lack of principled, formal approaches for embedding ethics into AI
agents and AI enabled group decision support systems by advancing the state of
the art in the safety and robustness of AI agents which, given how broadly AI
touches our daily lives, will have broad impact and benefit to
society.&lt;br/&gt;&lt;br/&gt;Specifically, the long-term goal of this project
is to establish mathematical and machine learning foundations for embedding
ethical guidelines into AI for group decision-making systems. Within the machine
ethics field there are two main approaches: the bottom-up approach focused on
data-driven machine learning techniques and the top-down approach following
symbolic and logic-based formalisms. This project brings these two methodologies
closer together through three specific aims. (1) Modeling and Evaluating Ethical
Principles: this project will extend principles in social choice theory and fair
division using preference models from the literature on knowledge representation
and preference reasoning. (2) Learning Ethical Principles From Data: this
project will develop novel machine-learning frameworks to learn individual
ethical principles and then aggregate them for use in group decision making
systems. And finally, (3) Embedding Ethical Principles into Group Decision
Support Systems: this project will develop novel frameworks for designing AI-
based mechanisms for ethical group decision-making. This research will establish
novel methods for the formal and experimental unification of aspects of the top-
down or rule-based approach with the bottoms-up or data-based approach for
embedding ethics into group decision making systems. The project will also
formalize a framework for ethical and constrained reasoning across teams of
computational agents.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory
mission and has been deemed worthy of support through evaluation using the
Foundation's intellectual merit and broader impacts review criteria.