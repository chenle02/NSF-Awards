* 1717388
* SHF: Small: Developing a Highly Efficient and Accurate Approximation System for Warehouse-Scale Computers with the Sub-dataset Distribution Aware Approach
* CSE,CCF
* 06/15/2017,05/31/2023
* Jun Wang, The University of Central Florida Board of Trustees
* Standard Grant
* Danella Zhao
* 05/31/2023
* USD 450,000.00

Despite the fact that today's warehouse-scale computers supply enormous data
processing capacity, getting an ad-hoc query answer from a big dataset remains
challenging. To attack the problem, recent years have seen one trend to exploit
approximate computing to achieve faster execution on a much smaller sample of
the original data by sacrificing result accuracy to a reasonable extent. Both
offline based sampling approaches and online cluster sampling solutions have
been gradually deployed in a real world to accelerate big data query.
Educational benefits arise from broadening the experience of students from a top
ranked Hispanic Ph.D. degree awarding institution and enhanced computer
science/engineering curriculum activities. The online cross-institution
undergraduate elective course about warehouse-scale computer and big data will
be helpful in providing a re-imagined learning experience that makes optimum use
of today's technologies supplemented by a broad range of media-rich study
materials that students from three different
universities.&lt;br/&gt; &lt;br/&gt;There are major difficulties in developing
an integrated hardware and software, scalable approximation system.  The main
challenge is to minimize the total size of accessed data and its associative I/O
overhead subject to a given error bound. Existing popular cluster sampling with
equal probability solutions do not deal well with many real-world applications
following a non-uniform distribution. This research aims to tackle those
challenges by investigating new sub-dataset distribution aware methods to
capture sub-dataset distributions especially for non-uniform types, applying
cluster sampling with unequal probability to address the inefficient sampling
and large variance problem caused by non-uniform sub-dataset distribution, and
taking into account the unique properties of sampling process to match with the
computer hardware features, such as SSD arrays to unleash their full potential.
The research will ensure future big data approximation system enables high
velocity of big-data analytics to revolutionize the way that people interact
with the world; and high productivity improvement of the economic impact through
the efficient and effective data processing.