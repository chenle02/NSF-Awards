* 1338373
* Workshop on Big Data Benchmarking: THE BIGDATA TOP100 LIST
* CSE,OAC
* 05/15/2013,04/30/2018
* Choonhan Youn, University of California-San Diego
* Standard Grant
* Robert Chadduck
* 04/30/2018
* USD 56,200.00

OCI 1338373&lt;br/&gt;Chaitanya Baru - U. of California at San
Diego&lt;br/&gt;Workshop on Big Data Benchmarking: The BigData Top 100
List&lt;br/&gt;&lt;br/&gt;The Workshop series on Big Data Benchmarking (WBDB)
was created in 2012 by the Center for Large-scale Data Systems Research (CLDS)
at the San Diego Supercomputer Center, UC San Diego to foster a community
activity in the area of benchmarking of big data systems. The first workshop was
held in May 2012 in San Jose, California and was sponsored by the National
Science Foundation along with a few industry sponsors. Subsequent meetings
followed, and a second workshop held in December 2012 in Pune, India. The
meetings and the second workshop substantiated the initial ideas for a big data
benchmark leading to the concept of the BigData Top100 List for ranking big data
systems according to performance on a specified big data workload, while also
recording and reporting system efficiency, for example, in terms of
price/performance.&lt;br/&gt;&lt;br/&gt;This current action is for the Third
Workshop on Big Data Benchmarking workshop to be held on July 16-17, 2013 in
Xi'an, China. The local hosts for this meeting will be the Xi'an University of
Posts and Telecommunications and the Shanxi HPC Center.
&lt;br/&gt;&lt;br/&gt;Intellectual Merit: While a mature transaction processing
and data management industry has been established over the last two decades
based primarily on relational database (RDBMS) technologies, the emergence of
the Big Data phenomenon characterized by the so-called "3Vs" - volume, velocity,
and variety) of data along with the need for agile development of data-driven
applications, has introduced a new set of challenges. A variety of new
techniques and technologies have emerged to address these challenges. A big data
benchmark could, indeed, be specified with the following components: (i) a
definition for a synthetic benchmark dataset with a well-defined and well-
specified data generation procedure; (ii) a representative workload for big data
applications; and (iii) a set of metrics, run rules and full disclosure reports
for fair comparisons among technologies and platforms. These results would then
form the basis of the BigData Top100 List.&lt;br/&gt;&lt;br/&gt;Broader Impacts:
The first two WBDB meetings have had a total of about 100 (invited) attendees
from about 60 different organizations from industry and academia. The BigData
Top100 List initiative was officially introduced at a dedicated session at the
Strata Conference in Santa Clara, on February 28th, 2013. This is a community
effort and the benchmark will be released via the bigdatatop100.org website.