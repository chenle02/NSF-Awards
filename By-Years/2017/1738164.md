* 1738164
* I-Corps: Smart Speech Perception Feedback for Training and Diagnostics
* TIP,TI
* 04/01/2017,09/30/2018
* Silvio Eberhardt, George Washington University
* Standard Grant
* Anita La Salle
* 09/30/2018
* USD 50,000.00

The broader impact/commercial potential of this I-Corps project is to provide
technologies and services based on models of speech signals and human speech
perception. These models incorporate a deep understanding of the physical speech
stimulus and the perceptual representations that drive speech perception.
Technology applications to be explored can break new ground in areas such as:
(1) Improving the efficacy of audiological testing; (2) Improving the realism of
computer-synthesized voices (3) Providing speech perception training for better
understanding of non-native speakers or speakers with neurological disorders;
(4) Enhancing multisensory speech perception through training of individuals
with audiovisual speech processing deficits such as individuals on the autism
spectrum; (5) Developing sensory substitution or augmentation through
vibrotactile stimuli; and (6) Improving the quality of older adults? lives
through visual speech perception training to ameliorate their declines in
perceiving auditory speech in noisy backgrounds.&lt;br/&gt;&lt;br/&gt;This
I-Corps project will investigate commercial applications of technologies and
services based on models of multisensory speech signals and human speech
perception. Human speech perception can be highly errorful in the presence of
noise and/or distortions that originate in the talker, the physical
communication channel, and/or the perceiver (e.g., hearing loss). The technology
to be explored models how speech perception degrades, and how multisensory
stimuli compensate for perceptual errors. For example, this technology supports
the characterization of speech perception difficulties using a simple talk-back
task in which the perceiver repeats what was just said. In formal laboratory
experiments, this technology has been used to improve speech perception training
outcomes through improvements in the contingencies between perceptual errors and
training feedback. This technology can be used in developing media that are
designed to reduce the potential for perceptual errors.