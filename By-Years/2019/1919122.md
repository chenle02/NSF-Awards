* 1919122
* SPX: Collaborative Research: Parallel Algorithm by Blocks - A Data-centric Compiler/runtime System for Productive Programming of Scalable Parallel Systems
* CSE,CCF
* 10/01/2019,09/30/2023
* Anantharaman Kalyanaraman, Washington State University
* Standard Grant
* Damian Dechev
* 09/30/2023
* USD 419,334.00

Achieving both high productivity and high performance on scalable parallel and
heterogeneous computer systems is a challenging goal for application developers.
Parallel programming with Message Passing Interface (MPI) is currently the most
widely used and effective means of developing scalable parallel applications;
however the productivity of application developers is lower than with
programming models that offer a global shared view of data structures. In
comparison, achieving high performance and scalability with global-address-space
programming models is challenging. This project focuses on the development of a
data-centric compiler/runtime framework, "Parallel Algorithms by Blocks" (PAbB),
aimed at offering users the combined positive attributes of multiple parallel
programming models without the disadvantages. The main novelty of this project
is that it uses a combination of user insights, new compiler optimizations, and
advanced runtime support to achieve both productivity and performance for an
important class of computations that operate on matrices, tensors, and graphs.
The main broader impact of the work is that it can significantly lower the
barrier to entry for scientists from various domains who wish to develop new
high-performance applications on large scale parallel systems, but presently
find it too difficult with currently available parallel programming models.
&lt;br/&gt;&lt;br/&gt;This project brings together a team of investigators, with
expertise across the software stack, to develop compiler tools and runtime
systems for PAbB and demonstrate its use across a number of applications from
computational science and data science. The PAbB model is intended to work in
concert with MPI; that is, PAbB programs can execute in any standard MPI
environment, interoperating with other native MPI code. The key idea behind the
proposed approach is to offer the user a global-address view of the targeted
data structures, requiring only (optionally in some cases) that they specify how
data should be partitioned, but have the compiler/runtime handle the tedious
aspects of the global-to-local re-indexing and inter-node data movement. In
addition to the productivity benefit, a second significant benefit is in
enabling system support for dynamic load balancing. The approach is being
designed and demonstrated in the context of applications operating on dense and
sparse matrices and tensors, and graphs.&lt;br/&gt;&lt;br/&gt;This award
reflects NSF's statutory mission and has been deemed worthy of support through
evaluation using the Foundation's intellectual merit and broader impacts review
criteria.