* 1617992
* CSR: Small: Running the Kernel Continuously with Simultaneous Multi-Threading
* CSE,CNS
* 10/01/2016,09/30/2020
* Jakob Eriksson, University of Illinois at Chicago
* Standard Grant
* Marilyn McClure
* 09/30/2020
* USD 500,000.00

Since 2002, many commodity computer processors include a feature called
simultaneous multi-threading (SMT), marketed by Intel as Hyperthreading (tm).
SMT enables a single processor core to perform two or more tasks in parallel.
Until now, operating systems researchers have focused on accommodating SMT in
existing operating system designs, investigating topics such as SMT-aware
resource allocation, scheduling and synchronization methods. In this project,
rather than merely accommodate SMT, we investigate a new low-level operating
system design that is enabled by SMT hardware. In modern operating systems, the
processor switches between the safe but quite limited 'user mode' which is used
to run applications, and the unsafe but all-powerful 'supervisor mode' which is
available only to the operating system. Sometimes, these switches occur millions
of times per second, providing an illusion of parallel operation. In our new
design, the user and supervisor modes are actually active simultaneously, but on
separate SMT threads. This avoids the often high cost of frequent mode switches,
and enables new efficiency and design improvements throughout the operating
system. &lt;br/&gt;&lt;br/&gt;Based on preliminary measurements, we find that
the throughput gains provided by conventional SMT diminishes rapidly with the
number of processor cores in a system, as a result of sub-linear scalability in
the application. To counter this, and to make better use of existing hardware,
we propose the "cokernel" operating system design principle, where one hardware
thread per CPU is dedicated to continuously executing the kernel. By offloading
kernel duties from the other hardware thread(s), a cokernel operating system
enables higher per-thread application throughput, avoiding scalability concerns.
In addition, having a continuously executing kernel thread on each core enables
a wide range of improvements to other aspects of the kernel, such as replacing
most system calls with message passing, hybrid cooperative-preemptive process
scheduling, kernel-assisted asynchronous inter-core and inter-socket
communication and true kernel background tasks.