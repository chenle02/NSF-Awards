* 0413257
* Learning the Sensorimotor Foundation for Spatial Reasoning
* CSE,IIS
* 01/01/2005,12/31/2008
* Benjamin Kuipers, University of Texas at Austin
* Continuing Grant
* Douglas H. Fisher
* 12/31/2008
* USD 435,000.00

The sensorimotor system for a long-lived autonomous robot is the foundation for
its knowledge base. This project addresses fundamental questions about how
higher-level features and actions, which are usually engineered into robots by
human designers, can be learned autonomously and grounded in experience
interacting with the environment. The project involves three tasks.
&lt;br/&gt;&lt;br/&gt;In Task 1, an unknown sensory system is divided into
different sensory "modalities", for example, vision and different types of range
sensors, and the goal is to learn the distinctions among these, their individual
properties, and sensor fusion methods for combining their information into a
common model of the nearby ("small-scale'') environment.
&lt;br/&gt;&lt;br/&gt;In Task 2, the basis for a map of the "large-scale''
environment is assumed to be a deterministic automaton model consisting of a
discrete set of so-called "distinctive states" that are reliably connected by
actions. One goal is to learn hill-climbing control laws that define distinctive
states by reaching the local maximum activation of learned feature-detectors. A
second goal is to learn trajectory-following control laws for moving reliably
from one distinctive state to the neighborhood of another, where hill-climbing
eliminates accumulated error. &lt;br/&gt;&lt;br/&gt;In Task 3, the goal is to
learn to model the dynamic as well as the static environment, using coherent
motion to distinguish individual objects from the background, so they can be
categorized and their properties learned to support recognition elsewhere. This
is in contrast to the usual approach of assuming that the environment is static
and that anything dynamic is treated as noise to be filtered
out.&lt;br/&gt;&lt;br/&gt;Together, the results of these tasks will allow an
autonomous learning agent to ground its own sensors and effectors in its own
experience, supporting a high level of competence in modeling and interacting
with its environment. Besides addressing fundamental issues in spatial
cognition, this research has practical importance in showing how robots can
adapt autonomously to new or changing sensors and effectors. These results can
apply to non-standard "robots'' such as autonomic computing in complex computing
systems, distributed sensor networks, MEMS sensors, or reconfigurable autonomous
spacecraft, and have applications to the creation of intelligent aids, such as
wheelchairs, for the disabled.&lt;br/&gt;&lt;br/&gt;The results of this project
have broader impacts on many educational activities, including innovative
undergraduate courses in robotics, involvement of high school students in the
work of the project, and outreach to the community through open houses and
public demonstrations. One focus of the project is the development of mobility
aids like an Intelligent Wheelchair for persons with disabilities in mobility
and communication, but with normal cognition and perception.
&lt;br/&gt;&lt;br/&gt;