* 9212003
* Interior-Point Methods in Artificial Neural Networks
* ENG,ECCS
* 08/01/1992,07/31/1996
* Theodore Trafalis, University of Oklahoma Norman Campus
* Continuing Grant
* Paul Werbos
* 07/31/1996
* USD 89,064.00

This project will investigate the benefits of applying interior point techniques
to learning algorithms in neural networks. The P.I. will attempt to show that by
using the tools of interior point methods, a neural network algorithm such as
back propagation can be improved both in learning time and quality of solution
by optimizing the given methods of learning. As an introductory study, this
proposal will investigate the effects on learning in BP by studying a method of
analytical centers (Huard 1967, Sonnevend 1985, Renegar 1989). A similar
approach was developed and investigated by Trafalis (1989), Abhyankar, Morin and
Trafalis (1990) for multiobjective optimization problems. The proposed research
would be conducted according to a three-part plan: (1) To consider piecewise
linear convex activation functions. The findings of the research will then be
generalized to cover more general activation functions (e.g. sigmoid functions);
(2) To design, implement and computationally test the learning algorithms which
were developed in phase one of the research; (3) To test the developed learning
laws in vision problems related to medical applications in cancer diagnosis.