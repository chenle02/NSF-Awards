* 1527706
* SHF: Small: Empirical Autotuning of Parallel Computation for Scalable Hybrid Systems
* CSE,CCF
* 07/15/2015,06/30/2019
* Jakub Kurzak, University of Tennessee Knoxville
* Standard Grant
* Almadena Chtchelkanova
* 06/30/2019
* USD 450,000.00

Today, scientific and engineering computing is synonymous with parallel
computing, and applications such as climate modeling, drug design, aircraft
design, etc. utilize very large supercomputer installations, with power
consumption measured in MegaWatts, and the cost of electricity measured in
millions of dollars. At the same time, every parallel application requires some
level of tuning to ensure that the software is mapped appropriately to the
hardware. Otherwise, suboptimal performance can lead to lost cycles, kilowatt-
hours, and, ultimately, dollars. Tuning the application by making repeated runs
is also a wasteful option at very large scale. The DARE project addresses this
problem by tuning the application through modeling and simulation of its
behavior at very large scale, rather than actually running it. Therefore,
resources required for tuning are marginal compared to those consumed in
production runs. DARE is based on the observation that the same approach that
replaces a wind tunnel with a computer simulation of the airfoil can be applied
to the software itself. Two aspects of today's high-end computing landscape make
the DARE work unique: 1) the prevalence of hardware accelerators, such as
Graphics Processing Units and Xeon Phi co-processors, and 2) adoption of task-
based, dynamic, work scheduling systems as an alternative to traditional, lock-
step parallel programming models. In particular, DARE combines three components
into a refinement loop: a hardware analysis component, a kernel modeling
component, and a workload simulation component. The role of the hardware
analysis component is to extract the basic hardware information, such as
processing power and data link speed. The role of the kernel modeling component
is to provide performance models of the serial kernels that constitute the
building blocks of the parallel program. Finally, the role of the simulation
component is to simulate large-scale parallel
workloads.&lt;br/&gt;&lt;br/&gt;The hardware analysis component gathers the
basic knowledge about the system, such as: the number of CPU sockets per shared
memory node, the number of CPU cores in each socket, the cache hierarchy,
existence of hyper-threading, number of NUMA nodes and proximity of CPUs to NUMA
nodes, number of GPU accelerators or Xeon Phi co-processors and capacities of
their device memories, and the topology and bandwidth of data links, both within
each node (busses), and between nodes (network switches). Part of this knowledge
can be gathered by using appropriate query APIs, such as hwloc, netloc, PAPI,
and those provided in the CUDA SDK, OpenCL SDK, and Xeon Phi SDK. Synthetic
tests can be used for parameters that cannot be established in this
manner.&lt;br/&gt;Kernels are essentially the serial building blocks of parallel
problems. Although kernels are usually characterized by serial control flow,
most of the time they already rely on a high degree of data parallelism. Today's
CPUs get most of their performance from SIMD parallelism, and GPUs get their
performance from massive SIMT parallelism. The role of the kernel modeling
component is two-fold: 1) to tune kernels for maximum performance at a given
granularity, 2) to provide the kernel performance model as a function of
granularity, which is changing to accommodate parallel execution.&lt;br/&gt;DARE
turns to a stochastic time-stepping simulation in order to predict the
performance of a dynamic runtime scheduler for two fundamental reasons: 1)
Building good performance models on the basis of benchmarking actual parallel
runs requires a significant number of runs with significant problem sizes, which
is simply too time consuming. And 2), the impact of many tuning parameters is
too complex to be modeled by sparsely sampling the tuning space and fitting
simple curves / surfaces to the sample points. The answer to the problem is to
replace the run with a time stepping simulation, where a given task-based
scheduler is used for assigning tasks to cores, but instead of invoking actual
kernel tasks, control is passed to a progress tracking simulation system, which
relies on kernel performance models to simulate the execution of the tasks and
produce a virtual trace of the simulated execution. The performance advantage is
twofold: 1) Simulating a single run is much faster than actually making that
run, and 2) Many simulations can be run in parallel allowing for fast sweeps
through a large parameter search space.&lt;br/&gt;DARE replaces the standard
waterfall autotuning process with a process that is incremental and iterative in
nature. The power of the DARE approach lies in the mutual refinement loop, where
each of the three phases is capable of massively pruning the search space for
the other two. As a result, very high quality models can be built for a
particular workload, since time is being spent refining the model for the
conditions that actually apply, rather than sampling the search space in areas
never touched at runtime.