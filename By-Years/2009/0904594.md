* 0904594
* Computational Mechanisms for Storing Motor Memories in Noisy Neural Circuits: How Activity Patterns Evolve during Learning
* CSE,IIS
* 08/01/2010,01/31/2015
* Neville Hogan, Massachusetts Institute of Technology
* Continuing Grant
* Kenneth Whang
* 01/31/2015
* USD 716,675.00

From throwing a baseball to playing the piano to typing on keyboards, human
beings are constantly learning new sensorimotor skills. During learning,
synaptic connections in the brain must be modified to form a motor memory.
Further, this modification seems both permanent and robust: a sensorimotor
skill, once learned, tends to persist throughout the course of a lifetime
regardless of its salience (recall the old adage of never forgetting how to ride
a bike). Despite the importance of motor memories, their distinctive features,
and their ubiquity in vertebrate behavior, little is known about the
computational principles and mechanisms that subserve the acquisition of
sensorimotor skills. This US-Canadian collaborative project takes an
interdisciplinary approach aimed at elucidating neural mechanisms of motor
memory formation and unifying -- under a common theoretical principle -- the
findings of single-neuron recording studies with established behavioral results.
The theory that is proposed makes the following testable prediction: as the
level of behavioral expertise in a specific task increases, the neural
representation for that skill becomes more selective. By selective, it is meant
that a neuron significantly recruited during the performance of the skill tends,
with practice, to specialize by firing only when that skill is performed (and
not when related skills are performed).&lt;br/&gt;&lt;br/&gt;Central to the
theory is a geometric interpretation of "biologically plausible" sensorimotor
neural networks, in which neurons are modeled as noisy signal processors and
synaptic change is modeled as a noisy morphological process. Because of the high
noise levels, it is shown that the system must be "hyperplastic" -- that is, the
learning rate must be unusually high in order to compensate for the noise and
operate at an acceptable performance level. Geometrically, the solution for a
skill can be represented as a manifold in the weight space of the network. To
learn multiple skills, a network configuration must be attained such that the
solution manifolds intersect. To learn multiple skills without noise leading to
destructive interference, the network must arrive at a point where the
intersecting solution manifolds are orthogonal. With this principle of
orthogonality, the neurophysiological predictions described above can be
explicitly formulated. These predictions will be tested with an experimental
method -- involving floating microelectrode arrays and antidromic stimulation --
that enables the identifiably same neuron to be recorded from for multiple
days/weeks, while a behaving animal learns a task. Finally, psychophysical
predictions of the theory will also be tested.&lt;br/&gt;&lt;br/&gt;This project
is jointly funded by Collaborative Research in Computational Neuroscience and
the OISE Americas program. A companion project is being funded by the Canadian
Institutes of Health Research.