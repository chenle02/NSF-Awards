* 1451475
* Phonological implications of covert articulatory variation
* SBE,BCS
* 06/15/2015,11/30/2021
* Jeff Mielke, North Carolina State University
* Standard Grant
* Mary Paster
* 11/30/2021
* USD 376,956.00

The most obvious difference between spoken languages is that they sound
different from one another. The sounds of language interact with each other
according to patterns that can be attributed to the human vocal tract, auditory
system, and memory, but these patterns vary arbitrarily from language to
language and dialect to dialect. Understanding how each language and dialect
came to be the way it is requires understanding how languages change. A
lingering mystery is why language change occurs abruptly in certain times and
places but not in others, when the phonetic motivations for language change are
ever-present. Unlocking this and other puzzles about variation and change in
linguistic sound systems provides a window into cognition, physiology, social
interaction, and how these interact with each other.

This project is a laboratory study of language variation and change, informed by
a database of phonological patterns in several hundred languages and a database
of hundreds of hours of spontaneous speech from one English-speaking community.
The project tests the hypothesis that the start of language change is favored by
covert differences in articulation, i.e., cases where speakers of the same
language produce speech sounds using their vocal tracts in different ways, even
though the sounds they make are indistinguishable to listeners under most
conditions. Different speakers producing the same speech in different ways is
hypothesized to be an important source of variation that drives language change.
The random alignment of covert articulatory differences with social structure is
hypothesized to account for the abruptness and infrequency of sound change. The
research team examines three known cases of covert articulatory variation in
English and assesses their impact on a range of sound patterns active in
Raleigh, NC. The project augments an existing collection of 200+ sociolinguistic
interviews with ultrasound video of the tongue, airflow measurement from the
nose and mouth, and perception data. The research team will develop tools for
rapid and flexible analysis of large quantities of articulatory data. These
tools will be shared publicly, with the potential to benefit other linguists,
speech pathologists, and engineers. The project expands and upgrades a public
database of sound patterns in several hundred languages. The speech sounds
focused on by the project include ones that are challenging to English-learning
children and adults. Detailed phonetic information will be shared with the
speech pathology and language teaching communities. Graduate and undergraduate
students working on this project will learn innovative laboratory methods and
quantitative skills.