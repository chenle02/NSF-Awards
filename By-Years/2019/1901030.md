* 1901030
* III: Medium: Visually Interactive Neural Probabilistic Models of Language
* CSE,IIS
* 11/01/2019,10/31/2023
* Hanspeter Pfister, Harvard University
* Continuing Grant
* Hector Munoz-Avila
* 10/31/2023
* USD 1,200,000.00

The application of machine learning to automate everyday tasks is becoming
increasingly common. While automation has the potential of yielding higher
efficiency and improved outcomes, it can lead to unpredictable mistakes that can
be hard to analyze and correct. Users of machine learning algorithms need better
explanations for predictions and choices that are made. Moreover, to prevent
harm, a user should be able to intervene in and control the decision process of
the algorithm. This award is primarily concerned with applications in neural
language models, i.e., machine learning systems that communicate using natural
language. Because these systems interact with users using text or speech, it is
essential to avoid misinformation from automated approaches and to retain human
agency. Developing explainable and controllable artificial intelligence methods
will empower users to collaborate with automation tools and gain efficiency and
performance benefits while at the same time preventing harm and misinformation.
&lt;br/&gt;&lt;br/&gt;This project targets the development of methods and
visually interactive tools that allow researchers to develop, examine, and
correct probabilistic neural models of language. Co-designing machine learning
models and visual interfaces will be a necessary step towards interpretable
models for common use-cases such as language summarization, translation, and
data-to-text applications. To achieve these interactive and collaborative
systems requires developing novel probabilistic neural network models with
latent variables that can act as "hooks" within the model. These hooks
correspond to interpretable decisions that a model has to take and that enable
end-users to overwrite and interact with model decisions. In a second step, the
project will develop query and visualization methods that utilize these hooks to
allow users to explore, debug, and improve neural models on real examples
through interactive user feedback. The project progress will be evaluated using
quantitative methods from machine learning, qualitative and quantitative user
studies, and long-term longitudinal observations of user engagement. The project
will result in an extensible software framework for visually interactive
analysis of neural sequence models that will assist other researchers and
developers in their application domains.&lt;br/&gt;&lt;br/&gt;This award
reflects NSF's statutory mission and has been deemed worthy of support through
evaluation using the Foundation's intellectual merit and broader impacts review
criteria.