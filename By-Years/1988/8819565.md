* 8819565
* Recovery of Viewer-Centered and Object-Centered Depth from  2-D Projections
* SBE,BCS
* 02/15/1989,01/31/1992
* Myron Braunstein, University of California-Irvine
* Continuing Grant
* Jasmine Young
* 01/31/1992
* USD 163,642.00

The visual environment is three-dimensional, but our information about it is
based on two-dimensional retinal projections. This research will investigate two
types of processes for recovering three-dimensional relationships from two-
dimensional images. The first type of process recovers distances from the eye to
features in the environment. The research will examine two examples of this type
of process: stereoscopic vision and motion parallax (the perception that objects
moving faster in the retinal projection are closer to the eye). The second type
of process recovers three-dimensional relationships among objects in the
environment independently of distances from the eye. "Structure- from-motion" is
the example of this type of process that will be considered. Perceptions based
on structure-from-motion recover three-dimensional relationships among objects
directly from the relative motions of the objects, assuming only that the
objects are moving rigidly or at constant speeds. Information about three-
dimensional distances from the eye and information about three-dimensional
relationships among objects must be integrated to provide a complete perception
of the three-dimensional environment. Preliminary research has shown that
structure- from-motion facilitates the use of stereoscopic information. A series
of five experiments will examine the basis for this facilitation. Preliminary
observations have also indicated that similar relative motions projected at the
eye may lead to different three-dimensional perceptions, depending on whether a
motion parallax analysis (projected velocities based on distance from the eye)
or a structure-from-motion analysis (velocities based only on relationships
among objects) is applied by the observer. Three experiments will examine the
conditions that determine which of these alternative interpretations is applied
by human observers. An understanding of how different types of information for
perceiving three-dimensional relationships from two-dimensional images are
combined has relevance to such questions as: Can people lacking stereoscopic
vision when tested with static displays demonstrate stereoscopic ability when
motion is added to the displays, and how should the three-dimensional
environment be represented in artificial displays requiring accurate observer
responses, such as flight simulator displays and aircraft displays that
represent the virtual environment?