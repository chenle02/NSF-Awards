
* 2208518
* Efficient Neural Network Based Numerical Schemes for Hyperbolic Conservation Laws
* DMS,COMPUTATIONAL MATHEMATICS
* 08/15/2022,08/03/2022
* Xiangxiong Zhang,IN,Purdue University
* Standard Grant
* Leland Jameson
* 07/31/2025
* USD 271,606.00

Neural network based methods have achieved success for many scientific computing
problems, but for many other problems, they still lack satisfying and practical
efficiency when compared to classical numerical methods. The PI will explore
various approaches for enhancing efficiency of neural network based methods for
solving hyperbolic conservation laws, which is a class of model equations used
in many important applications including gas dynamics and basically describe
transport. In addition, advanced optimization algorithms will be explored. As a
generic approach for solving PDEs, neural network based methods are still way
less efficient than classical numerical methods in many applications, especially
for hyperbolic conservation laws. The PI will explore methods for enhancing
efficiency of neural network based methods for solving time-dependent hyperbolic
conservation laws by using neural network as a spatial discretization along with
suitable limiters for enforcing convex invariant domain by non-smooth convex
optimization. A structured deterministic initialization of a neural network and
a finite volume method for updating cell averages can be used to accelerate
convergence of optimization for finding neural network solutions. Another focus
of the project is to explore inspirations of recent breakthroughs in numerical
PDEs toward designing more efficient optimization algorithms. In addition,
optimization techniques from unconditionally stable schemes for gradient flow
will be explored. A novel approach for constructing efficient neural network
based numerical schemes for conservation laws will be investigated. A finite
volume formulation will be used so that classical time marching tools can be
easily combined with a neural network spatial discretization to simplify the
optimization problem for acceleration of convergence. Rigorous analysis of non-
smooth optimization algorithms for a limiter enforcing convex invariant domain
along with efficient limiter implementation will be explored. Recent
breakthroughs in unconditionally stable schemes for phase field equations will
be applied to large scale optimization algorithms to seek possibly more
efficient steady state solvers for gradient descent type algorithms in data
science.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.
