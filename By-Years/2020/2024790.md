* 2024790
* NRI: FND: Coordinating and Incorporating Trust in Teams of Humans and Robots with Multi-Robot Reinforcement Learning
* CSE,IIS
* 10/01/2020,09/30/2024
* Stacy Marsella, Northeastern University
* Standard Grant
* Cang
* 09/30/2024
* USD 646,999.00

The decreasing cost and increasing sophistication of robot hardware has created
new opportunities for applications where teams of robots can be deployed in
combination with skilled humans to automate labor-intensive tasks. However, if
such systems are to become widely deployable, they must be able to appropriately
reason about human teamwork. Therefore, this project will create new methods for
generating and solving models for teams of multiple humans and robots working
together to solve complex problems. These approaches will be able to learn
quickly from limited interactions and consider the dynamic and uncertain nature
of coordinating teams of robots and humans. Furthermore, the project will
develop methods that allows for communication between the robots and humans and
incorporates models of trust to permit humans and robots to appropriately
establish trust in each other.&lt;br/&gt;&lt;br/&gt;In particular, this project
will produce several novel methods for modeling and learning solutions for teams
of robots interacting with multiple people. The approaches will leverage the
strengths of POMDPs to consider the dynamic and uncertain nature of coordinating
teams of robots and humans. Because sample efficiency is of utmost importance
when dealing with humans and real-world tasks when the number of interactions
will be limited, the project will develop Bayesian reinforcement learning
methods that scale by exploiting hierarchy and deep learning. The project will
also develop methods for communication and shared mental models to allow the
humans and robots to have confidence in what each other is doing. These methods
will allow tight cooperation between the humans and robots. Furthermore, humans
will not want to use our system if they cannot trust the robots. Therefore, the
project will develop methods that model and incorporate trust into the approach
while generating interpretable POMDP models and solutions that can be shared
with humans during or after execution. These advances will produce high-quality
solutions for mixed human-robot teams in realistic
scenarios.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.