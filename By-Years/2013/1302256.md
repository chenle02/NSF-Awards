* 1302256
* RI: Medium: Collaborative Research: BCSP: Automated Parameter Tuning of Large-Scale Spiking Neural Networks
* CSE,IIS
* 09/15/2013,08/31/2017
* Kenneth De Jong, George Mason University
* Standard Grant
* Kenneth Whang
* 08/31/2017
* USD 474,996.00

A framework will be developed to help scientists and engineers create brain-
inspired, brain-sized networks that can carry out practical applications. Large-
scale spiking neural networks, which follow the brain's architecture and
activity, have been used to successfully model phenomena such as learning and
memory, vision, auditory processing, neural oscillations, and many other
important aspects of neural function. Additionally, spiking neural networks are
particularly well suited to run on neuromorphic hardware, state of the art
computers that emulate the brain?s structure and dynamics. These neuromorphic
systems depend on the binary nature of spikes to lower communication bandwidth
and energy consumption. Although significant progress has been made towards the
specification and simulation of large-scale spiking neural networks on a variety
of hardware platforms, many challenges remain before these neurobiologically
inspired algorithms can be used in practical applications. While biology does
provide increasingly abundant empirical data that can constrain these systems,
many parameter values must be chosen manually by the designer to achieve
appropriate neuronal dynamics, a task that is extremely tedious and often error-
prone. To meet this challenge, an automated parametertuning framework will be
developed that is capable of quickly and efficiently tuning large-scale spiking
neural networks. The framework will leverage recent progress in evolutionary
algorithms and optimization techniques for off-the-shelf graphics processing
units (GPUs). The parameter search will be guided by the idea in neuroscience
that biological networks adapt their responses to increase the amount of
transmitted information, reduce redundancies, and span the stimulus space. This
notion of efficient coding will guide the tuning process of the artificial
spiking neural networks. Computer scientists and engineers will be able to use
the resulting automated parameter-tuning framework to create brain inspired
applications, such as vision and memory systems, on neuromorphic hardware.
Moreover, the resulting framework will allow neuroscientists to more readily
create models that better describe their empirical data and generate new
quantitative hypotheses that can be tested in the laboratory.