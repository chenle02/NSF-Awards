* 2212418
* Collaborative Research: III: Medium: Conditional Transport: Theory, Methods, Computation, and Applications
* CSE,IIS
* 10/01/2022,09/30/2026
* Mingyuan Zhou, University of Texas at Austin
* Standard Grant
* Sorin Draghici
* 09/30/2026
* USD 600,000.00

Measuring the difference between probability distributions is a fundamental
problem in statistics and machine learning (ML). It plays essential roles in
many critical ML and artificial intelligence (AI) tasks, such as building deep
generative models to synthesize realistic data and training deep reinforcement
learning agents. The project’s novelties are 1) establishing Conditional
Transport (CT) as a new statistical distance between probability distributions
to address several key limitations of existing methods, 2) developing a new
distribution-based learning framework with efficient approximate computation
algorithms, and 3) applying CT to better solve modern ML/AI problems involving
large-scale and high-dimensional data and models. The project’s impacts are 1)
advancing distribution-based ML/AI fundamental research, and 2) enabling
efficient and robust methods for the ML/AI applications in science, engineering,
and bio-medicine, in particular in inverse materials design and multi-omics data
analysis. The investigators will integrate the proposed research with training,
education, and outreach activities for next-generation workforce development, by
developing new ML/AI course materials to better prepare students and researchers
at all levels with a diversified educational background, promoting diversity,
equity, and inclusion with the emphasis on attracting talents from under-
represented groups, with a special emphasis on broadening participation in
interdisciplinary computing. &lt;br/&gt;&lt;br/&gt;This project aims to
establish CT and its enabled distribution-based learning framework, which has
the paradigm-shift potential to further advance ML/AI research with new models
and inference algorithms. In particular, 1) theoretical understanding of CT will
provide the foundation of this new learning framework with desired model
representation power as well as learning stability. 2) Maximum likelihood
estimation, Bayesian inference, and entropy regularized optimal transport will
be revisited based on CT, enabling efficient Bayesian computation and
optimization taking advantage of modern deep network models and stochastic
gradient descent tools. 3) New and improved ML/AI models and inference
algorithms will be developed for deep generative modeling, contrastive
representation learning, and deep reinforcement learning to advance the state of
the art. 4) Inverse materials design and multi-omics data analysis, two real-
world applications that require reliable uncertainty quantification for
consequent critical decision making, will showcase the advantages of the CT-
based methods.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission
and has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.