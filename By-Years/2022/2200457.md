* 2200457
* EXCELLENCE in RESEARCH: SECURING MACHINE LEARNING AGAINST ADVERSARIAL ATTACKS FOR CONNECTED AND AUTONOMOUS VEHICLES
* CSE,CNS
* 10/01/2022,09/30/2025
* Negash Begashaw, Benedict College
* Standard Grant
* Subrata Acharya
* 09/30/2025
* USD 492,914.00

This research is motivated by the need to boost U.S. competitiveness and
increase the number of young people with an in-depth understanding of the
safety, security, and dependability of intelligent systems by accelerating the
adoption of threat identification and attack-resistant control countermeasures.
Future cyberattacks on connected and automated vehicles will necessitate the
study and development of novel countermeasures to increase market acceptance of
these vehicle technologies, which could improve traffic conditions, vehicle and
personal safety, and energy efficiency. This award will contribute to the
intellectual development of underrepresented undergraduate and graduate students
in modeling, Artificial Intelligence, and communication to address cybersecurity
issues in connected autonomous vehicles. The prime objective of this research is
to create a defense technique that will enable Connected Autonomous Vehicles to
be more resistant to adversarial attacks and hence capable of meeting more
stringent safety and performance requirements. Another key focus is to involve
teams of undergraduate and graduate students in creative inquiry and design
projects based on hands-on demo platforms. This research focuses especially on
enhancing the resilience of Connected Autonomous Vehicles against the
possibility of adversarial attacks aimed at affecting the performance of the
perception module, thereby improving vehicle reliability and functional safety
beyond currently adopted practices. In addition, the award has larger
theoretical implications in the fields of security, Machine Learning, filtering,
and optimization, ultimately expediting the deployment of connected autonomous
vehicles.&lt;br/&gt;&lt;br/&gt;Recent advancements in connected and autonomous
vehicles reveal that several companies are investing substantially in the
development of perception modules based on machine learning algorithms. However,
these machine learning algorithms are vulnerable to adversarial attacks designed
to mislead the input of the deep neural network to induce a misclassification,
which may undermine vehicle decision-making and, therefore, functional safety.
Through wireless Ethernet connectivity, attackers may compromise the in-vehicle
computer platform and obtain access to the sensor data stored in memory. Before
the perception module, adversarial inputs may be introduced to supplant the
original normal inputs and destabilize vehicle operations. The overall framework
comprises modeling potential adversarial threats impacting the perception and
fusion process and designing both reactive and proactive countermeasures for the
secure and reliable functioning of the system. This technique is modular and can
be deployed to a range of Deep Neural Network applications such as robotics,
biometric identification, and speech recognition. Incorporating robustness
measures during the training phase will yield a more resilient Deep Neural
Network. Moreover, filtering at several stages of the perceptron process can be
used to develop a system that can innately tolerate a greater spectrum of
attacks. The project tasks aim at conducting fundamental research on a plan that
includes adversarial attack modeling for single and fused sensor data, novel
data filtering algorithms for detecting various white-box and black-box attacks,
revised Deep Neural Network training based on robustness/sensitivity tradeoff in
optimization models, evaluation of the impact of sensor fusion, and testing the
framework on F1/10 cars and autonomous golf cars.&lt;br/&gt;&lt;br/&gt;This
award reflects NSF's statutory mission and has been deemed worthy of support
through evaluation using the Foundation's intellectual merit and broader impacts
review criteria.