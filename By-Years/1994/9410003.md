* 9410003
* RIA:  Model-Based Robotic Visual Servoing
* CSE,IIS
* 08/15/1994,07/31/1997
* Nikolaos Papanikolopoulos, University of Minnesota-Twin Cities
* Continuing Grant
* Howard Moraff
* 07/31/1997
* USD 55,000.00

This research pursues a model-based approach for visual tracking and servoing in
robotics. Deformable active models are explored as an effective way for tracking
a rigid or semi-rigid (possibly partially occluded) object in movement within
the manipulator's workspace. Deformable models imitate, in real-time, the
dynamic behavior of elastic structures. These computer-generated models are
designed to capture the silhouette of rigid or semi-rigid objects with well-
defined boundaries, in terms of image gradient. By means of an eye-in-hand robot
arm configuration, the desired motion of the end-effector is computed with the
objective of keeping the target's position and shape invariant with respect to
the camera frame. Optimal estimation and control techniques (LQG regulator)
techniques are used in order to deal with noisy measurements provided by the
vision sensor. Preliminary experimental results show that the deformable models
help to achieve robust tracking even when the target is partially occluded.
These techniques will be applied to assembly tasks that involve a combination of
vision and force robot control. Finally, the algorithms will be tested by
applying them to transportation problems such as pedestrian tracking and vision
based vehicle- following.