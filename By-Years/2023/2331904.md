* 2331904
* SLES: CRASH - Challenging Reinforcement-learning based Adversarial scenarios for Safety Hardening
* CSE,IIS
* 12/01/2023,11/30/2026
* Madhur Behl, University of Virginia Main Campus
* Standard Grant
* Cang Ye
* 11/30/2026
* USD 799,803.00

Autonomous vehicles, with their reliance on learning-enabled components for key
operations, promise an exciting future for transportation. Yet, assuring the
safety of these vehicles amid unpredictable real-world traffic scenarios filled
with 'unknown unknowns' remains a significant hurdle. While on-road testing is
essential, it is time-consuming, risky, and insufficient due to the rarity of
safety-critical traffic situations. High-fidelity simulations present a
promising way to complement these efforts, allowing us to stress-test autonomous
vehicles in a myriad of challenging scenarios. This raises key questions: how
can we generate rare, but realistic traffic situations in simulation that would
truly stress test an autonomous vehicle's safety? Moreover, how can we
continuously improve the autonomous vehicle's software to learn from each
identified failure? In response, this project offers an innovative approach
where we purposefully introduce rare but realistic scenarios in simulation that
may cause autonomous vehicles to fail, and then enhance the software to ensure
these failures do not reoccur. The implications of the research extends beyond
safety improvements, having the potential to redefine industry practices, shape
regulatory frameworks for autonomous vehicle safety, and ensure the safe and
reliable deployment of autonomous vehicles.

The project will develop a new framework, named CRASH - Challenging
Reinforcement-learning based Adversarial scenarios for Safety Hardening. CRASH
leverages a novel multi-agent adversarial deep reinforcement learning setting to
automatically and effectively stress test existing autonomous vehicle software
stacks, helping identify potential failures in motion planning. It then enhances
the AV's safety performance by improving its ability to avoid repeating these
failures and learn from them. Notably, CRASH emphasizes the realistic,
plausible, and naturalistic aspects of identified AV failures, mirroring
unexpected situations in real-world traffic conditions. The real strength of
CRASH is its iterative process, where after each falsification, an improvement
simulation leads to continuous enhancement of the autonomous vehicle stack - an
approach the team termed safety hardening. This iterative refinement fortifies
an AV's safety, allowing it to navigate unexpected traffic situations more
efficiently, thereby increasing its resilience. The project provides a pragmatic
and reliable pathway to advance the safety testing of autonomous vehicles that
rely heavily on learning-enabled components so that they can navigate our roads
with an enhanced level of safety and robustness.

This research is supported by a partnership between the National Science
Foundation and Open Philanthropy.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.