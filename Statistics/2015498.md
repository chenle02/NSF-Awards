
* 2015498
* Scalable Algorithms for Bayesian On-Line Learning with Large-Scale Dynamic Data
* DMS,STATISTICS
* 08/01/2020,06/20/2020
* Faming Liang,IN,Purdue University
* Standard Grant
* Pena Edsel
* 07/31/2023
* USD 250,000.00

Bayesian methods provide a principled way for assessing model uncertainty in
machine learning of big data, which is critical to the development of
trustworthy artificial intelligence (AI). However, the lack of efficient Monte
Carlo algorithms has drastically hindered applications of Bayesian methods in
the big data era. Compared to frequentist methods, Bayesian methods are often
much slower. To tackle this difficulty, a variety of scalable Monte Carlo
algorithms have been developed in the recent literature. However, these
algorithms can only be applied to static data; none of them can be directly
applied to dynamic data. Many of the problems centering data science, such as
natural language processing, autonomous car driving and weather forecasting, are
facing challenges of dynamic data. The traditional particle filters or
sequential Monte Carlo algorithms lack the scalability necessary for dealing
with large-scale dynamic data. By reformulating the ensemble Kalman filter
(EnKF) under the framework of Langevin dynamics, this project proposes
Langevinized EnKF as a general and scalable stochastic gradient sequential Monte
Carlo algorithm for Bayesian on-line learning with large-scale dynamic data. The
Langevinized EnKF improves uncertainty quantification for a wide class of data
assimilation problems, advancing the development of trustworthy AI. Successful
completion of this project will generate a set of scalable and theoretically
rigorous algorithms for Bayesian on-line learning, which can provide significant
benefits to the development of data driven technologies. The research results
will be disseminated to communities of interest via collaborations,
publications, and conference presentations. The project will also have
significant impacts on education through direct involvement of graduate students
and incorporation of the research results into undergraduate and graduate
courses.

Although the EnKF has been extremely successful in dealing with complex dynamic
data encountered in oceanography, reservoir modeling and weather forecasting, it
does not converge to the right filtering distribution except for linear systems
in the large ensemble limit. The Langevinized EnKF resolves this issue; it
converges to the right filtering distribution in data assimilation and is thus
able to quantify uncertainty of the underlying dynamic system. The Langevinized
EnKF can also be used for Bayesian learning with large-scale statistic data by
reformulating the Bayesian inverse problem as a state-space model with Langevin
dynamics and the subsampling technique. Different variants of the Langevinized
EnKF will be developed to extend its applications to non-Gaussian data and
incomplete data. As the whole, this project will provide a complete treatment
for Bayesian analysis of big data. The Langevinized EnKF can be applied to big
data problems in various data scenarios: dynamic data and static data, Gaussian
data and non-Gaussian data, and complete data and incomplete data, provided the
data is classified in different ways. Statistical theory underlying the
Langevinized EnKF will be rigorously studied. Exciting scientific applications,
including language modeling and dynamic network analysis, will be conducted.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.
