* 0347740
* CAREER: Precomputing Data-driven Deformable Systems for Multimodal Interactive Simulation
* CSE,CCF
* 02/15/2004,05/31/2007
* Doug James, Carnegie-Mellon University
* Continuing Grant
* Lawrence Rosenblum
* 05/31/2007
* USD 254,201.00

James, Doug&lt;br/&gt;Carnegie Mellon
University&lt;br/&gt;CCF-0347740&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;Deformation
phenomena are a rich and integral part of our lives; it affects our appearance
(e.g., skin, hair), the sounds we make (e.g., clothing, vocal cords), beauty in
nature (e.g., a forest blowing in the wind), and important decisions (e.g.,
medical planning). Deformation modeling has made enormous progress, but we still
desire increasingly realistic levels of geometric and dynamic complexity.
Deformation also plays an important role in multimodal feedback for virtual
environments: feeling contact forces using haptic interfaces, seeing realistic
deformable appearances with shadows and interreflections, and hearing contact
sounds. Not only are accurate deformations required at high rates, but the
phenomena can also be extremely complex.&lt;br/&gt;&lt;br/&gt;Given the
conflicting demands of real-time interactivity and complex large-scale
simulation, one logical algorithmic strategy is to do as much work ahead of time
as possible. Exploiting massive precomputation and data-driven tabulation is
appealing, but how this can be done, and to what extent, remains a mystery for
most nonlinear systems. Nevertheless, preliminary evidence suggests that
potential precomputation speedups are easily a million-fold. By researching
precomputation techniques today, we stand to exploit million-fold speedups for
multimodal simulation on supercomputers of tomorrow.&lt;br/&gt;&lt;br/&gt;Our
scientific objective is to understand how to systematically precompute, simulate
and experience data-driven models of large-scale nonlinear deformable systems.
We address these goals in three ways: (1) precomputation techniques for data-
driven deformable models based on reduced coordinate representations; (2)
deformable motion databases of complex motions for real-time ``playback;'' (3)
multimodal aspects of interactive simulation, including haptic rendering of
contact forces, data-driven deformable sound models, and precomputed deformable
object appearance models. Our research is driven by real-world applications, and
will be explored in the broad context of interactive computer animation, virtual
medicine, robotics and manufacturing, and simulation of large-scale natural
environments.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;