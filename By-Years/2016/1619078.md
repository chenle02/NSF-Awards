* 1619078
* RI: Small: Modeling and Learning Visual Similarities Under Adverse Visual Conditions
* CSE,IIS
* 09/01/2016,08/31/2021
* Ying Wu, Northwestern University
* Standard Grant
* Jie Yang
* 08/31/2021
* USD 440,000.00

In many emerging applications such as autonomous/assisted driving, intelligent
video surveillance, and rescue robots, the performances of visual sensing and
analytics are largely jeopardized by various adverse visual conditions in
complex unconstrained environments, e.g., bad weather and illumination
conditions. This project studies how and to what extend such adverse visual
conditions can be coped with. It will advance and enrich the fundamental
research of computer vision, and bring significant impact on developing "all-
weather"computer vision systems that benefit security/safety, autonomous
driving, and robotics. The project contributes to education through curriculum
development, student training, and knowledge dissemination. It also includes
interactions with K-12 students for participation and research opportunities.
&lt;br/&gt;&lt;br/&gt;This research seeks innovative solution to overcome
adverse visual conditions for visual sensing and analytics. It explores a
unified approach that avoids explicit image restoration that is in general
computationally demanding. It is focused on learning the "alignment" between the
two image spaces under adverse and normal conditions, rather than learn
everything from scratch. Acting on low-quality data directly without image
restoration, this research leads to innovative and computationally efficient
solutions to handle adverse visual conditions. Visual restoration can also be
done as by-products, and the same approach also provides a general solution to
target attribute estimation. The research is focused on: (1) constructing a
principled model, called space alignment that models and learns visual
similarity, and its theoretical foundation, (2) developing new effective visual
matching and tracking approaches based on learning the appropriate visual
similarity under various adverse visual condition, (3) investigating visual
attribute estimation and identification via learning reconstruction-based visual
regression, and (4) developing effective and efficient tools and prototype
systems for visual detection, identification, tracking and recognition.