* 2304799
* I-Corps: Detecting Performance Degradation and Failures of Deep Neural Networks in Cancer Imaging
* TIP,TI
* 03/15/2023,08/31/2024
* Ghulam Rasool, H. Lee Moffitt Cancer Center and Research Institute Hospital Inc
* Standard Grant
* Ruth Shuman
* 08/31/2024
* USD 50,000.00

The broader impact/commercial potential of this I-Corps project is the
development of a failure detection framework that learns the behavior of the
machine learning model under various noisy conditions. This solution is
currently focused on cancer imaging applications, especially head and neck, lung
and brain cancers. Neural networks are used in many areas of the human endeavor,
and their use is expected to increase exponentially. These machine learning
models do not provide a measure of confidence in the decisions and fail without
warning. There are no solutions for addressing these issues except manually
monitoring and reviewing the performance of these models after deployment. The
proposed technology can integrate seamlessly with any machine learning model
before or after deployment and output model confidence in the decision with
minimal additional computational cost. The proposed technology will help
artificial intelligence find its true potential in mission-critical areas. The
proposed mechanisms for detecting performance degradation and model failure can
provide a path to achieve the much-desired trustworthiness in artificial
intelligence models. The applicability of the proposed technology encompasses
various areas, including healthcare, transportation, cybersecurity, economics,
environment, and financial services.

This I-Corps project is based on the development of a generalized framework that
quantifies the performance and detects failure in all types of machine learning
models, including convolutional neural networks and transformers. This framework
does not require retraining of the original model and can be used as an out-of-
the-box solution. This technique consists of different methods to identify the
type of machine learning model and its output. This information is used to
specify a fixed threshold or learn a dynamic one. These threshold values serve
as a guide for identifying the performance degradation of the machine learning
model. In the first case, the technology defines a fixed threshold value based
on the model performance on the test dataset with a changing signal-to-noise
ratio. The second method learns the threshold value using a shallow neural
network. The proposed failure detection methods seamlessly integrate with the
original machine learning model and abstain from making decisions when the
modelâ€™s confidence is below the threshold. This technique, when used during the
machine learning model training phase, can help improve model accuracy.

This award reflects NSF's statutory mission and has been deemed worthy of
support through evaluation using the Foundation's intellectual merit and broader
impacts review criteria.