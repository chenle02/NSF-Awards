* 9626266
* Artificial and Approximate Likelihoods
* MPS,DMS
* 08/01/1996,07/31/2000
* Per Mykland, University of Chicago
* Standard Grant
* Joseph M. Rosenblatt
* 07/31/2000
* USD 120,000.00

DMS 9626266 Mykland The project seeks to extend the use of likelihood methods
to semi- and nonparametric situations. Important questions include how to define
and assess the accuracy of the likelihood ratio and R-star statistics. Of
particular interest so far has been the development of the dual likelihood, of
Bartlett identities for martingales, and of embedding techniques which permit
the derivation of asymptotic expansions for martingales. Currently, the
investigators are expanding the theory to cover non-martingale situations, by
considering criterion functions which are approximately likelihoods. This covers
a much broader spectrum of data analysis problems. It is desirable to describe
what types of inference can be covered by this, and what corrections over
likelihood inference that ought to be used when carrying out procedures based on
this approach. The study concerns both existing procedures (such as empirical
and point process "likelihoods"), and at new constructions which arise from the
artificial likelihood point of view. In particular, the "design-your-own
likelihood" is being investigated, with particular reference to resampling based
criterion functions. The implications for problems in financial engineering and
investment under uncertainty are being studied as part of the project. Policy
makers in both business and goverment are faced with the need to take decisions
under uncertainty. Firms invest in new plants, for instance, with imperfect
knowledge of current and future market conditions for their products.
Regulations concerning the environment, as another example, often try to affect
systems that are so complex that even with the best models and scientific
studies, there is tremendous uncertainty about the effects of one's actions.
Decisions in such circumstances not only require estimates and predictions, but
also a maximally accurate quantification of how far away such estimates are
likely to be from the actual figures. This project is about a new technology for
doing this, one that substantially improves the reliability of such assessments.
It is based on a statistical theory ("likelihood inference") first developed in
Britain in the 1920s, but which has only in the last few years been opened up to
the more complex and vaguely specified systems often faced by policy makers.