* 1311033
* NSF East Asia and Pacific Summer Institute (EAPSI) for FY 2013 in Japan
* O/D,OISE
* 06/01/2013,05/31/2014
* Richard Veale, Veale                   Richard        E
* Fellowship Award
* Anne Emig
* 05/31/2014
* USD 70.00

This action funds Richard Veale of Indiana University to conduct a research
project in the Computer and Information Science and Engineering area during the
summer of 2013 at the National Institute of Physiological Sciences in Okazaki,
Aichi Prefecture, Japan. The project title is "How Do Small Eye Movements Help
Us See Things?" The host scientists are Dr. Tadashi Isa and Dr. Masatoshi
Yoshida.

Microsaccades are very small eye movements which take place during periods of
gaze fixation. This research investigates the influence of microsaccades on
attention via a computational neural model. Specifically, a spiking neural
circuit model of the primate visuo-motor circuit is modified to produce
microsaccade behavior. The model is implemented in a robotic system to control
cameras, whose movement is fit to gaze data from monkeys. To verify that the
neural model is accurate, the model is be fit to data from both intact monkeys
and also to monkeys with damaged visual cortex.

Broader impacts of an EAPSI fellowship include providing the Fellow a first-hand
research experience outside the U.S.; an introduction to the science, science
policy, and scientific infrastructure of the respective location; and an
orientation to the society, culture and language. These activities meet the NSF
goal to educate for international collaborations early in the career of its
scientists, engineers, and educators, thus ensuring a globally aware U.S.
scientific workforce. Furthermore, this research broadly informs our
understanding of how humans can behave intelligently in the real world by
allocating their attention to important aspects of the environment while
ignoring irrelevant distractors. This will both directly allow us to better
understand and treat humans with visual deficits, while also enabling us to
build better autonomous robotic systems by implementing models of the human
visual system in robots. Systems with better visual capabilities will enable a
plethora of new and exciting technologies which require autonomous activity in
busy real-world environments, thus taking robots out of the laboratory and
extending the benefits of the robotic revolution to the average citizen.