* 2114952
* EAGER: SaTC AI-Cybersecurity: Faking It: Facilitating Public Awareness of Cybersecurity Issues in AI
* EDU,DGE
* 07/15/2021,06/30/2024
* Nathan Fisk, University of South Florida
* Standard Grant
* ChunSheng Xin
* 06/30/2024
* USD 300,000.00

The lack of a strong public understanding of artificial intelligence (AI)
technologies represents both a threat to national security and an opportunity
for the development of new approaches to cybersecurity education and research.
The project intends to develop and support a series of publicly accessible AI
challenge competitions aimed at facilitating the public’s understanding of AI
technologies and cybersecurity. All challenges will additionally serve as large-
scale data collection platforms, assisting researchers in better understanding
the trustworthiness and interpretability of AI systems. Project plans include
creating lesson plans and challenges designed simultaneously to broaden
understanding of cybersecurity issues in AI and provide an on-ramp for students
interested in AI and cybersecurity across K-12 and higher education. Overall,
the project team hopes to contribute to and scale ongoing efforts to develop and
administer freely available online curricula that fosters public awareness of
AI.&lt;br/&gt;&lt;br/&gt;There is a clear and urgent need to connect research,
education, and workforce development efforts at the intersection of AI and
cybersecurity due to the highly interdisciplinary nature of AI and machine
learning challenges, as well as the rapid development and adoption of AI
technologies. This project will address these urgent challenges through the
following research questions: First, how do individuals identify trustworthy AI
systems and outputs? Second, how do AI/Cybersecurity concepts align with current
educational standards? Last, how can public understanding and trust of AI be
enhanced further? To answer these questions, the project will develop scaffolded
challenges at the intersection of cybersecurity and AI entitled “Deeperfakes”
and “P0150N”. The project team will work with the non-profit AI Education
Project, working specifically to include modules on deep fakes and the role of
AI in the cybersecurity workforce. The Deeperfakes challenges will ask
participants to verify a series of AI-generated images and media, explaining
their reasoning for either accepting or rejecting various media as real or
fabricated. Similarly, the P0150N challenges will pit students against simple AI
systems modeling those that detect denial of service attacks. This will allow
students to experiment with mechanisms to poison the AI and successfully carry
out an attack. The challenges will also serve as data collection tools and
produce a large, open dataset for AI and cybersecurity research. This dataset
will provide AI and cybersecurity researchers with information on how people
read “faked” algorithmic media as real or fabricated. &lt;br/&gt;&lt;br/&gt;This
project is supported by a special initiative of the Secure and Trustworthy
Cyberspace (SaTC) program to foster new, previously unexplored, collaborations
between the fields of cybersecurity, artificial intelligence, and education. The
SaTC program aligns with the Federal Cybersecurity Research and Development
Strategic Plan and the National Privacy Research Strategy to protect and
preserve the growing social and economic benefits of cyber systems while
ensuring security and privacy.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's
statutory mission and has been deemed worthy of support through evaluation using
the Foundation's intellectual merit and broader impacts review criteria.