* 1124193
* Large State Space Issues in Dynamic Models
* SBE,SES
* 09/15/2011,08/31/2014
* Federico Bugni, Duke University
* Standard Grant
* Nancy Lutz
* 08/31/2014
* USD 391,114.00

The estimation of models of dynamic decision making is complicated by needing to
calculate the future payoffs associated with different choice paths. These
expected future payoffs from behaving optimally in the future are called the
value function. Calculating a value function for a complicated dynamic game is
computationally expensive because of the large number of possible choice paths.
This award funds research to develop a new method for approximating value
functions. The approximation is based on sieve methods, and it has good
asymptotic properties as the complexity of the sieve increases.&lt;br/&gt;These
methods will be useful for models of individual decision making and also useful
for dynamic games, where several individuals make decisions over time. The sieve
method can be used to solve for the finite horizon Nash equilibrium; it can also
be used to test whether this equilibrium is being played by individuals in a
particular application. The research team will apply this method to analyzing
data from a sample of sixth grade students; the dynamic game here is the
establishment of friendships and how students over time form strong peer
networks.&lt;br/&gt;&lt;br/&gt;The new method will potentially advance empirical
work in many areas of applied microeconomics. Because the method is
computationally less expensive, it may be well suited for use by researchers who
wish to estimate dynamic game models at a reasonable cost.