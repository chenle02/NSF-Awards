* 2224213
* AF: Small: Bridging the Past and Present of Continuous Optimization for Learning
* CSE,CCF
* 10/01/2022,09/30/2025
* Stephen Wright, University of Wisconsin-Madison
* Standard Grant
* A. Funda Ergun
* 09/30/2025
* USD 600,000.00

Machine learning (ML) is being used to drive applications of artificial
intelligence in many areas of science and society. Ultimately, ML problems must
be distilled using statistical and mathematical techniques into problems that
can be solved using computational algorithms. For the past 25 years, ML has
depended heavily on the field of optimization to provide a wealth of techniques
to formulate and solve ML problems. Indeed, the ML problems that optimization is
called on to solve continue to grow in complexity and difficulty. Optimization
tools have been applied to some of these modern ML problems, but often in ways
that lack theoretical guarantees on their performance. This project aims to
develop new, powerful, principled optimization approaches for solving these more
complex modern ML problems.&lt;br/&gt; &lt;br/&gt;The project will study several
areas of optimization that are critical to current research in ML, developing
new algorithmic techniques and new theory for these areas. Priorities include
the discovery of algorithms that leverage the structures that characterize
various ML problems, such as sparsity, and the development of theoretical
analysis to illuminate the computational performance of practical algorithms,
including finite-time sample complexity bounds in the presence of nonconvexity.
Three specific thrusts of the project include (i) the development of algorithms
and analysis techniques for convex-concave min-max problems that take into
account sparsity or regularity properties; (ii) the development of theoretically
grounded algorithms for solving nonlinear programs with nonconvex functions and
stochastic oracles, motivated by problems arising in constrained neural
networks, problems with fairness constraints, and distributionally robust
optimization; and (iii) advancing the use of optimization in reinforcement
learning, such as making use of the primal-dual techniques developed in the
first thrust and extending the theory of policy gradient methods to account for
the inexactness that inevitably arises in practical implementations. The
project's research agenda has foundations in classical optimization and more
recent developments in optimization, control, learning theory, and
statistics.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and
has been deemed worthy of support through evaluation using the Foundation's
intellectual merit and broader impacts review criteria.