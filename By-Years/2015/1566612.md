* 1566612
* CRII: CHS: Leveraging Implicit Human Cues to Design Effective Behaviors for Collaborative Robots
* CSE,IIS
* 06/15/2016,05/31/2019
* Daniel Szafir, University of Colorado at Boulder
* Continuing Grant
* Ephraim Glinert
* 05/31/2019
* USD 174,300.00

Robots have the potential to significantly benefit society by actively
collaborating with people in critical domains including manufacturing,
healthcare, and space exploration. But to provide effective assistance, robots
must be able to work with people in a natural, intuitive, and socially adept
manner. Current human-robot collaborations require that people explicitly
communicate their goals and desired responses to robotic partners. As a result,
joint human-robot activities bear little resemblance to scenarios involving
human-human teamwork, where people are able to understand their partner's
implicit cues, such as eye gaze, facial expressions, and intonations, and intuit
appropriate responses, such as moving to a certain location, preemptively
fetching a tool, or providing a clarification. The PI's goal in this project is
to establish a research program that will explore the design of effective
behaviors for collaborative robots by developing computational models that
enable them to sense implicit human communicative cues and guide robot responses
by inferring cue intent, and to evaluate the effectiveness of the new algorithms
in human-robot studies. The research holds significant promise of benefiting
society by helping to achieve a vision of robots acting as key contributors,
partners, and assistants in human work, with applications across a range of
activities including domestic housework, manufacturing, construction,
healthcare, and space exploration. In addition to disseminating project outcomes
to the larger research community, the PI will build on his successful past
outreach activities to provide opportunities for K-12 summer programs centered
on robotics and computer science education.&lt;br/&gt;&lt;br/&gt;To these ends,
the PI will address the challenge of designing effective collaborative robots by
developing a preliminary framework, process, and set of methods to sense and
respond to implicit human communicative behaviors. His approach will involve (1)
observing and classifying implicit cues and responses for human-human teams
engaged in an archetypical collaborative task, (2) developing computational
models of the relationships between goals, cues, and responses using features
and parameters extracted from observed behaviors, (3) integrating implicit cue
sensing and response algorithms to guide robot behaviors in specific
collaborative use cases, and (4) evaluating the effectiveness of these behaviors
on collaborative task outcomes. This research will produce a set of
generalizable design principles for collaborative robots, generate open-source
algorithms showcasing practical implementations, and advance knowledge regarding
computational understanding of human behaviors. Overall, the work will lead to
robots that are able to work more effectively with people and accelerate the
integration of assistive robots into society. It will synthesize theories of
human communication and explore their application to human-robot interaction, as
well as advancing knowledge regarding how robots might provide assistance as
human collaborators and the types of sensors necessary for robots working
closely with human partners. Implicit sensing and response algorithms that have
been empirically validated in HRI experiments will be disseminated as modules
for the open-source Robotic Operating System (ROS).