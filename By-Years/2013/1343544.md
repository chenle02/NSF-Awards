* 1343544
* INSPIRE Track 1:  Action, Vision and Language, and their Brain Mechanisms in Evolutionary Relationship
* SBE,BCS
* 09/15/2013,12/31/2019
* Michael Arbib, University of Southern California
* Continuing Grant
* Betty Tuller
* 12/31/2019
* USD 800,000.00

This INSPIRE award is partially funded by the Perception, Action, and Cognition
Program in the Division of Behavioral and Cognitive Sciences in the Directorate
for Social, Behavioral, and Economic Sciences and the Robust Intelligence
Program in the Division of Information and Intelligent Systems in the
Directorate of Computer and Information Science and
Engineering.&lt;br/&gt;&lt;br/&gt;This research will address and bridge two
grand challenges: (1) To understand how action, perception, and social
interaction were supported by the brain of the last common ancestor of macaque
and human, complementing modeling elsewhere on great apes, and (2) To build on
evolutionary insights to better understand how different parts of the human
brain work together when we use language. Key entry points will be signed and
spoken languages and the use of hand gestures (e.g., novel hand gestures by
apes) to convey meaning. Going further, a particular focus will be on systems
that link the brain's capacities to generate as well as recognize actions, and
their interactions with other brain systems. &lt;br/&gt;&lt;br/&gt;An
international group of scientists in linguistics, primatology, neuroanatomy,
neurophysiology, and neurocomputational modeling of motor, cognitive and
language processes will pool data on the anatomy, physiology, behavior and
communication of the various primate species. To support this extended
collaboration, the researchers will build a novel online collaborative
environment ("Collaboratory Workspaces") to test, make predictions, and
challenge both the modeling and experimentation. This infrastructure may
catalyze a new style of collaboration between modelers, experimentalists, and
clinicians. &lt;br/&gt;&lt;br/&gt;The research also has the potential to support
modeling of the damage that results in the clinical disorders of apraxia and
aphasia. Integration of models of vision, action and language is also important
for creating robots that can flexibly and usefully interact with individual
people and for "neuromorphic architecture," in which a building's sensors and
action systems adaptively adjust to the human inhabitants.