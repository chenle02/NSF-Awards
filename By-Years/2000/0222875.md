* 0222875
* Task-Level Perception From Kinesthetic Sensors
* CSE,IIS
* 09/01/2002,08/31/2006
* Michael Erdmann, Carnegie-Mellon University
* Continuing Grant
* C.S. George Lee
* 08/31/2006
* USD 565,720.00

This research explores perception of task-level information from kinesthetic
sense data in mobile manipulation tasks. A mobile manipulator interacts with the
terrain through its feet or wheels, and it interacts with fixed or mobile
objects through its hands, wheels, bumpers, or other effectors. All of these
interactions contribute to the robot's motion and to internal shape deformations
of the robot, which can be detected by encoders, strain gauges, and other
sensors. This kinesthetic sense data can be used to estimate features of the
terrain, locations of objects, location of the robot, contact state between the
robot and objects, and other task variables. This project is developing a theory
of task-level kinesthetic perception, by developing suitable models of task and
robot dynamics, and using the framework of nonlinear observability to analyze
specific tasks and develop algorithms for estimating task parameters and state
variables. Experimental work includes evaluation of several mobile manipulator
designs, implementation and testing of observers, and demonstration in mobile
manipulation tasks.