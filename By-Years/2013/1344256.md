* 1344256
* INSPIRE Track 1: Human reasoning and learning in a complex but tractable decision-making paradigm
* CSE,IIS
* 10/01/2013,09/30/2018
* Whee Ky Ma, New York University
* Continuing Grant
* Kenneth Whang
* 09/30/2018
* USD 799,782.00

This INSPIRE award is partially funded by the Robust Intelligence Program in the
Division of Information and Intelligent Systems in the Directorate for Computer
and Information Science and Engineering and the Perception, Action, and
Cognition Program in the Division of Behavioral and Cognitive Sciences in the
Directorate for Social, Behavioral, and Economic Sciences.

This project studies a hallmark of human intelligence, namely the ability to
think ahead. Anticipating the consequences of one's own actions and those of
others is of crucial importance in areas as diverse as business negotiations,
military strategy, and teaching. In each of these domains, the quality of one's
decisions depends on the quality of one's mental simulations of event sequences,
which might be limited by cognitive capacity limitations, one's grasp of the
complexities of the decision space, or both. The project's goal is to identify
the factors that affect people's performance in thinking ahead, and investigate
to what extent this performance can be improved through training. The project
ties into the study of heuristics (general rules used by decision-makers) in
psychology and behavioral economics.

Thinking ahead is difficult to measure and model in real-world problems.
Therefore, the investigator has developed a two-person strategic decision-making
task as a controllable experimental environment. Participants take turns to put
tokens on a 4x11 board and try to get four of their own tokens in a row. The
rules are unfamiliar to subjects, yet easy to learn. The size of the state space
for this task is of the order of 10^20, much smaller than that of chess
(~10^47), yet of appreciable complexity and much too large for humans to easily
grasp. The investigators have "weakly solved" this task using an improved
version of alpha-beta pruning. It can most likely also be solved strongly, which
means that one can determine in any given position whether any given decision is
an error. Human data will be collected in three task modes: one in which the
subject is given a position and has to win in a set number of moves; human
versus computer; and human versus human. The investigators will track subjects'
eye movements, which could reveal aspects of planning and perhaps even serve to
visualize the process of mental simulation.

An important component of the project will be computational modeling of the
data. Humans cannot think ahead to the end of the task, so we hypothesize that
they use simple features of positions (heuristics) to value certain moves over
others. Examples of features could be the presence of a three-in-a-row, or of an
adjacent, open-ended two-in-a-row. Preliminary human data suggest "strategic
blind spots" created by the application of the incorrect heuristics. The
investigators aim to predict the probability that a subject will in a given
position make a particular move, based on features of the position that would be
created by that move, as well as the subject's limited depth of reasoning. The
resulting model will allow to quantitatively address the question of whether
learning mostly serves to increase one's depth of reasoning or to refine one's
palette of heuristics. The behavioral and eye movement data will lay the
foundation for studies of the neural substrates of reasoning in complex
decision-making contexts.

The project is positioned at the intersection of computer science, cognitive
psychology, management and decision science, and education, and has the
potential to contribute to each of these fields. In the long run, the project
might be able to contribute to understanding and perhaps avoiding failures to
think "out of the box" in real-life problem-solving. Moreover, strategic tasks
like the one used in this project could serve as a mini-environment for testing
hypotheses about teaching methods.